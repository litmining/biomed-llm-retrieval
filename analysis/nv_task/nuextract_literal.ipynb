{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from utils import clean_extracted_data\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load extracted data\n",
    "output_dir = Path('../../outputs/nv_task/extractions')\n",
    "\n",
    "subset = [\n",
    "    '*NOMC-zeroshot_NuExtract-v1.5.jsonl',\n",
    "    '*NOMC-noexample-zeroshot_NuExtract-2-4B_temperature=0_do_sample=False.jsonl',\n",
    "    '*gpt-4o-mini-2024-07-18*'\n",
    "    ]\n",
    "\n",
    "\n",
    "# Extract substring after NuExtract for each output\n",
    "nv_task_nu_json = {}\n",
    "for s in subset:\n",
    "    t = list(output_dir.glob(s))[0]\n",
    "\n",
    "    # Everying after zeroshot_\n",
    "    key = t.stem.split('zeroshot_')[1]\n",
    "    with open(t, 'r') as f:\n",
    "        nv_task_nu_json[key] = json.load(f)\n",
    "\n",
    "nv_task_nu_dict = {}\n",
    "for params, data in nv_task_nu_json.items():\n",
    "    nv_task_nu_dict[params] = clean_extracted_data(data)\n",
    "\n",
    "# Load documents\n",
    "\n",
    "docs = pd.read_json('../../../labelbuddy-annotations/projects/nv_task/documents/batch_0.jsonl', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add pmcid to docs\n",
    "docs['pmcid'] = docs['metadata'].apply(lambda x: x['pmcid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ns-extraction/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdocs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpmcid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10028637\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ns-extraction/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ns-extraction/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 0"
     ]
    }
   ],
   "source": [
    "docs[docs['pmcid'] == 10028637][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: NuExtract-v1.5\n",
      "Processing Model: NuExtract-2-4B_temperature=0_do_sample=False\n",
      "Processing Model: gpt-4o-mini-2024-07-18\n"
     ]
    }
   ],
   "source": [
    "compare_cols = ['StudyObjective', 'TaskName', 'TaskDescription']\n",
    "# --- End Sample Data ---\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "# --- Helper Function for Text Normalization ---\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Normalizes text extensively:\n",
    "    - Ensures input is a string.\n",
    "    - Converts to lowercase.\n",
    "    - Performs Unicode normalization (NFKC) to handle ligatures (e.g., ﬁ -> fi)\n",
    "      and other compatibility characters.\n",
    "    - Removes accents/diacritics (e.g., é -> e).\n",
    "    - Normalizes various dashes and hyphens to a standard hyphen (-).\n",
    "    - Removes remaining punctuation (excluding the standard hyphen).\n",
    "    - Normalizes whitespace (collapses multiple spaces/tabs/newlines, strips ends).\n",
    "    \"\"\"\n",
    "    # 1. Ensure input is a string\n",
    "    if not isinstance(text, str):\n",
    "        return \"\" # Return empty string if input is not a string\n",
    "\n",
    "    # 2. Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # 3. Unicode Normalization (NFKC)\n",
    "    # Decomposes compatibility characters (like ligatures ﬁ, ﬂ)\n",
    "    # and recomposes them in canonical form.\n",
    "    try:\n",
    "        text = unicodedata.normalize('NFKC', text)\n",
    "    except Exception as e:\n",
    "        # Handle potential errors during normalization if needed\n",
    "        # print(f\"Warning: Unicode normalization failed for text chunk: {e}\")\n",
    "        pass # Continue with the text as is if normalization fails\n",
    "\n",
    "    # 4. Remove accents (diacritics)\n",
    "    # Decompose into base character and combining marks (NFKD)\n",
    "    # then filter out the combining marks.\n",
    "    try:\n",
    "        nfkd_form = unicodedata.normalize('NFKD', text)\n",
    "        text = \"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
    "    except Exception as e:\n",
    "        # print(f\"Warning: Accent removal failed for text chunk: {e}\")\n",
    "        pass # Continue with the text as is if accent removal fails\n",
    "\n",
    "\n",
    "    # 5. Normalize different types of dashes/hyphens to a standard hyphen (-)\n",
    "    # Includes En Dash, Em Dash, Figure Dash, Horizontal Bar, Minus Sign, Hyphen Bullet, Non-breaking Hyphen, standard Hyphen itself\n",
    "    # Ensures all these variants become the standard ASCII hyphen U+002D.\n",
    "    # Using r'[...]' creates a character set.\n",
    "    dashes_pattern = r'[–—‒―−‐‑]' # Note: standard hyphen '-' is implicitly handled if present, but explicitly converting others to it is key.\n",
    "    text = re.sub(dashes_pattern, '-', text)\n",
    "\n",
    "    # 6. Define punctuation to remove (excluding the standard hyphen)\n",
    "    # Start with string.punctuation and remove the standard hyphen '-' from the set.\n",
    "    punctuation_to_remove = string.punctuation.replace('-', '')\n",
    "    # Escape the punctuation characters for safe use in the regex pattern\n",
    "    escaped_punctuation = re.escape(punctuation_to_remove)\n",
    "\n",
    "    # 7. Remove the defined punctuation characters\n",
    "    # Using f'[{escaped_punctuation}]' creates a character set of punctuation to remove.\n",
    "    text = re.sub(f'[{escaped_punctuation}]', '', text)\n",
    "\n",
    "    # 8. Normalize whitespace\n",
    "    # Replace sequences of one or more whitespace characters (space, tab, newline, etc.) with a single space.\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove leading/trailing whitespace.\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "# --- Main Logic ---\n",
    "results = {}\n",
    "\n",
    "\n",
    "def _compare_string(extracted_data, normalized_original_text):\n",
    "    if isinstance(extracted_data, str) and extracted_data.strip():\n",
    "        normalized_extracted = normalize_text(extracted_data)\n",
    "        # Check only if normalized extracted string is not empty\n",
    "        is_substring = normalized_extracted in normalized_original_text if normalized_extracted else False\n",
    "        return is_substring\n",
    "    else:\n",
    "        return False # Treat empty/non-string as not found\n",
    "\n",
    "for model_name, model_data in nv_task_nu_dict.items():\n",
    "    results[model_name] = {}\n",
    "    print(f\"Processing Model: {model_name}\")\n",
    "\n",
    "    for pmcid_str, extracted_values in model_data.items():\n",
    "        results[model_name][pmcid_str] = {}\n",
    "\n",
    "        # Find the original text for the current PMCID\n",
    "        # Assumes PMCID in metadata is integer, key in dict is string\n",
    "        pmcid_int = int(pmcid_str)\n",
    "        original_text = docs[docs['pmcid'] == pmcid_int].iloc[0]['text']\n",
    "\n",
    "        normalized_original_text = normalize_text(original_text)\n",
    "        \n",
    "\n",
    "        if not normalized_original_text: # Handle cases where original text is empty/invalid\n",
    "                raise ValueError(f\"Original text is empty for PMCID {pmcid_str}.\")\n",
    "\n",
    "        # Process each column to compare\n",
    "        for col in compare_cols:\n",
    "\n",
    "            extracted_data = extracted_values[col]\n",
    "\n",
    "            # --- StudyObjective (String) ---\n",
    "            if col == 'StudyObjective':\n",
    "                results[model_name][pmcid_str][col] = _compare_string(normalize_text(extracted_data), normalized_original_text)\n",
    "\n",
    "            # --- TaskName & TaskDescription (List of Strings) ---\n",
    "            elif col in ['TaskName', 'TaskDescription']:\n",
    "                if isinstance(extracted_data, list):\n",
    "                    substring_results = []\n",
    "                    for item in extracted_data:\n",
    "                        substring_results.append(_compare_string(normalize_text(item), normalized_original_text))\n",
    "\n",
    "                else:\n",
    "                        results[model_name][pmcid_str][col] = [] # Treat non-list as empty list\n",
    "                        print(f\"      {col}: Extracted data is not a list.\")\n",
    "\n",
    "                results[model_name][pmcid_str][col] = substring_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_format_data = []\n",
    "\n",
    "# Iterate through the nested dictionary structure\n",
    "for model_name, model_results in results.items():\n",
    "    for pmcid_str, pmcid_results in model_results.items():\n",
    "\n",
    "        # Check for processing errors first\n",
    "        if isinstance(pmcid_results, dict) and 'error' in pmcid_results:\n",
    "            long_format_data.append({\n",
    "                'model': model_name,\n",
    "                'pmcid': pmcid_str,\n",
    "                'column': None, # Or pd.NA\n",
    "                'list_index': pd.NA, # Use pandas NA for missing integer index\n",
    "                'is_substring': None, # Or pd.NA\n",
    "                'status': f\"Error: {pmcid_results['error']}\"\n",
    "            })\n",
    "            continue # Skip to the next PMCID if there was a general error\n",
    "\n",
    "        # Process results for each column if no general error\n",
    "        for col in compare_cols: # Use the same compare_cols list\n",
    "            if col not in pmcid_results:\n",
    "                # This case might not happen if we handled it previously,\n",
    "                # but good for robustness\n",
    "                 long_format_data.append({\n",
    "                    'model': model_name,\n",
    "                    'pmcid': pmcid_str,\n",
    "                    'column': col,\n",
    "                    'list_index': pd.NA,\n",
    "                    'is_substring': None, # Or pd.NA\n",
    "                    'status': 'Column Not Processed' # Or similar indicator\n",
    "                })\n",
    "                 continue\n",
    "\n",
    "            result_value = pmcid_results[col]\n",
    "\n",
    "            if result_value is None:\n",
    "                 # Case where the column was present in compare_cols\n",
    "                 # but missing in the specific extraction output\n",
    "                 long_format_data.append({\n",
    "                    'model': model_name,\n",
    "                    'pmcid': pmcid_str,\n",
    "                    'column': col,\n",
    "                    'list_index': pd.NA,\n",
    "                    'is_substring': None, # Or pd.NA\n",
    "                    'status': 'Column Missing in Extraction'\n",
    "                })\n",
    "\n",
    "            elif isinstance(result_value, bool): # StudyObjective case\n",
    "                long_format_data.append({\n",
    "                    'model': model_name,\n",
    "                    'pmcid': pmcid_str,\n",
    "                    'column': col,\n",
    "                    'list_index': pd.NA, # No list index for single boolean\n",
    "                    'is_substring': result_value,\n",
    "                    'status': 'OK'\n",
    "                })\n",
    "\n",
    "            elif isinstance(result_value, list): # TaskName/TaskDescription case\n",
    "                if not result_value: # Handle empty lists\n",
    "                    long_format_data.append({\n",
    "                        'model': model_name,\n",
    "                        'pmcid': pmcid_str,\n",
    "                        'column': col,\n",
    "                        'list_index': pd.NA,\n",
    "                        'is_substring': None, # Or pd.NA\n",
    "                        'status': 'Extracted List Empty'\n",
    "                    })\n",
    "                else:\n",
    "                    for idx, bool_val in enumerate(result_value):\n",
    "                         long_format_data.append({\n",
    "                            'model': model_name,\n",
    "                            'pmcid': pmcid_str,\n",
    "                            'column': col,\n",
    "                            'list_index': idx, # Add the index from the list\n",
    "                            'is_substring': bool_val,\n",
    "                            'status': 'OK'\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame\n",
    "results_long_df = pd.DataFrame(long_format_data)\n",
    "\n",
    "# Optional: Set specific data types if needed\n",
    "results_long_df['pmcid'] = results_long_df['pmcid'].astype(str) # Keep PMCID as string\n",
    "results_long_df['list_index'] = results_long_df['list_index'].astype(pd.Int64Dtype()) # Use nullable integer type\n",
    "results_long_df['is_substring'] = results_long_df['is_substring'].astype(pd.BooleanDtype()) # Use nullable boolean type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model                                         column         \n",
       "NuExtract-2-4B_temperature=0_do_sample=False  StudyObjective     0.828571\n",
       "                                              TaskDescription    0.595455\n",
       "                                              TaskName           0.945455\n",
       "NuExtract-v1.5                                StudyObjective     0.820755\n",
       "                                              TaskDescription    0.863158\n",
       "                                              TaskName           0.991228\n",
       "gpt-4o-mini-2024-07-18                        StudyObjective     0.211538\n",
       "                                              TaskDescription    0.111111\n",
       "                                              TaskName            0.79798\n",
       "Name: is_substring, dtype: Float64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_long_df.groupby(['model', 'column'])['is_substring'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>column</th>\n",
       "      <th>list_index</th>\n",
       "      <th>is_substring</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NuExtract-v1.5</td>\n",
       "      <td>10129386</td>\n",
       "      <td>TaskDescription</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NuExtract-v1.5</td>\n",
       "      <td>4517759</td>\n",
       "      <td>TaskDescription</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>NuExtract-v1.5</td>\n",
       "      <td>4517759</td>\n",
       "      <td>TaskDescription</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NuExtract-v1.5</td>\n",
       "      <td>5324609</td>\n",
       "      <td>TaskDescription</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>NuExtract-v1.5</td>\n",
       "      <td>5324609</td>\n",
       "      <td>TaskDescription</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>9308012</td>\n",
       "      <td>TaskDescription</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>9454014</td>\n",
       "      <td>TaskDescription</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>9837608</td>\n",
       "      <td>TaskDescription</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>9910278</td>\n",
       "      <td>TaskDescription</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>9910278</td>\n",
       "      <td>TaskDescription</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model     pmcid           column  list_index  \\\n",
       "10            NuExtract-v1.5  10129386  TaskDescription           0   \n",
       "131           NuExtract-v1.5   4517759  TaskDescription           1   \n",
       "132           NuExtract-v1.5   4517759  TaskDescription           2   \n",
       "162           NuExtract-v1.5   5324609  TaskDescription           0   \n",
       "163           NuExtract-v1.5   5324609  TaskDescription           1   \n",
       "...                      ...       ...              ...         ...   \n",
       "1255  gpt-4o-mini-2024-07-18   9308012  TaskDescription           0   \n",
       "1258  gpt-4o-mini-2024-07-18   9454014  TaskDescription           0   \n",
       "1264  gpt-4o-mini-2024-07-18   9837608  TaskDescription           0   \n",
       "1268  gpt-4o-mini-2024-07-18   9910278  TaskDescription           0   \n",
       "1269  gpt-4o-mini-2024-07-18   9910278  TaskDescription           1   \n",
       "\n",
       "      is_substring status  \n",
       "10           False     OK  \n",
       "131          False     OK  \n",
       "132          False     OK  \n",
       "162          False     OK  \n",
       "163          False     OK  \n",
       "...            ...    ...  \n",
       "1255         False     OK  \n",
       "1258         False     OK  \n",
       "1264         False     OK  \n",
       "1268         False     OK  \n",
       "1269         False     OK  \n",
       "\n",
       "[190 rows x 6 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_long_df[(results_long_df['is_substring'] == False) & (results_long_df['column'] == 'TaskDescription')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmcid = 10129386\n",
    "_sub = normalize_text(nv_task_nu_dict['NuExtract-2-4B_temperature=0_do_sample=False'][pmcid]['TaskDescription'][0]) \n",
    "_text = normalize_text(docs[docs['pmcid'] == pmcid].iloc[0]['text'])\n",
    "_sub in _text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'participants were administered a set of trait adjectives from the affective norms of emotion words database the original 20 positive and 20 negative trait adjectives were translated to swedish by the first author slightly modified to make the words more relevant in swedish and divided into blocks of five words each which were either all positive or all negative to each block one ‘fluid’ word and one ‘constant’ word judged to be of the same valence as the rest of the block were added total 16 words relating to fluiditysolidity each word was presented for 3 s resulting in a total of 21 s per seven-word block a fixation cross was presented for 4 s between each block the blocks were presented three times once in conjunction with each of three questions ‘describes me’ self condition ‘is positive’ valence condition and ‘is uppercase’ case condition'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "_s = 'participants were administered a set of trait adjectives from the affective norms of emotion words database the original 20 positive and 20 negative trait adjectives were translated to swedish by the first author slightly modified to make the words more relevant in swedish and divided into blocks of five words each which were either all positive or all negative to each block one ‘fluid’ word and one ‘constant’ word judged to be of the same valence as the rest of the block were added total 16 words relating to fluiditysolidity examples of such words were ‘bestandig’ durable positive-constant ‘dynamisk’ dynamic positive-fluid ‘statisk’ static negative-constant and ‘flyktig’ volatile negative-fluid half of the words evenly distributed across positive and negative were presented in uppercase and the other half in lowercase letters each word was presented for 3 s resulting in a total of 21 s per seven-word block a fixation cross was presented for 4 s between each block the blocks were presented three times once in conjunction with each of three questions ‘describes me’ self condition ‘is positive’ valence condition and ‘is uppercase’ case condition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Home findings\n",
    "\n",
    "For the most part, NuExtract models are fairly truthfully quoting the original text, although occasionally both models will leave out a word\n",
    "\n",
    "However, more annoyingly, due to punctionation and slight differences in text normalization, it can be difficult to find the substring in the original text.\n",
    "\n",
    "In longer texts it is likely it is this normalization that is throwing things off, although in NuExtract 2 it is very often modifying the original text\n",
    "\n",
    "Meanwhile, GPT 4o is not too far from accurately quoting the original task for taskname, but veers further in StudyObject and TaskDescription, although this can often be a good thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ns-extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
