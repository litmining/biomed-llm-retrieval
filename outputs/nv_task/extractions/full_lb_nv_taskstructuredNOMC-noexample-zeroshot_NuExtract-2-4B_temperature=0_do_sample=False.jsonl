[{"StudyObjective": "To ask whether the connectivity within and between three networks that are primary sites of propofol\u2010induced sedation and key to conscious cognition\u2014the DAN, ECN, and DMN\u2014underlie individual responsiveness differences under anaesthesia.", "fMRITasks": [{"TaskName": "Auditory target detection task", "TaskDescription": "Participants were asked to perform a computerized auditory target detection task (50 trials), which aimed to assess individual responsiveness differences during moderate anaesthesia.", "DesignDetails": "The task was conducted prior to scanning, and responses beyond 3000\u2009ms were not monitored.", "Conditions": ["Wakefulness", "Moderate anaesthesia"], "TaskMetrics": ["Reaction time", "Hit rate"], "RestingState": "false", "TaskDuration": "3000\u2009ms"}, {"TaskName": "Resting\u2010state fMRI", "TaskDescription": "Participants underwent two functional scans during wakefulness and moderate anaesthesia. A plot\u2010driven auditory narrative (5\u00a0min) was presented over MRI compatible noise cancelation headphones (Sensimetrics, S14; www.sens.com). Participants were asked to simply listen with eyes closed.", "DesignDetails": "The narrative comprised a highly engaging auditory excerpt from the movie \u201cTaken\u201d depicting dramatic events, where a young girl travelling abroad without her family is kidnapped while speaking on the phone to her father. The same narrative was presented during wakefulness and moderate anaesthesia.", "Conditions": ["Wakefulness", "Moderate anaesthesia"], "TaskMetrics": [], "RestingState": "true", "TaskDuration": "8\u00a0min"}], "BehavioralTasks": [{"TaskName": "Suspense ratings", "TaskDescription": "To determine how similar suspense ratings were across the group, the inter\u2010subject correlation of suspense ratings was computed as the average of the Pearson correlations of each participant's data with the mean data from the rest of the group.", "DesignDetails": "To account for the non\u2010normalized distribution of correlation values (Fisher,\u00a0), all statistical analyses were performed on z\u2010transformed correlation values, using Fisher's r\u2010to\u2010z transformation.", "Conditions": [], "TaskMetrics": ["Suspense ratings"]}], "id": 10028637}, {"StudyObjective": "To explore the neural correlates of four distinct dimensions of Formal Thought Disorder (FTD) using perfusion and structural MRI.", "fMRITasks": [], "BehavioralTasks": [], "id": 10031743}, {"StudyObjective": "To target the neural correlates of trait self-boundarylessness both in rest and in relation to narrative and minimal self.", "fMRITasks": [{"TaskName": "SRP", "TaskDescription": "Participants were administered a set of trait adjectives from the Affective Norms of Emotion Words database. The original 20 positive and 20 negative trait adjectives were translated to Swedish by the first author, slightly modified to make the words more relevant in Swedish, and divided into blocks of five words each, which were either all positive or all negative. To each block, one \u2018fluid\u2019 word and one \u2018constant\u2019 word judged to be of the same valence as the rest of the block were added (total 16 words relating to fluidity/solidity). Each word was presented for 3 s, resulting in a total of 21\u2009s per seven-word block. A fixation cross was presented for 4 s between each block. The blocks were presented three times, once in conjunction with each of three questions: \u2018describes me?\u2019 (Self condition), \u2018is positive?\u2019 (Valence condition), and \u2018is uppercase?\u2019 (Case condition).", "DesignDetails": "The first functional run was a resting-state scan lasting 10.43\u2009minutes (350 TRs of 1.8 s each). Participants were instructed to keep their eyes closed and rest but not fall asleep and to not deliberately meditate. The field of view was 224\u2009\u00d7\u2009232\u2009\u00d7\u2009149\u2009mm  comprising 68 slices.", "Conditions": ["Self condition", "Valence condition", "Case condition"], "TaskMetrics": ["Response times", "Endorsement of fluidity words", "Endorsement of constancy words"], "RestingState": "true", "TaskDuration": "10.43\u2009minutes"}, {"TaskName": "Checking-in", "TaskDescription": "This task was also presented through E-prime and consisted of simple math questions interspersed with presentations of shapes (circle, square, triangle, or arrow). Participants were instructed beforehand to \u2018focus on the centre of your experience, the \u201cexperiencer\u201d or \u201cobserver\u201d\u2019 whenever the arrow was presented. Again, while Arrow was the condition of interest, Symbol was a close control condition, and Math a disparate control condition. The duration of math blocks (three questions per block) and arrow blocks were fixed to 12\u2009s, whereas the duration of the other symbols was jittered (randomized between two and eight TRs), so that the average was 12\u2009s per block of two symbols. The order of the three conditions (Math, Arrow, and Symbol) was the same for all participants and was pseudo-randomized, so that no block type was presented more than twice in a row. The duration of this run was 12\u2009minutes (600 TRs of 1.2 s each), and the field of view was 224\u2009\u00d7\u2009232\u2009\u00d7\u200997 mm , comprising 44 dynamic slices.", "DesignDetails": "The third functional run was designed to target the sense of perspectival ownership of experience (hereafter checking-in). This task was also presented through E-prime and consisted of simple math questions interspersed with presentations of shapes (circle, square, triangle, or arrow). Participants were instructed beforehand to \u2018focus on the centre of your experience, the \u201cexperiencer\u201d or \u201cobserver\u201d\u2019 whenever the arrow was presented. Again, while Arrow was the condition of interest, Symbol was a close control condition, and Math a disparate control condition. The duration of math blocks (three questions per block) and arrow blocks were fixed to 12\u2009s, whereas the duration of the other symbols was jittered (randomized between two and eight TRs), so that the average was 12\u2009s per block of two symbols. The order of the three conditions (Math, Arrow, and Symbol) was the same for all participants and was pseudo-randomized, so that no block type was presented more than twice in a row. The duration of this run was 12\u2009minutes (600 TRs of 1.2 s each), and the field of view was 224\u2009\u00d7\u2009232\u2009\u00d7\u200997 mm , comprising 44 dynamic slices.", "Conditions": ["Arrow condition", "Symbol condition", "Math condition"], "TaskMetrics": ["Response times", "Endorsement of fluidity words", "Endorsement of constancy words"], "RestingState": "false", "TaskDuration": "12\u2009minutes"}], "BehavioralTasks": [{"TaskName": "SRP", "TaskDescription": "Participants were administered a set of trait adjectives from the Affective Norms of Emotion Words database. The original 20 positive and 20 negative trait adjectives were translated to Swedish by the first author, slightly modified to make the words more relevant in Swedish, and divided into blocks of five words each, which were either all positive or all negative. To each block, one \u2018fluid\u2019 word and one \u2018constant\u2019 word judged to be of the same valence as the rest of the block were added (total 16 words relating to fluidity/solidity). Each word was presented for 3 s, resulting in a total of 21\u2009s per seven-word block. A fixation cross was presented for 4 s between each block. The blocks were presented three times, once in conjunction with each of three questions: \u2018describes me?\u2019 (Self condition), \u2018is positive?\u2019 (Valence condition), and \u2018is uppercase?\u2019 (Case condition).", "DesignDetails": "The first functional run was a resting-state scan lasting 10.43\u2009minutes (350 TRs of 1.8 s each). Participants were instructed to keep their eyes closed and rest but not fall asleep and to not deliberately meditate. The field of view was 224\u2009\u00d7\u2009232\u2009\u00d7\u2009149\u2009mm  comprising 68 slices.", "Conditions": ["Self condition", "Valence condition", "Case condition"], "TaskMetrics": ["Response times", "Endorsement of fluidity words", "Endorsement of constancy words"], "RestingState": "true", "TaskDuration": "10.43\u2009minutes"}, {"TaskName": "Checking-in", "TaskDescription": "This task was also presented through E-prime and consisted of simple math questions interspersed with presentations of shapes (circle, square, triangle, or arrow). Participants were instructed beforehand to \u2018focus on the centre of your experience, the \u201cexperiencer\u201d or \u201cobserver\u201d\u2019 whenever the arrow was presented. Again, while Arrow was the condition of interest, Symbol was a close control condition, and Math a disparate control condition. The duration of math blocks (three questions per block) and arrow blocks were fixed to 12\u2009s, whereas the duration of the other symbols was jittered (randomized between two and eight TRs), so that the average was 12\u2009s per block of two symbols. The order of the three conditions (Math, Arrow, and Symbol) was the same for all participants and was pseudo-randomized, so that no block type was presented more than twice in a row. The duration of this run was 12\u2009minutes (600 TRs of 1.2 s each), and the field of view was 224\u2009\u00d7\u2009232\u2009\u00d7\u200997 mm , comprising 44 dynamic slices.", "DesignDetails": "The third functional run was designed to target the sense of perspectival ownership of experience (hereafter checking-in). This task was also presented through E-prime and consisted of simple math questions interspersed with presentations of shapes (circle, square, triangle, or arrow). Participants were instructed beforehand to \u2018focus on the centre of your experience, the \u201cexperiencer\u201d or \u201cobserver\u201d\u2019 whenever the arrow was presented. Again, while Arrow was the condition of interest, Symbol was a close control condition, and Math a disparate control condition. The duration of math blocks (three questions per block) and arrow blocks were fixed to 12\u2009s, whereas the duration of the other symbols was jittered (randomized between two and eight TRs), so that the average was 12\u2009s per block of two symbols. The order of the three conditions (Math, Arrow, and Symbol) was the same for all participants and was pseudo-randomized, so that no block type was presented more than twice in a row. The duration of this run was 12\u2009minutes (600 TRs of 1.2 s each), and the field of view was 224\u2009\u00d7\u2009232\u2009\u00d7\u200997 mm , comprising 44 dynamic slices.", "Conditions": ["Arrow condition", "Symbol condition", "Math condition"], "TaskMetrics": ["Response times", "Endorsement of fluidity words", "Endorsement of constancy words"], "RestingState": "false", "TaskDuration": "12\u2009minutes"}], "id": 10129386}, {"StudyObjective": "Accurate localization and coactivation profiles of the frontal eye field and inferior frontal junction: an ALE and MACM fMRI meta-analysis", "fMRITasks": [{"TaskName": "Prosaccades and antisaccades", "TaskDescription": "The planning and execution of visually guided and voluntary eye movements", "DesignDetails": "The FEF is a well-characterized region in the fMRI literature", "Conditions": ["Prosaccades", "Antisaccades", "Fixation"], "TaskMetrics": ["FEF peaks"], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Oddball and attention", "TaskDescription": "Visual attention, working memory, and cognitive control", "DesignDetails": "The IFJ does not have a well-established homolog in the macaque", "Conditions": ["Oddball", "Target trials", "Endogenous cueing paradigms"], "TaskMetrics": ["IFJ peaks"], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Task-switching and Stroop tasks", "TaskDescription": "Task-switching and cognitive control", "DesignDetails": "The IFJ does not have a well-established homolog in the macaque", "Conditions": ["Task-switching", "Stroop tasks"], "TaskMetrics": ["IFJ peaks"], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [], "id": 10147761}, {"StudyObjective": "The neural signature of reality\u2010monitoring: A meta\u2010analysis of functional neuroimaging studies", "fMRITasks": [{"TaskName": "Reality\u2010monitoring", "TaskDescription": "Reality\u2010monitoring involves distinguishing between self\u2010generated actions or thoughts and those generated by others.", "DesignDetails": "Reality\u2010monitoring involves distinguishing between self\u2010generated actions or thoughts and those generated by others.", "Conditions": ["Self\u2009>\u2009nonself", "Self\u2009<\u2009nonself"], "TaskMetrics": ["Hedge's g\u2010corrected effect sizes", "Low between\u2010study heterogeneity"], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Self\u2010monitoring", "TaskDescription": "Self\u2010monitoring involves distinguishing self\u2010generated actions or thoughts from those generated by others.", "DesignDetails": "Self\u2010monitoring involves distinguishing self\u2010generated actions or thoughts from those generated by others.", "Conditions": ["Self\u2009>\u2009nonself", "Self\u2009<\u2009nonself"], "TaskMetrics": ["Hedge's g\u2010corrected effect sizes", "Low between\u2010study heterogeneity"], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [], "id": 10318245}, {"StudyObjective": "Adolescents\u2019 neural sensitivity to high and low popularity: Longitudinal links to risk-taking and prosocial behavior", "fMRITasks": [{"TaskName": "Classmates Task", "TaskDescription": "Participants viewed yearbook photos of their classmates from school. The yearbook photos were selected based on the sociometric data from the previous year, and the task had four conditions: High social preference, low social preference, high popularity, and low popularity.", "DesignDetails": "The task was adapted from  , participants viewed yearbook photos of their peers from school. The yearbook photos were selected based on the sociometric data from the previous year, and the task had four conditions: High social preference, low social preference, high popularity, and low popularity.", "Conditions": ["High social preference", "low social preference", "high popularity", "low popularity"], "TaskMetrics": ["neural tracking of high popularity", "neural tracking of low popularity"], "RestingState": "false", "TaskDuration": "1.5\u00a0h"}, {"TaskName": "Other tasks", "TaskDescription": "Four other tasks that are not the focus of this manuscript.", "DesignDetails": "Four other tasks that are not the focus of this manuscript.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Prosocial Tendencies Measure", "TaskDescription": "Participants reported on how much they feel 19 different behavioral tendencies apply to them on a 5-point scale.", "DesignDetails": "During the school based assessment, participants completed the Prosocial Tendencies Measure ( ). Adolescents reported on how much they feel 19 different behavioral tendencies apply to them on a 5-point scale (1\u00a0= Does not describe me at all, 2\u00a0= Describes me a little, 3\u00a0= Somewhat describes me, 4\u00a0= Describes me well, 5\u00a0= Describes me greatly).", "Conditions": [], "TaskMetrics": ["prosocial behavior"]}, {"TaskName": "Adolescent Risk-taking Scale", "TaskDescription": "Participants completed a modified version of the Adolescent Risk-taking Scale ( ). Adolescents reported on their frequency of engaging in 14 risky behaviors on a 4-point scale.", "DesignDetails": "Participants completed a modified version of the Adolescent Risk-taking Scale ( ). Adolescents reported on their frequency of engaging in 14 risky behaviors on a 4-point scale (0\u00a0= never, 1\u00a0= once or twice, 2 = several times, 3 = many times).", "Conditions": [], "TaskMetrics": ["risk-taking behavior"]}], "id": 10458690}, {"StudyObjective": "The neurocognitive processes underlying Pavlovian conditioning in humans are still largely debated.", "fMRITasks": [{"TaskName": "Expectancy ratings", "TaskDescription": "A repeated-measures ANOVA on expectancy ratings performed with trial sequence (6 levels) as a within-subject variable revealed a significant main effect of trial sequence [  F  (5, 100)\u2009=\u200957.98,   P  \u2009<\u20090.001,   =\u20090.744]. A significant linear trend was also identified, indicating that expectancy ratings decreased linearly with sequential shock [  F  (1, 20)\u2009=\u200971.88,   P  \u2009<\u20090.001,   =\u20090.782] ( ).", "DesignDetails": "A repeated-measures ANOVA on expectancy ratings performed with trial sequence (6 levels) as a within-subject variable revealed a significant main effect of trial sequence [  F  (5, 100)\u2009=\u200957.98,   P  \u2009<\u20090.001,   =\u20090.744]. A significant linear trend was also identified, indicating that expectancy ratings decreased linearly with sequential shock [  F  (1, 20)\u2009=\u200971.88,   P  \u2009<\u20090.001,   =\u20090.782] ( ).", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "fMRI univariate whole-brain results", "TaskDescription": "The unthresholded whole-brain maps reported below, including those that were non-significant, can be found at  .", "DesignDetails": "The unthresholded whole-brain maps reported below, including those that were non-significant, can be found at  .", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "fMRI univariate ROI results", "TaskDescription": "No significant effects were observed in the bilateral amygdala ROI.", "DesignDetails": "No significant effects were observed in the bilateral amygdala ROI.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "FMRI exploratory FIR results", "TaskDescription": "The results of a whole-brain analysis on the fifth FIR bin, corresponding to 8\u201310\u2009seconds after CS onset, revealed several clusters of activity consistent with the associative strength model\u00a0( ;  ). Notably, there was significant activity in the left insula, including the parts of both the anterior and posterior insula, and the left visual cortex, including the occipital pole. Additionally, activity during this time-window of the FIR was also not confounded by the shock delivery, as shock-related BOLD response to shock-no shock was observed in FIR bins 7\u20138 (2\u20136\u2009seconds after CS offset) as can be seen in\u00a0 .", "DesignDetails": "The results of a whole-brain analysis on the fifth FIR bin, corresponding to 8\u201310\u2009seconds after CS onset, revealed several clusters of activity consistent with the associative strength model\u00a0( ;  ). Notably, there was significant activity in the left insula, including the parts of both the anterior and posterior insula, and the left visual cortex, including the occipital pole. Additionally, activity during this time-window of the FIR was also not confounded by the shock delivery, as shock-related BOLD response to shock-no shock was observed in FIR bins 7\u20138 (2\u20136\u2009seconds after CS offset) as can be seen in\u00a0 .", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Expectancy ratings", "TaskDescription": "A repeated-measures ANOVA on expectancy ratings performed with trial sequence (6 levels) as a within-subject variable revealed a significant main effect of trial sequence [  F  (5, 100)\u2009=\u200957.98,   P  \u2009<\u20090.001,   =\u20090.744]. A significant linear trend was also identified, indicating that expectancy ratings decreased linearly with sequential shock [  F  (1, 20)\u2009=\u200971.88,   P  \u2009<\u20090.001,   =\u20090.782] ( ).", "DesignDetails": "A repeated-measures ANOVA on expectancy ratings performed with trial sequence (6 levels) as a within-subject variable revealed a significant main effect of trial sequence [  F  (5, 100)\u2009=\u200957.98,   P  \u2009<\u20090.001,   =\u20090.744]. A significant linear trend was also identified, indicating that expectancy ratings decreased linearly with sequential shock [  F  (1, 20)\u2009=\u200971.88,   P  \u2009<\u20090.001,   =\u20090.782] ( ).", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "id": 10597625}, {"StudyObjective": "The continuous decline of executive abilities with age is mirrored by increased neural activity of domain-general networks during task processing. So far, it remains unclear how much domain-general networks contribute to domain-specific processes such as language when cognitive demands increase.", "fMRITasks": [{"TaskName": "Semantic judgment", "TaskDescription": "Participants were required to decide whether an auditory stimulus matches with a presented image via yes/no-button press using the index and middle finger of their left hand.", "DesignDetails": "Two tasks were implemented in the fMRI experiment: a semantic judgment task with varying cognitive demand (low demand: WPM, high demand: FPM) and a non-verbal tone judgment task.", "Conditions": ["WPM", "FPM", "tone judgment"], "TaskMetrics": ["accuracy", "reaction time"], "RestingState": "false", "TaskDuration": "3.5\u00a0s"}, {"TaskName": "Tone judgment", "TaskDescription": "Participants were required to decide whether an auditory stimulus matches with a presented image via yes/no-button press using the index and middle finger of their left hand.", "DesignDetails": "Two tasks were implemented in the fMRI experiment: a semantic judgment task with varying cognitive demand (low demand: WPM, high demand: FPM) and a non-verbal tone judgment task.", "Conditions": ["WPM", "FPM", "tone judgment"], "TaskMetrics": ["accuracy", "reaction time"], "RestingState": "false", "TaskDuration": "3.5\u00a0s"}], "BehavioralTasks": [{"TaskName": "Semantic judgment", "TaskDescription": "Participants were required to decide whether an auditory stimulus matches with a presented image via yes/no-button press using the index and middle finger of their left hand.", "DesignDetails": "Two tasks were implemented in the fMRI experiment: a semantic judgment task with varying cognitive demand (low demand: WPM, high demand: FPM) and a non-verbal tone judgment task.", "Conditions": ["WPM", "FPM", "tone judgment"], "TaskMetrics": ["accuracy", "reaction time"], "RestingState": "false"}, {"TaskName": "Tone judgment", "TaskDescription": "Participants were required to decide whether an auditory stimulus matches with a presented image via yes/no-button press using the index and middle finger of their left hand.", "DesignDetails": "Two tasks were implemented in the fMRI experiment: a semantic judgment task with varying cognitive demand (low demand: WPM, high demand: FPM) and a non-verbal tone judgment task.", "Conditions": ["WPM", "FPM", "tone judgment"], "TaskMetrics": ["accuracy", "reaction time"], "RestingState": "false"}], "id": 10615837}, {"StudyObjective": "Meta-Analysis Reveals That Explore-Exploit Decisions are Dissociable by Activation in the Dorsal Lateral Prefrontal Cortex, Anterior Insula, and the Anterior Cingulate Cortex", "fMRITasks": [{"TaskName": "n-armed bandit tasks", "TaskDescription": "Participants decide which slot machine they would like to sample from.", "DesignDetails": "Explore-exploit decisions are classified through a variety of computational algorithms, such as Boltzmann exploration (softmax), reinforcement learning ( ), and can be approximated through Partially Observable Markov Decision Processes (POMDP) ( ). Ultimately, when the participant chooses bandits higher expected value, the decisions are classified as exploitative and when they choose bandits with lower or unknown expected value, they are classified as explorative (Daw et al., 2006).", "Conditions": ["exploitation", "exploration"], "TaskMetrics": ["activation in the dorsal lateral prefrontal cortex, anterior insula, and anterior cingulate cortex during exploration versus exploitation"], "RestingState": "false", "TaskDuration": null}, {"TaskName": "other tasks", "TaskDescription": "Tasks that do not have a continuous sequence of changing rewards as may be expected.", "DesignDetails": "Other tasks do not have a continuous sequence of changing rewards as may be expected. While both n-armed bandit and foraging tasks are grouped as explore-exploit tasks, they are sufficiently different to serve as potential comparison groups.", "Conditions": ["exploitation", "exploration"], "TaskMetrics": ["activation in the dorsal lateral prefrontal cortex, anterior insula, and anterior cingulate cortex during exploration versus exploitation"], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "foraging tasks", "TaskDescription": "A participant selects whether to forage from a patch of resources such as an apple tree, or to travel to another patch at some distance from the current patch.", "DesignDetails": "Foraging tasks can be modeled through Markov decision processes ( ).", "Conditions": ["exploitation", "exploration"], "TaskMetrics": ["activation in the dorsal lateral prefrontal cortex, anterior insula, and anterior cingulate cortex during exploration versus exploitation"]}, {"TaskName": "clock hand task", "TaskDescription": "A fixed reward structure which is learned over time and exploration and exploitation is classified based on response times.", "DesignDetails": "The clock hand task employs a fixed reward structure which is learned over time and exploration and exploitation is classified based on response times ( ).", "Conditions": ["exploitation", "exploration"], "TaskMetrics": ["activation in the dorsal lateral prefrontal cortex, anterior insula, and anterior cingulate cortex during exploration versus exploitation"]}, {"TaskName": "web surf task", "TaskDescription": "A task that has clear shifts between exploration and exploitation based on observable changes in strategy.", "DesignDetails": "The web surf task has clear shifts between exploration and exploitation based on observable changes in strategy.", "Conditions": ["exploitation", "exploration"], "TaskMetrics": ["activation in the dorsal lateral prefrontal cortex, anterior insula, and anterior cingulate cortex during exploration versus exploitation"]}, {"TaskName": "observe-bet task", "TaskDescription": "A task that has clear shifts between exploration and exploitation based on observable changes in strategy.", "DesignDetails": "The observe-bet task has clear shifts between exploration and exploitation based on observable changes in strategy.", "Conditions": ["exploitation", "exploration"], "TaskMetrics": ["activation in the dorsal lateral prefrontal cortex, anterior insula, and anterior cingulate cortex during exploration versus exploitation"]}], "id": 10634720}, {"StudyObjective": "To investigate central pain mechanisms in the context of the gut-brain axis, novel experimental protocols with painful stimuli from different modalities applied within one brain imaging session, so called \u2018multiple threat paradigms\u2019, have more recently been implemented. These were designed to model the experience of multiple symptoms arising from the viscera and other bodily sites, reflecting patients\u2019 clinical reality of aversive intestinal and extraintestinal symptoms.", "fMRITasks": [{"TaskName": "Visceral pain", "TaskDescription": "Pain arising from the viscera, herein induced by pressure-controlled rectal distensions stimuli", "DesignDetails": "Visceral pain thresholds were comparable across groups, but visceral thresholds correlated with gastrointestinal symptom severity and chronic stress burden exclusively within UC.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Somatic pain", "TaskDescription": "Pain arising from somatically innervated organs such as the muscles or the skin, herein induced using cutaneous thermal heat pain stimuli", "DesignDetails": "Pain thresholds were comparable across groups, but visceral thresholds correlated with gastrointestinal symptom severity and chronic stress burden exclusively within UC.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Perceived pain intensity", "TaskDescription": "With regard to perceived pain intensity, the mixed ANOVA revealed a significant interaction between group and modality (F[2,65]\u2005=\u20054.634,   p  \u2005=\u20050.013, \u03b7  = .13). Post-hoc paired t-tests demonstrated a significant difference between mean visceral and somatic perceived pain intensities for healthy volunteers (t[24]\u2005=\u20052.14,   p  \u2005=\u20050.042, d\u2005=\u20050.43) and patients with IBS (t[22]\u2005=\u20052.42,   p  \u2005=\u20050.024, d\u2005=\u20050.51).", "DesignDetails": "With regard to perceived pain intensity, the mixed ANOVA revealed a significant interaction between group and modality (F[2,65]\u2005=\u20054.634,   p  \u2005=\u20050.013, \u03b7  = .13). Post-hoc paired t-tests demonstrated a significant difference between mean visceral and somatic perceived pain intensities for healthy volunteers (t[24]\u2005=\u20052.14,   p  \u2005=\u20050.042, d\u2005=\u20050.43) and patients with IBS (t[22]\u2005=\u20052.42,   p  \u2005=\u20050.024, d\u2005=\u20050.51).", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "id": 10637045}, {"StudyObjective": "To examine self-reported rumination in association with rejection-related neural activity and connectivity in adolescent girls.", "fMRITasks": [{"TaskName": "Chatroom fMRI task", "TaskDescription": "Participants were asked to classify half of the 60 adolescents' photographs into the peers that they wanted to chat with (liked peers) and another half of the photographs into the peers that they did not want to chat with (unliked peers). At the second visit, in the fMRI scanner, participants received feedback indicating whether each of 60 adolescents were interested in chatting with them (acceptance) or not (rejection) or did not rate their interest (not rated), and reported how receiving this social feedback made them feel.", "DesignDetails": "The task consists of a selection phase (out of scanner) and a feedback phase (in scanner) administered in two visits. Visits one and two were separated 16.49 days on average (SD: 28.96). Both phases of the task were administered using E-Prime software.", "Conditions": ["liked peers", "unliked peers"], "TaskMetrics": ["neural response to rejection from liked peers", "neural response to rejection from unliked peers"], "RestingState": "false", "TaskDuration": "16.49 days"}, {"TaskName": "Chatroom fMRI task", "TaskDescription": "Participants were asked to classify half of the 60 adolescents' photographs into the peers that they wanted to chat with (liked peers) and another half of the photographs into the peers that they did not want to chat with (unliked peers). At the second visit, in the fMRI scanner, participants received feedback indicating whether each of 60 adolescents were interested in chatting with them (acceptance) or not (rejection) or did not rate their interest (not rated), and reported how receiving this social feedback made them feel.", "DesignDetails": "The task consists of a selection phase (out of scanner) and a feedback phase (in scanner) administered in two visits. Visits one and two were separated 16.49 days on average (SD: 28.96). Both phases of the task were administered using E-Prime software.", "Conditions": ["liked peers", "unliked peers"], "TaskMetrics": ["neural response to rejection from liked peers", "neural response to rejection from unliked peers"], "RestingState": "false", "TaskDuration": "16.49 days"}], "BehavioralTasks": [{"TaskName": "Emotional rating", "TaskDescription": "Participants were asked to report how receiving this social feedback made them feel.", "DesignDetails": null, "Conditions": ["liked peers", "unliked peers"], "TaskMetrics": ["emotional response to rejection from liked peers", "emotional response to rejection from unliked peers"]}, {"TaskName": "Reaction time", "TaskDescription": "Participants were asked to report how receiving this social feedback made them feel.", "DesignDetails": null, "Conditions": ["liked peers", "unliked peers"], "TaskMetrics": ["reaction time to rejection from liked peers", "reaction time to rejection from unliked peers"]}], "id": 10641579}, {"StudyObjective": "Neural tracking of social hierarchies in adolescents\u2019 real-world social networks", "fMRITasks": [{"TaskName": "Classmates fMRI task", "TaskDescription": "Adolescents viewed yearbook photos of their peers from their school and grade. The task was created using E-prime 2.0, and one version was made for each grade level within each school.", "DesignDetails": "The task had four conditions: high social preference, low social preference, high popularity, and low popularity.", "Conditions": ["high social preference", "low social preference", "high popularity", "low popularity"], "TaskMetrics": ["sociometric rating"], "RestingState": "false", "TaskDuration": "1750\u2009ms"}], "BehavioralTasks": [], "id": 10656574}, {"StudyObjective": "To assess the causal effect of VVGs on the behavioral and neural correlates of empathy and emotional reactivity to violence.", "fMRITasks": [{"TaskName": "Empathy-for-pain task", "TaskDescription": "Participants either received electric stimuli themselves or saw images of the confederate indicating that he was currently receiving electric stimulation. The stimuli were either painful or perceptible but not painful.", "DesignDetails": "Participants were randomly assigned to the violent game group or the control game group. Participants first completed a pretest fMRI session, during which they performed an experimental task designed to measure empathy for pain. Then, over the course of 2 weeks, participants of the violent game group repeatedly played a VVG, while the control game group played a non-violent version of the same game. Subsequently, both groups completed the posttest fMRI session.", "Conditions": ["Self Pain", "Self No Pain", "Other Pain", "Other No Pain"], "TaskMetrics": ["Painfulness ratings", "Unpleasantness ratings"], "RestingState": "false", "TaskDuration": "20 min"}, {"TaskName": "Emotional reactivity task", "TaskDescription": "To investigate emotional reactivity to violent images, we used an affective picture paradigm. Participants were shown pictures of either neutral or violent content. Additionally, the pictures depicted either real scenes, or scenes taken from the video game participants played during the gaming sessions.", "DesignDetails": "Participants were randomly assigned to the violent game group or the control game group. Participants first completed a pretest fMRI session, during which they performed an experimental task designed to measure empathy for pain. Then, over the course of 2 weeks, participants of the violent game group repeatedly played a VVG, while the control game group played a non-violent version of the same game. Subsequently, both groups completed the posttest fMRI session.", "Conditions": ["Neutral Real", "Neutral Game", "Violent Real", "Violent Game"], "TaskMetrics": ["Unpleasantness ratings"], "RestingState": "false", "TaskDuration": "5 min"}], "BehavioralTasks": [{"TaskName": "Empathy-for-pain task", "TaskDescription": "Participants either received electric stimuli themselves or saw images of the confederate indicating that he was currently receiving electric stimulation. The stimuli were either painful or perceptible but not painful.", "DesignDetails": "Participants were randomly assigned to the violent game group or the control game group. Participants first completed a pretest fMRI session, during which they performed an experimental task designed to measure empathy for pain. Then, over the course of 2 weeks, participants of the violent game group repeatedly played a VVG, while the control game group played a non-violent version of the same game. Subsequently, both groups completed the posttest fMRI session.", "Conditions": ["Self Pain", "Self No Pain", "Other Pain", "Other No Pain"], "TaskMetrics": ["Painfulness ratings", "Unpleasantness ratings"], "RestingState": "false", "TaskDuration": "20 min"}, {"TaskName": "Emotional reactivity task", "TaskDescription": "To investigate emotional reactivity to violent images, we used an affective picture paradigm. Participants were shown pictures of either neutral or violent content. Additionally, the pictures depicted either real scenes, or scenes taken from the video game participants played during the gaming sessions.", "DesignDetails": "Participants were randomly assigned to the violent game group or the control game group. Participants first completed a pretest fMRI session, during which they performed an experimental task designed to measure empathy for pain. Then, over the course of 2 weeks, participants of the violent game group repeatedly played a VVG, while the control game group played a non-violent version of the same game. Subsequently, both groups completed the posttest fMRI session.", "Conditions": ["Neutral Real", "Neutral Game", "Violent Real", "Violent Game"], "TaskMetrics": ["Unpleasantness ratings"], "RestingState": "false", "TaskDuration": "5 min"}], "id": 10791126}, {"StudyObjective": "This study examined whether perceived friendship quality was related to better mental health and lower neural stress response in young people with childhood adversity (CA).", "fMRITasks": [{"TaskName": "Montreal Imaging Stress Task", "TaskDescription": "A well-validated and widely used acute psychosocial stress paradigm for fMRI.", "DesignDetails": "The MIST is a computerised mental arithmetic task with an artificially induced failure component.", "Conditions": ["stress", "control", "rest"], "TaskMetrics": ["stress", "control", "rest"], "RestingState": "false", "TaskDuration": "5\u2005min"}], "BehavioralTasks": [{"TaskName": "Short-Form of the Childhood Trauma Questionnaire", "TaskDescription": "A measure of physical abuse, emotional abuse, physical neglect, and emotional neglect.", "DesignDetails": "The CTQ-SF is a measure of physical abuse, emotional abuse, physical neglect, and emotional neglect.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Measure of Parental Style Questionnaire", "TaskDescription": "A measure of maternal and paternal abuse, indifference, and overcontrol.", "DesignDetails": "The MOPS is a measure of maternal and paternal abuse, indifference, and overcontrol.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Alabama Parenting Questionnaire", "TaskDescription": "A measure of corporal punishment, poor parental involvement, and negative parenting.", "DesignDetails": "The APQ is a measure of corporal punishment, poor parental involvement, and negative parenting.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Mood and Feelings Questionnaire", "TaskDescription": "A measure of depressive symptoms.", "DesignDetails": "The MFQ is a measure of depressive symptoms.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Revised Children\u2019s Manifest Anxiety Scale", "TaskDescription": "A measure of physiological anxiety, worry/oversensitivity, and social concerns/concentration.", "DesignDetails": "The RCMAS is a measure of physiological anxiety, worry/oversensitivity, and social concerns/concentration.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Leyton Obsessional Inventory-Child Version", "TaskDescription": "A measure of compulsions, obsessions, and cleanliness.", "DesignDetails": "The LOI-CV is a measure of compulsions, obsessions, and cleanliness.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Behavioral Checklist", "TaskDescription": "A measure of behavioural problems.", "DesignDetails": "The BCL is a measure of behavioural problems.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Rosenberg Self-Esteem Scale", "TaskDescription": "A measure of self-esteem.", "DesignDetails": "The SES is a measure of self-esteem.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Kessler Psychological Distress Scale", "TaskDescription": "A measure of psychological distress.", "DesignDetails": "The K10 is a measure of psychological distress.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Warwick-Edinburgh Mental Well-Being Scale", "TaskDescription": "A measure of mental well-being.", "DesignDetails": "The WEMWBS is a measure of mental well-being.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "id": 10990450}, {"StudyObjective": "An Enduring Role for Hippocampal Pattern Completion in Addition to an Emergent Nonhippocampal Contribution to Holistic Episodic Retrieval after a 24\u2005h Delay", "fMRITasks": [{"TaskName": "fMRI", "TaskDescription": "We used fMRI and an experimental assay of holistic episodic memory retrieval to assess hippocampal pattern completion and its relationship to neocortical reinstatement across delay.", "DesignDetails": "We identified neocortical regions that showed differences in the BOLD activity between elements that were the cue or target of retrieval and those that were nontargets. Greater activity for closed- versus open-loops in nontarget regions was then used as a marker of holistic neocortical reinstatement.", "Conditions": ["open-loop", "delay", "no-delay", "closed-loop", "delay", "no-delay"], "TaskMetrics": ["BOLD response", "neocortical reinstatement", "hippocampal pattern completion"], "RestingState": "false", "TaskDuration": "6\u2005s"}, {"TaskName": "Behavioral analysis", "TaskDescription": "A 2\u2009\u00d7\u20092 (loop\u2009\u00d7\u2009delay) ANOVA was used for the behavioral analysis of retrieval accuracy and retrieval dependency, with the within-subject factor loop referring to whether the events formed closed- or open-loops and delay referring to whether closed- or open-loops were encoded immediately (no-delay) or 24\u2005h prior to retrieval (delay).", "DesignDetails": "The mean proportion correct (and standard deviations) and mean proportion of joint retrieval (and standard deviations) for the data and independent model at no-delay (i.e., encoded immediately prior to retrieval delay) and delay (i.e., encoded 24\u2005h prior to retrieval) for closed- and open-loops.", "Conditions": ["open-loop", "delay", "no-delay", "closed-loop", "delay", "no-delay"], "TaskMetrics": ["proportion correct", "proportion of joint retrieval", "retrieval dependency"], "RestingState": "false", "TaskDuration": "6\u2005s"}], "BehavioralTasks": [{"TaskName": "cued-recognition task", "TaskDescription": "Participants performed a six-alternative forced-choice cued-recognition task. On each trial, a cue and six potential targets were presented simultaneously on the screen. The cue was presented in the middle of the screen with the six possible targets; one target and five foils form the same category (e.g., if the target was hammer, the five foils would be other randomly selected objects from the other events, regardless of closed- vs open-loop or delay vs no-delay status) presented in two rows of three below the cue ( ). Participants had a maximum of 6\u2005s to respond with a button response that corresponded to the target position on the screen and were instructed to be as accurate as possible in the time given. The position of the correct target was randomly selected on each retrieval trial. The cue and six targets were presented until a response was made or when the maximum 6\u2005s limit was reached (M response times\u2009\u00b1\u2009SD\u2009=\u20092.86\u2005s\u2009\u00b1\u20090.42\u2005s). Missing responses (i.e., responses that fell outside the 6\u2005s response window) were treated as incorrect trials for both accuracy and dependency (M percentage of missing responses\u2009\u00b1\u2009SD\u2009=\u20093.54%).", "DesignDetails": "Each encoded pairwise association (regardless of delay or loop status) was tested in both directions (e.g., cue, location; target, person; cue, person; target, location) across two scanning runs (total retrieval trials, 360; 180 trials per run). For the open-loops, we only tested the pairwise associations that were directly encoded\u2014and not those that could potentially be inferred from overlapping nature of pairwise associations ( ;  )\u2014resulting in four retrieval trials per open-loop compared with six retrieval trials per closed-loop. The presentation order was optimized to measure the univariate BOLD activity in each of the four within-subject experimental conditions (i.e., open-loop, delay; open-loop, no-delay; closed-loop, delay; closed-loop, no-delay; optimization algorithm available at ). To avoid adaptation effects, cue\u2013target associations from the same closed- or open-loop were never presented on successive trials, and each block contained 18 null trials that each lasted 6\u2005s. In each retrieval block (or scan run), cue\u2013target associations belonging to nine closed- and open-loops encoded during the first encoding session and nine closed- and nine open-loops encoded immediately before retrieval were tested in a random order, making a total of 180 retrieval trials, in addition to the 18 null trials.", "Conditions": ["open-loop", "delay", "no-delay", "closed-loop", "delay", "no-delay"], "TaskMetrics": ["BOLD response", "neocortical reinstatement", "hippocampal pattern completion"], "RestingState": "false", "TaskDuration": "6\u2005s"}], "id": 11063816}, {"StudyObjective": "Motivated with joy or anxiety: Does approach-avoidance goal framing elicit differential reward-network activation in the brain?", "fMRITasks": [{"TaskName": "stopwatch task", "TaskDescription": "Participants were instructed that they could win or lose points during the stopwatch task depending on their performance, and their overall goal was to earn the total point of zero or larger than zero at the end of the experiments.", "DesignDetails": "Participants completed a stopwatch task (a task that was proven to be intrinsically engaging for adults; Murayama et al.,  ,  ; Sakaki et al.,  ) while being scanned in an MRI scanner. They were instructed that they could win or lose points during the stopwatch task depending on their performance, and their overall goal was to earn the total point of zero or larger than zero at the end of the experiments. They were also told that the points they would earn would have nothing to do with their monetary rewards.", "Conditions": ["approach blocks", "avoidance blocks"], "TaskMetrics": ["enjoyment", "anxiety", "disappointment", "engagement", "excitement"], "RestingState": "false", "TaskDuration": "5 s"}], "BehavioralTasks": [{"TaskName": "stopwatch task", "TaskDescription": "Participants were instructed that they could win or lose points during the stopwatch task depending on their performance, and their overall goal was to earn the total point of zero or larger than zero at the end of the experiments. They were also told that the points they would earn would have nothing to do with their monetary rewards.", "DesignDetails": "Participants completed a stopwatch task (a task that was proven to be intrinsically engaging for adults; Murayama et al.,  ,  ; Sakaki et al.,  ) while being scanned in an MRI scanner. They were instructed that they could win or lose points during the stopwatch task depending on their performance, and their overall goal was to earn the total point of zero or larger than zero at the end of the experiments. They were also told that the points they would earn would have nothing to do with their monetary rewards.", "Conditions": ["approach blocks", "avoidance blocks"], "TaskMetrics": ["enjoyment", "anxiety", "disappointment", "engagement", "excitement"], "RestingState": "false", "TaskDuration": "5 s"}], "id": 11078806}, {"StudyObjective": "Fast reproducible identification and large-scale databasing of individual functional cognitive networks", "fMRITasks": [{"TaskName": "Right hand action", "TaskDescription": "Pressing three times the left button with the left thumb button according to visual instructions", "DesignDetails": "10 trials", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "5 min"}, {"TaskName": "Vertical checkerboards", "TaskDescription": "Passive viewing of flashing vertical checkerboards", "DesignDetails": "10 trials", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "5 min"}, {"TaskName": "Pressing left button", "TaskDescription": "Pressing three times the left button according to visual instruction", "DesignDetails": "5 trials", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "5 min"}, {"TaskName": "Pressing right button", "TaskDescription": "Pressing three times the right button according to visual instruction", "DesignDetails": "5 trials", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "5 min"}, {"TaskName": "Pressing left button", "TaskDescription": "Pressing three times the left button according to auditory instruction", "DesignDetails": "5 trials", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "5 min"}, {"TaskName": "Pressing right button", "TaskDescription": "Pressing three times the right button according to auditory instruction", "DesignDetails": "5 trials", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "5 min"}, {"TaskName": "Silently reading", "TaskDescription": "Reading short visual sentences", "DesignDetails": "10 trials", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "5 min"}, {"TaskName": "Listening", "TaskDescription": "Listening to short sentences", "DesignDetails": "10 trials", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "5 min"}, {"TaskName": "Solving subtraction problems", "TaskDescription": "Solving silently visual subtraction problems", "DesignDetails": "10 trials", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "5 min"}, {"TaskName": "Solving subtraction problems", "TaskDescription": "Solving silently auditory subtraction problems", "DesignDetails": "10 trials", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "5 min"}], "BehavioralTasks": [{"TaskName": "Reading", "TaskDescription": "Reading short visual sentences", "DesignDetails": "10 trials", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "5 min"}, {"TaskName": "Listening", "TaskDescription": "Listening to short sentences", "DesignDetails": "10 trials", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "5 min"}, {"TaskName": "Solving subtraction problems", "TaskDescription": "Solving silently visual subtraction problems", "DesignDetails": "10 trials", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "5 min"}, {"TaskName": "Solving subtraction problems", "TaskDescription": "Solving silently auditory subtraction problems", "DesignDetails": "10 trials", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "5 min"}], "id": 2241626}, {"StudyObjective": "To evaluate the consistency associated with functionally localising reading- and object-sensitive areas of left occipito-temporal cortex.", "fMRITasks": [{"TaskName": "Reading", "TaskDescription": "A one-back task with four categories of visual stimuli: written words, pictures of common objects, scrambled pictures of the same objects, and consonant letter strings.", "DesignDetails": "The stimuli were divided equally into two lists, with the order counter-balanced across subjects such that 50% of subjects saw the first list of stimuli during run 1 and the remaining 50% during run 2.", "Conditions": ["words", "consonants", "objects", "scrambled objects"], "TaskMetrics": ["hit rate", "false alarm rate", "d-prime scores", "reaction times"], "RestingState": "false", "TaskDuration": "16.4 min"}], "BehavioralTasks": [{"TaskName": "1-back", "TaskDescription": "A one-back task with four categories of visual stimuli: written words, pictures of common objects, scrambled pictures of the same objects, and consonant letter strings.", "DesignDetails": "The stimuli were divided equally into two lists, with the order counter-balanced across subjects such that 50% of subjects saw the first list of stimuli during run 1 and the remaining 50% during run 2.", "Conditions": ["words", "consonants", "objects", "scrambled objects"], "TaskMetrics": ["hit rate", "false alarm rate", "d-prime scores", "reaction times"]}], "id": 2686646}, {"StudyObjective": "investigate the role of the caudate nucleus in events that violate predictions", "fMRITasks": [{"TaskName": "movement observation paradigm", "TaskDescription": "watched movies of a dancer producing the same sequences either according to the cue (88%) or not (12%)", "DesignDetails": "participants were trained to produce a sequence of whole-body movements according to auditory cues", "Conditions": ["prediction-violating movements"], "TaskMetrics": ["caudate nucleus activation"], "RestingState": "false", "TaskDuration": "one second"}, {"TaskName": "behavioral probe session", "TaskDescription": "participants watched a dancer performing according to cue, but occasionally making mistakes", "DesignDetails": "participants had to register auditory cues that determined what movement the dancer was to perform next, and watch the ensuing movements", "Conditions": ["breaches of expectation"], "TaskMetrics": ["caudate nucleus activation"], "RestingState": "false", "TaskDuration": "one second"}], "BehavioralTasks": [{"TaskName": "movement training", "TaskDescription": "participants had to conduct movement sequences, starting each movement when it was called out to them", "DesignDetails": "participants had to keep moving at a high level of accuracy and trainers would correct them verbally, and, if necessary, by showing the model-video, over the entire course of training", "Conditions": ["breaches of expectation"], "TaskMetrics": ["caudate nucleus activation"]}], "id": 3078751}, {"StudyObjective": "Parsing the neural correlates of moral cognition: ALE meta-analysis on morality, theory of mind, and empathy", "fMRITasks": [{"TaskName": "moral cognition", "TaskDescription": "Reflection of the social appropriateness of people\u2019s actions.", "DesignDetails": "Participants passively viewed or explicitly evaluated mainly textual, sometimes pictorial social scenarios with moral violations/dilemmas.", "Conditions": ["moral cognition"], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "theory of mind", "TaskDescription": "Attributing mental states to others to predict or explain their behavior.", "DesignDetails": "Participants adopted an intentional stance towards others, that is, predict their thoughts, intentions, and future actions.", "Conditions": ["theory of mind"], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "empathy", "TaskDescription": "Understanding and vicariously sharing the emotional experience of others.", "DesignDetails": "Participants understood and vicariously shared the emotional experience of others.", "Conditions": ["empathy"], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [], "id": 3445793}, {"StudyObjective": "A quantitative meta-analysis and review of motor learning in the human brain", "fMRITasks": [{"TaskName": "sensorimotor tasks", "TaskDescription": "Learning to produce new patterns of movement kinematics and/or dynamics.", "DesignDetails": "35 sensorimotor tasks", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "SRTT variants", "TaskDescription": "Learning to perform skilled sequences of button presses with minimal novel motor components.", "DesignDetails": "35 SRTT variants", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [], "id": 3555187}, {"StudyObjective": "The default modes of reading: modulation of posterior cingulate and medial prefrontal cortex connectivity associated with comprehension and task focus while reading", "fMRITasks": [{"TaskName": "Reading", "TaskDescription": "Reading is a fundamental human capacity and yet it can easily be derailed by the simple act of mind-wandering.", "DesignDetails": "Resting-state functional magnetic resonance imaging (rs-fMRI) was used to explore whether the intrinsic functional connectivity of the two key midline hubs of the default mode network (DMN)\u2014the posterior cingulate cortex (PCC) and anterior medial prefrontal cortex (aMPFC)\u2014was predictive of individual differences in reading comprehension and task focus recorded outside of the scanner.", "Conditions": [], "TaskMetrics": [], "RestingState": "true", "TaskDuration": "one hour"}, {"TaskName": "Reading", "TaskDescription": "Reading is a fundamental human capacity and yet it can easily be derailed by the simple act of mind-wandering.", "DesignDetails": "Resting-state functional magnetic resonance imaging (rs-fMRI) was used to explore whether the intrinsic functional connectivity of the two key midline hubs of the default mode network (DMN)\u2014the posterior cingulate cortex (PCC) and anterior medial prefrontal cortex (aMPFC)\u2014was predictive of individual differences in reading comprehension and task focus recorded outside of the scanner.", "Conditions": [], "TaskMetrics": [], "RestingState": "true", "TaskDuration": "one hour"}], "BehavioralTasks": [{"TaskName": "Reading", "TaskDescription": "Reading is a fundamental human capacity and yet it can easily be derailed by the simple act of mind-wandering.", "DesignDetails": "Resting-state functional magnetic resonance imaging (rs-fMRI) was used to explore whether the intrinsic functional connectivity of the two key midline hubs of the default mode network (DMN)\u2014the posterior cingulate cortex (PCC) and anterior medial prefrontal cortex (aMPFC)\u2014was predictive of individual differences in reading comprehension and task focus recorded outside of the scanner.", "Conditions": [], "TaskMetrics": []}], "id": 3825257}, {"StudyObjective": "To investigate sex differences and menstrual cycle effects in resting state functional connectivity of fronto-parietal cognitive control networks.", "fMRITasks": [{"TaskName": "Resting state fMRI", "TaskDescription": "Participants were instructed to relax and keep their eyes closed during scanning.", "DesignDetails": "The participants completed three sessions of rs-fMRI. They were instructed to relax and keep their eyes closed during scanning.", "Conditions": [], "TaskMetrics": [], "RestingState": "true", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Lexical decision task", "TaskDescription": null, "DesignDetails": null, "Conditions": [], "TaskMetrics": []}, {"TaskName": "Left-right confusion task", "TaskDescription": null, "DesignDetails": null, "Conditions": [], "TaskMetrics": []}], "id": 4110030}, {"StudyObjective": "To investigate gender differences on voice localizer scans by employing the conventional univariate analysis as well as MVPA.", "fMRITasks": [{"TaskName": "Voice localizer paradigm", "TaskDescription": "Subjects were instructed to close their eyes and passively listen to a large variety of sounds. Stimuli were presented in a simple block design and divided into vocal (20 blocks) and non-vocal (20 blocks) conditions.", "DesignDetails": "Subjects were instructed to close their eyes and passively listen to a large variety of sounds. Stimuli were presented in a simple block design and divided into vocal (20 blocks) and non-vocal (20 blocks) conditions.", "Conditions": ["Vocal", "Non-vocal"], "TaskMetrics": ["Classification accuracy"], "RestingState": "false", "TaskDuration": "8 s"}, {"TaskName": "Multivariate pattern analysis", "TaskDescription": "Multivariate pattern classification was performed on unsmoothed and non-normalized data using Matlab and in-house utility scripts.", "DesignDetails": "Multivariate pattern classification was performed on unsmoothed and non-normalized data using Matlab and in-house utility scripts.", "Conditions": ["Vocal", "Non-vocal"], "TaskMetrics": ["Classification accuracy"], "RestingState": "false", "TaskDuration": "8 s"}], "BehavioralTasks": [], "id": 4115625}, {"StudyObjective": "Investigate which brain regions are activated during HE and LE food choices, and assess in which brain regions activation varies with tastiness and individual differences in self-regulatory success.", "fMRITasks": [{"TaskName": "fMRI single food choice task", "TaskDescription": "Participants made 100 choices. In every trial, they viewed one of the study stimuli (3000 ms, choice period) and subsequently had to indicate with a button press (1500 ms, button press period) whether they wanted to eat a portion of the snack or not.", "DesignDetails": "Participants were instructed to make their choice already during the period that the image was shown. To ensure that their choices were actually made in direct response to the food pictures, the button press period was so short that it only allowed them to locate whether they had to push the left or right button. The choice trials were interspersed with a random interval (2000 and 5000 ms). At the beginning, halfway (after 50 trials) and at the end an additional baseline period of 30,000 ms was included in the task.", "Conditions": ["HE choice periods", "LE choice periods", "button press screen", "practice trial and missed trials"], "TaskMetrics": ["choice", "tastiness", "energy content"], "RestingState": "false", "TaskDuration": "30,000 ms"}, {"TaskName": "fMRI single food choice task", "TaskDescription": "Participants made 100 choices. In every trial, they viewed one of the study stimuli (3000 ms, choice period) and subsequently had to indicate with a button press (1500 ms, button press period) whether they wanted to eat a portion of the snack or not.", "DesignDetails": "Participants were instructed to make their choice already during the period that the image was shown. To ensure that their choices were actually made in direct response to the food pictures, the button press period was so short that it only allowed them to locate whether they had to push the left or right button. The choice trials were interspersed with a random interval (2000 and 5000 ms). At the beginning, halfway (after 50 trials) and at the end an additional baseline period of 30,000 ms was included in the task.", "Conditions": ["HE choice periods", "LE choice periods", "button press screen", "practice trial and missed trials"], "TaskMetrics": ["choice", "tastiness", "energy content"], "RestingState": "false", "TaskDuration": "30,000 ms"}], "BehavioralTasks": [{"TaskName": "food choice task", "TaskDescription": "Participants made 100 choices. In every trial, they viewed one of the study stimuli (3000 ms, choice period) and subsequently had to indicate with a button press (1500 ms, button press period) whether they wanted to eat a portion of the snack or not.", "DesignDetails": "Participants were instructed to make their choice already during the period that the image was shown. To ensure that their choices were actually made in direct response to the food pictures, the button press period was so short that it only allowed them to locate whether they had to push the left or right button. The choice trials were interspersed with a random interval (2000 and 5000 ms). At the beginning, halfway (after 50 trials) and at the end an additional baseline period of 30,000 ms was included in the task.", "Conditions": ["HE choice periods", "LE choice periods", "button press screen", "practice trial and missed trials"], "TaskMetrics": ["choice", "tastiness", "energy content"]}], "id": 4179768}, {"StudyObjective": "The aim of this study was to investigate the relationship between GABA concentration and fear-related BOLD responses in the insula.", "fMRITasks": [{"TaskName": "Fear provocation paradigm", "TaskDescription": "The fear provocation paradigm involved presenting still pictures of spiders, of other control animals, generally negative pictures taken from the International Affective Picture System (IAPS), and neutral pictures also obtained from the IAPS. This allowed us to produce a fear-specific contrast SPIDERS > ANIMALS and a fear-unspecific contrast IAPSnegative > IAPSneutral.", "DesignDetails": "The paradigm was designed to elicit fear-specific (pictures of spiders vs. control animals) and fear-unspecific (negative vs. neutral IAPS pictures) BOLD responses.", "Conditions": ["SPIDERS", "ANIMALS", "IAPSnegative", "IAPSneutral"], "TaskMetrics": ["BOLD responses"], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Covert task", "TaskDescription": "Participants were instructed to perform a covert task of responding (button press with right index and middle finger) whether they could detect the presence of a human in the picture (50% of the pictures).", "DesignDetails": "The tasks were presented in the scanner using Presentation (Neurobehavioral Systems, Albany, CA) and rear-projected onto a screen behind the participant's head that was visible through a mirror mounted on the RF head coil.", "Conditions": ["SPIDERS", "ANIMALS", "IAPSnegative", "IAPSneutral"], "TaskMetrics": ["BOLD responses"]}], "id": 4374765}, {"StudyObjective": "To assess whether the coupling between ALFF and FC depends on anatomical brain localization, frequency band, and pathological conditions.", "fMRITasks": [{"TaskName": "Functional connectivity", "TaskDescription": "Voxel-wise connectivity analysis was carried out using 3dTcorrMap (AFNI package, [ ]). For each voxel, Pearson correlation coefficients between each voxel and all other voxels of the brain were computed; then, after a z-Fisher transformation, these coefficients were averaged.", "DesignDetails": "Voxel-wise connectivity analysis was carried out using 3dTcorrMap (AFNI package, [ ]). For each voxel, Pearson correlation coefficients between each voxel and all other voxels of the brain were computed; then, after a z-Fisher transformation, these coefficients were averaged.", "Conditions": [], "TaskMetrics": [], "RestingState": "true", "TaskDuration": "7 minutes and 20 seconds"}, {"TaskName": "Amplitude of low frequency fluctuations", "TaskDescription": "ALFF measures voxel-wisely the total power of a given BOLD time course within the low-frequency band [ ,  ].", "DesignDetails": "ALFF measures voxel-wisely the total power of a given BOLD time course within the low-frequency band [ ,  ].", "Conditions": [], "TaskMetrics": [], "RestingState": "true", "TaskDuration": "7 minutes and 20 seconds"}], "BehavioralTasks": [], "id": 4386762}, {"StudyObjective": "Overlapping reward processes in soccer players upon scoring and winning money", "fMRITasks": [{"TaskName": "Soccer Paradigm", "TaskDescription": "Participants decide to either pass or shoot the ball via button press.", "DesignDetails": "The fMRI paradigm was programmed using in-house software. Upon being confronted with the situation, participants decided to either pass or shoot the ball via button press.", "Conditions": ["pass", "shoot"], "TaskMetrics": ["choice", "choice (parametrically modulated via reward probability (RP))", "positive feedback (goal) after a pass", "positive feedback (goal) after a shot", "negative feedback (miss)", "missed response", "movement regressors"], "RestingState": "false", "TaskDuration": "34 minutes"}, {"TaskName": "Monetary Paradigm", "TaskDescription": "Participants guessed under which out of one to four randomly shown boxes a circle was hidden, leading to winning probabilities ranging from 25% to 100%.", "DesignDetails": "In the previously published monetary incentive paradigm, participants guessed under which out of one to four randomly shown boxes a circle was hidden, leading to winning probabilities ranging from 25% to 100%.", "Conditions": ["win", "no win"], "TaskMetrics": ["choice", "choice (parametrically modulated via reward probability (RP))", "positive feedback (win)", "negative feedback (no win)", "missed response", "movement regressors"], "RestingState": "false", "TaskDuration": "32 minutes"}], "BehavioralTasks": [{"TaskName": "Personality Questionnaires", "TaskDescription": "Each participant handed in the completed personality questionnaires (HEXACO PI-R 200 and SVO, previously distributed) at the scanning appointment.", "DesignDetails": "Personality Questionnaires were handed out to the participants to prevent the soccer players from recognizing the egoism component of the study and thus influencing the decision making process of the individuals.", "Conditions": [], "TaskMetrics": []}], "id": 4398371}, {"StudyObjective": "fMRI measurements of amygdala activation are confounded by stimulus correlated signal fluctuations in nearby veins draining distant brain regions", "fMRITasks": [{"TaskName": "emotional matching paradigm", "TaskDescription": "Subjects were shown triplets of geometric shapes (as neutral stimuli) and of threatening scenes as well as fearful faces (as emotional conditions) presented in alternating blocks of neutral and emotional stimuli.", "DesignDetails": "The task-fMRI experiment comprised 1420 volumes.", "Conditions": ["neutral stimuli", "emotional conditions"], "TaskMetrics": ["Faces \u2013 Forms", "IAPS Pictures \u2013 Forms"], "RestingState": "true", "TaskDuration": "1420 volumes"}], "BehavioralTasks": [], "id": 4440210}, {"StudyObjective": "Neural Correlates of Attentional Flexibility during Approach and Avoidance Motivation", "fMRITasks": [{"TaskName": "Composite Letter Task", "TaskDescription": "Participants were presented with a large letter composed of several smaller letters (e.g., a T made of smaller Ls), and instructed to indicate with a button press whether the stimulus contained a T or an H. Each composite stimulus contained only one target letter (T or H), which was presented as either the large letter (global target) or the small letters (local target).", "DesignDetails": "Participants completed a modified version of the composite letter task, in which the ratio of global to local targets changes across blocks of trials.", "Conditions": ["Approach", "Avoidance", "Neutral"], "TaskMetrics": ["Reaction time"], "RestingState": "false", "TaskDuration": "approximately 27 minutes"}], "BehavioralTasks": [{"TaskName": "Stop-signal Task", "TaskDescription": "Participants were instructed to stop their response if a stop signal appeared.", "DesignDetails": "Participants completed a stop-signal task involving inhibitory control.", "Conditions": [], "TaskMetrics": ["Reaction time"]}, {"TaskName": "Cognitive Reappraisal Task", "TaskDescription": "Participants were instructed to reappraise the emotional content of a sentence.", "DesignDetails": "Participants completed a cognitive reappraisal task involving emotion regulation.", "Conditions": [], "TaskMetrics": ["Reaction time"]}], "id": 4441475}, {"StudyObjective": "Shaped by the Past: The Default Mode Network Supports Cognition that Is Independent of Immediate Perceptual Input", "fMRITasks": [{"TaskName": "1-back", "TaskDescription": "Participants had to encode the identity of shapes presented on screen and when prompted by a coloured slide to respond based on the position of a specific target shape on the prior trial.", "DesignDetails": "Participants alternated between two tasks. One task involved observing non-coloured shapes presented at fixation waiting for the presentation of a coloured slide at which point they would indicate using a button press which side of the fixation cross a target shape was (0-back). In the other task participants had to encode the identity of shapes presented on screen and when prompted by a coloured slide to respond based on the position of a specific target shape on the prior trial (1-back).", "Conditions": ["0-back", "1-back"], "TaskMetrics": ["BOLD activity in regions of the medial prefrontal cortex and posterior cingulate cortex"], "RestingState": "false", "TaskDuration": "~35 minutes"}, {"TaskName": "0-back", "TaskDescription": "Participants either made decisions about the location of shapes as they are presented on screen or with respect to their location on the prior trial.", "DesignDetails": "Participants alternated between two tasks. One task involved observing non-coloured shapes presented at fixation waiting for the presentation of a coloured slide at which point they would indicate using a button press which side of the fixation cross a target shape was (0-back). In the other task participants had to encode the identity of shapes presented on screen and when prompted by a coloured slide to respond based on the position of a specific target shape on the prior trial (1-back).", "Conditions": ["0-back", "1-back"], "TaskMetrics": ["BOLD activity in regions of the medial prefrontal cortex and posterior cingulate cortex"], "RestingState": "false", "TaskDuration": "~35 minutes"}], "BehavioralTasks": [{"TaskName": "Experience sampling", "TaskDescription": "Participants rated their task focus on a scale from 0 (completely off task) to 9 (completely on task).", "DesignDetails": "Analysis of the experience sampling data recorded in the behavioural experiment (top right graph), demonstrated that participants rated their task focus on a scale from 0 (completely off task) to 9 (completely on task).", "Conditions": ["0-back", "1-back"], "TaskMetrics": ["Participants\u2019 responses to the probes in each condition is shown."]}], "id": 4488375}, {"StudyObjective": "To investigate the neural substrate of typewriting Japanese words and to detect the difference between the neural substrate of typewriting and handwriting.", "fMRITasks": [{"TaskName": "Typing task", "TaskDescription": "A word was presented on a screen and the subject was instructed to type the visually presented word on a keyboard.", "DesignDetails": "The typing task required the subjects to type the letters corresponding to the red colored keys.", "Conditions": ["typing task", "reading task", "typing-movement task"], "TaskMetrics": ["typing speed", "left-hand and right-hand usage"], "RestingState": "false", "TaskDuration": "20-s"}, {"TaskName": "Reading task", "TaskDescription": "A picture of a book, which indicated that the subject should read, was presented for 2000 ms followed by six different words presented sequentially over a period of 18000 ms with no interval and subjects were instructed to read each word silently.", "DesignDetails": "The word list for the reading task was the same as that used in the writing task, and no word was shown more than once in the experiment.", "Conditions": ["reading task"], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "20-s"}, {"TaskName": "Typing-movement task", "TaskDescription": "In the typing-movement task, a double circle (\u25ce) was presented for 2000-ms periods with a blank screen presented for 1000 ms between each period, and subjects were instructed to type randomly with both hands at a pre-learned speed during the presentation of the double circle.", "DesignDetails": "The stimulus duration in the typing-movement task was longer than that in the typing-movement task to control for the difference in the time taken to complete these two tasks.", "Conditions": ["typing-movement task"], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "20-s"}, {"TaskName": "Writing task", "TaskDescription": "Subjects were instructed to write words with their right index finger in the air.", "DesignDetails": "The word list for this task was the same as that used in the typing condition.", "Conditions": ["writing task"], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "20-s"}, {"TaskName": "Reading task", "TaskDescription": "A picture of a book, which indicated that the subject should read, was presented for 2000 ms followed by six different words presented sequentially over a period of 18000 ms with no interval, and subjects were instructed to read each word silently.", "DesignDetails": "The word list for the reading task was the same as that used in the writing task, and no word was shown more than once in the experiment.", "Conditions": ["reading task"], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "20-s"}, {"TaskName": "Writing-movement task", "TaskDescription": "In the writing-movement task, a double circle (\u25ce) was presented and subjects were instructed to move their index finger randomly at a pre-learned speed, in the way they do when they write in the air.", "DesignDetails": "The stimulus duration in the writing-movement task was longer than that in the typing-movement task to control for the difference in the time taken to complete these two tasks.", "Conditions": ["writing-movement task"], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "20-s"}], "BehavioralTasks": [{"TaskName": "Typing task", "TaskDescription": "A word was presented on a screen and the subject was instructed to type the visually presented word on a keyboard.", "DesignDetails": "The typing task required the subjects to type the letters corresponding to the red colored keys.", "Conditions": ["typing task", "reading task", "typing-movement task"], "TaskMetrics": ["typing speed", "left-hand and right-hand usage"], "RestingState": "false", "TaskDuration": "20-s"}, {"TaskName": "Reading task", "TaskDescription": "A picture of a book, which indicated that the subject should read, was presented for 2000 ms followed by six different words presented sequentially over a period of 18000 ms with no interval and subjects were instructed to read each word silently.", "DesignDetails": "The word list for the reading task was the same as that used in the writing task, and no word was shown more than once in the experiment.", "Conditions": ["reading task"], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "20-s"}, {"TaskName": "Typing-movement task", "TaskDescription": "In the typing-movement task, a double circle (\u25ce) was presented for 2000-ms periods with a blank screen presented for 1000 ms between each period, and subjects were instructed to type randomly with both hands at a pre-learned speed during the presentation of the double circle.", "DesignDetails": "The stimulus duration in the typing-movement task was longer than that in the typing-movement task to control for the difference in the time taken to complete these two tasks.", "Conditions": ["typing-movement task"], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "20-s"}, {"TaskName": "Writing task", "TaskDescription": "Subjects were instructed to write words with their right index finger in the air.", "DesignDetails": "The word list for this task was the same as that used in the typing condition.", "Conditions": ["writing task"], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "20-s"}, {"TaskName": "Reading task", "TaskDescription": "A picture of a book, which indicated that the subject should read, was presented for 2000 ms followed by six different words presented sequentially over a period of 18000 ms with no interval, and subjects were instructed to read each word silently.", "DesignDetails": "The word list for the reading task was the same as that used in the writing task, and no word was shown more than once in the experiment.", "Conditions": ["reading task"], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "20-s"}, {"TaskName": "Writing-movement task", "TaskDescription": "In the writing-movement task, a double circle (\u25ce) was presented and subjects were instructed to move their index finger randomly at a pre-learned speed, in the way they do when they write in the air.", "DesignDetails": "The stimulus duration in the writing-movement task was longer than that in the typing-movement task to control for the difference in the time taken to complete these two tasks.", "Conditions": ["writing-movement task"], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "20-s"}], "id": 4517759}, {"StudyObjective": "To determine how the level of physical fitness (measured as CRF) and PA (measured via accelerometer) are related to functional brain health measured as SD .", "fMRITasks": [{"TaskName": "Resting state fMRI", "TaskDescription": "We collected resting functional magnetic resonance BOLD data from 100 healthy older participants (60\u201380 years).", "DesignDetails": "We modeled the relations between whole-brain voxel-wise SD , CRF, and PA (mean daily sedentary time, time spent in LI-PA, and MV-PA) within a multivariate partial least squares framework.", "Conditions": [], "TaskMetrics": ["SD"], "RestingState": "true", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Physical activity assessment", "TaskDescription": "Participants were instructed to wear the GT3X ActiGraph accelerometer (ActiGraph; Pensacola, Florida) for 7 consecutive days on an elastic belt on the left (non-dominant) hip during all waking hours, except for when bathing or swimming.", "DesignDetails": "We collected PA and CRF data from 150 community-dwelling healthy older adults (51 males).", "Conditions": [], "TaskMetrics": ["PA"]}, {"TaskName": "Cardiorespiratory fitness assessment", "TaskDescription": "All participants obtained physician's approval to engage in cardiorespiratory fitness (CRF) testing.", "DesignDetails": "CRF was defined as peak oxygen consumption [ml/kg/min], measured with indirect calorimetry during a modified Balke graded maximal exercise test on a motor-driven treadmill test.", "Conditions": [], "TaskMetrics": ["CRF"]}], "id": 4526228}, {"StudyObjective": "To investigate facial affect processing and the processing of one\u2019s own face through measures of emotion identification, functional magnetic resonance imaging (fMRI) and eyetracking.", "fMRITasks": [{"TaskName": "implicit emotion processing task", "TaskDescription": "Participants were presented with each stimulus twice in a pseudorandom fashion, resulting in a total of 16 presentations of each emotion over two runs.", "DesignDetails": "In the implicit task, participants were presented with each stimulus twice in a pseudorandom fashion, resulting in a total of 16 presentations of each emotion over two runs.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "explicit emotion identification task", "TaskDescription": "Participants were shown each stimulus once, resulting in eight presentations per emotion over one run.", "DesignDetails": "In the explicit task, participants were shown each stimulus once, resulting in eight presentations per emotion over one run.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "emotion identification task", "TaskDescription": "Participants were asked to identify the emotion displayed in the previous face from a list containing all of the emotions.", "DesignDetails": "Participants were asked to identify the emotion displayed in the previous face from a list containing all of the emotions.", "Conditions": [], "TaskMetrics": ["rate of emotion identification errors"]}], "id": 4530666}, {"StudyObjective": "To investigate how the neural processing for understanding a gift\u2019s social meaning is modulated by preferences for the giver.", "fMRITasks": [{"TaskName": "Gift Judgement Task", "TaskDescription": "Participants were asked to judge the value of gifts from two male acquaintances they knew in real life: for each female participant, one male giver was preferred, while she was indifferent toward the other giver (i.e., the \u201cliked\u201d and \u201cuninteresting\u201d givers). The social meaning of the gift (i.e., gift type) was either \u201cromantic\u201d or \u201cnon-romantic.\u201d", "DesignDetails": "The task was conducted in an event-related design. Six trials from either the liked or the uninteresting male acquaintance were combined in a set. Each set contained pseudo-randomized four target trials (judgments of romantic and non-romantic gifts) mixed with two control trials.", "Conditions": ["Liked giver", "Uninteresting giver"], "TaskMetrics": ["Gift attractiveness", "Reaction time"], "RestingState": "false", "TaskDuration": "30 min"}], "BehavioralTasks": [{"TaskName": "Gift Attractiveness Rating", "TaskDescription": "Participants rated the attractiveness of the gifts on a 9-point scale, where 1 is the least attractive, 9 is the most attractive.", "DesignDetails": "The gift attractiveness showed significant main effects of both the giver and gift type (two-way repeated measures ANOVA, giver, F = 458.50, p < 0.001; gift type, F = 7.91, p < 0.01, ). The interaction between these two factors was also significant (F = 8.34, p < 0.01).", "Conditions": ["Liked giver", "Uninteresting giver"], "TaskMetrics": ["Gift attractiveness"]}, {"TaskName": "Reaction Time", "TaskDescription": "Participants were asked to judge the value of gifts on a 9-point scale, where 1 is the least attractive, 9 is the most attractive.", "DesignDetails": "The mean reaction time (RT) showed significant main effect of giver but not the gift type (two-way repeated measures ANOVA, giver, F = 8.67, p < 0.01; gift type: F = 0.09, p = 0.77, ). The interaction between these factors was not significant (F = 1.64, p = 0.21).", "Conditions": ["Liked giver", "Uninteresting giver"], "TaskMetrics": ["Reaction time"]}], "id": 4547715}, {"StudyObjective": "To study the underlying neural processes of humor by examining brain hemodynamic activity during viewing and re-viewing of comedy movies.", "fMRITasks": [{"TaskName": "fMRI scanning", "TaskDescription": "Subjects were presented with three short silent movie clips twice, in an order that was randomized across subjects, during 3T fMRI with a 32-channel head coil.", "DesignDetails": "The movie clips were taken from comedy-genre movies \u201cThe Circus\u201d and \u201cCity Lights\u201d, directed by Charles Chaplin and produced by Charles Chaplin Productions in 1928 and 1931, respectively.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "3T"}, {"TaskName": "Behavioral control experiment", "TaskDescription": "Subjects viewed the movie clips twice and rated their self-experienced humorousness on both views.", "DesignDetails": null, "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Self-reported humorousness ratings", "TaskDescription": "Subjects were asked to recall and rate, on a Likert scale running from 1 to 10, once every 15 seconds, the degree of humorousness that they had experienced due to the humorous events depicted in the movies.", "DesignDetails": null, "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "id": 4914983}, {"StudyObjective": "The human Brainnetome Atlas: A New Brain Atlas Based on Connectional Architecture", "fMRITasks": [{"TaskName": "Resting-state functional MRI", "TaskDescription": "To map the whole-brain resting-state connectivity pattern for each atlas subregion, we resampled each subregion (thresholded at 50% probability) at the 2 mm resolution of the resting-state data and computed its average time series per subject. A functional connectivity map was then provided by the Pearson's correlation coefficient between the mean time series of each subregion and that of each voxel in the whole brain.", "DesignDetails": "To map the whole-brain resting-state connectivity pattern for each atlas subregion, we resampled each subregion (thresholded at 50% probability) at the 2 mm resolution of the resting-state data and computed its average time series per subject. A functional connectivity map was then provided by the Pearson's correlation coefficient between the mean time series of each subregion and that of each voxel in the whole brain.", "Conditions": [], "TaskMetrics": [], "RestingState": "true", "TaskDuration": null}, {"TaskName": "Diffusion MRI", "TaskDescription": "To map the whole-brain anatomical connectivity pattern for each subregion of the atlas, we performed probabilistic tractography by drawing 5000 samples from each voxel in each subregion (thresholded at 25% probability) to all the other voxels of the whole brain.", "DesignDetails": "To map the whole-brain anatomical connectivity pattern for each subregion of the atlas, we performed probabilistic tractography by drawing 5000 samples from each voxel in each subregion (thresholded at 25% probability) to all the other voxels of the whole brain.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "BrainMap Database", "TaskDescription": "The functional characterizations of each subregion in the Brainnetome Atlas are illustrated based on their behavioral domain and paradigm class meta data labels following the BrainMap taxonomy.", "DesignDetails": "The functional characterizations of each subregion in the Brainnetome Atlas are illustrated based on their behavioral domain and paradigm class meta data labels following the BrainMap taxonomy.", "Conditions": [], "TaskMetrics": []}], "id": 4961028}, {"StudyObjective": "An individual differences analysis of the neurocognitive architecture of the semantic system at rest", "fMRITasks": [{"TaskName": "Synonyms Task", "TaskDescription": "Participants had 1 min to generate as many unique words as possible belonging to a semantic category (category fluency) or starting with a specific letter (letter fluency).", "DesignDetails": "Verbal Fluency (from Cambridge Semantic Battery; ( ,  ), participants had 1 min to generate as many unique words as possible belonging to a semantic category (category fluency) or starting with a specific letter (letter fluency).", "Conditions": ["high frequency items", "low frequency items", "high imageability items", "low imageability items"], "TaskMetrics": ["accuracy", "reaction time"], "RestingState": "true", "TaskDuration": "1 min"}, {"TaskName": "Fluency Task", "TaskDescription": "The Fluency Task required participants to generate words starting with a particular letter or category name.", "DesignDetails": "Fluency Task (from Cambridge Semantic Battery; ( ,  ), participants had 1 min to generate as many unique words as possible belonging to a semantic category (category fluency) or starting with a specific letter (letter fluency).", "Conditions": ["Category fluency", "Letter fluency"], "TaskMetrics": ["number of correct words generated per minute"], "RestingState": "true", "TaskDuration": "1 min"}], "BehavioralTasks": [{"TaskName": "Synonyms Task", "TaskDescription": "Participants had 1 min to generate as many unique words as possible belonging to a semantic category (category fluency) or starting with a specific letter (letter fluency).", "DesignDetails": "Verbal Fluency (from Cambridge Semantic Battery; ( ,  ), participants had 1 min to generate as many unique words as possible belonging to a semantic category (category fluency) or starting with a specific letter (letter fluency).", "Conditions": ["high frequency items", "low frequency items", "high imageability items", "low imageability items"], "TaskMetrics": ["accuracy", "reaction time"], "RestingState": "true", "TaskDuration": "1 min"}, {"TaskName": "Fluency Task", "TaskDescription": "The Fluency Task required participants to generate words starting with a particular letter or category name.", "DesignDetails": "Fluency Task (from Cambridge Semantic Battery; ( ,  ), participants had 1 min to generate as many unique words as possible belonging to a semantic category (category fluency) or starting with a specific letter (letter fluency).", "Conditions": ["Category fluency", "Letter fluency"], "TaskMetrics": ["number of correct words generated per minute"], "RestingState": "true", "TaskDuration": "1 min"}], "id": 5090046}, {"StudyObjective": "To quantitatively assess the nature and extent of overlap between the subjective value network (SVN) and default mode network (DMN) in the human brain.", "fMRITasks": [{"TaskName": "fMRI", "TaskDescription": "Conducted a series of coordinate-based meta-analyses (CBMA) of results from 466 functional magnetic resonance imaging experiments on task-negative or subjective value-related activations in the human brain.", "DesignDetails": "Conducted CBMA using the activation likelihood estimation (ALE) method.", "Conditions": ["Task-negative", "Subjective value-related"], "TaskMetrics": ["Activation likelihood estimate"], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [], "id": 5243799}, {"StudyObjective": "The role of the hippocampus in generalizing configural relationships", "fMRITasks": [{"TaskName": "Generalization Test", "TaskDescription": "Participants were tested on their ability to generalize what they had learned.", "DesignDetails": "Participants were presented with a set of wall texture configurations and were required to select the rewarded building.", "Conditions": [], "TaskMetrics": ["Proportion of correct responses"], "RestingState": "false", "TaskDuration": "12"}, {"TaskName": "Learning Phase", "TaskDescription": "Participants learned a set of visual discriminations via trial-and-error.", "DesignDetails": "Participants were required to learn not only which combination of textures was rewarded but also which spatial arrangement of textures was rewarded.", "Conditions": [], "TaskMetrics": ["Learning curves"], "RestingState": "false", "TaskDuration": "48"}], "BehavioralTasks": [{"TaskName": "Generalization Test", "TaskDescription": "Participants were tested on their ability to generalize what they had learned.", "DesignDetails": "Participants were presented with a set of wall texture configurations and were required to select the rewarded building.", "Conditions": [], "TaskMetrics": ["Proportion of correct responses"], "RestingState": "false", "TaskDuration": "12"}, {"TaskName": "Learning Phase", "TaskDescription": "Participants learned a set of visual discriminations via trial-and-error.", "DesignDetails": "Participants were required to learn not only which combination of textures was rewarded but also which spatial arrangement of textures was rewarded.", "Conditions": [], "TaskMetrics": ["Learning curves"], "RestingState": "false", "TaskDuration": "48"}], "id": 5324609}, {"StudyObjective": "To investigate the behavioral and neural correlates of social norm processing in both adolescents and adults, using a new instrument: the revised Social Norm Processing Task (SNPT-R).", "fMRITasks": [{"TaskName": "Intentional norm violations versus neutral stories", "TaskDescription": "Reading stories describing intentional violations of social norms, in comparison to reading neutral stories.", "DesignDetails": "Reading stories describing intentional violations of social norms, in comparison to reading neutral stories.", "Conditions": ["Intentional norm violations", "Neutral stories"], "TaskMetrics": ["Activation in the paracingulate gyrus, superior frontal gyrus and frontal pole", "Activation in the left amygdala"], "RestingState": "false", "TaskDuration": "8 min 44 s"}, {"TaskName": "Unintentional norm violations versus neutral stories", "TaskDescription": "Reading stories describing unintentional violations of social norms, in comparison to reading neutral stories.", "DesignDetails": "Reading stories describing unintentional violations of social norms, in comparison to reading neutral stories.", "Conditions": ["Unintentional norm violations", "Neutral stories"], "TaskMetrics": ["Activation in the left superior frontal gyrus, left middle frontal gyrus, left frontal pole, left paracingulate gyrus and right superior frontal gyrus"], "RestingState": "false", "TaskDuration": "8 min 44 s"}, {"TaskName": "Intentional versus unintentional norm violations", "TaskDescription": "Reading stories describing intentional and unintentional violations of social norms, in comparison to reading neutral stories.", "DesignDetails": "Reading stories describing intentional and unintentional violations of social norms, in comparison to reading neutral stories.", "Conditions": ["Intentional norm violations", "Unintentional norm violations"], "TaskMetrics": ["Activation in the left orbitofrontal cortex, left paracingulate gyrus and subcallosal cortex", "Activation in the right postcentral gyrus and right middle frontal gyrus", "Activation in the left lateral occipital cortex and the left superior parietal lobule"], "RestingState": "false", "TaskDuration": "8 min 44 s"}], "BehavioralTasks": [{"TaskName": "Behavioral ratings of inappropriateness and embarrassment", "TaskDescription": "Participants rated the stories on embarrassment and inappropriateness.", "DesignDetails": "Participants rated the stories on embarrassment and inappropriateness.", "Conditions": ["Intentional norm violations", "Unintentional norm violations", "Neutral stories"], "TaskMetrics": ["Ratings of inappropriateness and embarrassment"]}], "id": 5404760}, {"StudyObjective": "The Impact of Carotid Artery Stenting on Cerebral Perfusion, Functional Connectivity, and Cognition in Severe Asymptomatic Carotid Stenosis Patients", "fMRITasks": [{"TaskName": "pASL MRI", "TaskDescription": "pASL perfusion images were collected using Q2TIPS II technique.", "DesignDetails": "TR\u2009=\u20092,500\u2009ms, TE\u2009=\u200911\u2009ms, FOV\u2009=\u2009240\u2009mm\u2009\u00d7\u2009240\u2009mm, matrix\u2009=\u200964\u2009\u00d7\u200964, FA\u2009=\u200990\u00b0, and slice thickness\u2009=\u20096\u2009mm.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "R-fMRI", "TaskDescription": "Resting-state functional MRI preprocessing was performed with Data Processing Assistant for Resting-State fMRI (DPABI 2.1).", "DesignDetails": "Repetition time\u2009=\u20092,000\u2009ms, echo time\u2009=\u200930\u2009ms, flip angle\u2009=\u200990\u00b0, number of slices\u2009=\u200933, slice thickness\u2009=\u20093.8\u2009mm, gap\u2009=\u20091\u2009mm, data matrix\u2009=\u200964\u2009\u00d7\u200964, and field of view\u2009=\u2009240\u2009mm\u2009\u00d7\u2009240\u2009mm.", "Conditions": [], "TaskMetrics": [], "RestingState": "true", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "MMSE", "TaskDescription": "The Montreal Cognitive Assessment Beijing Version was used to assess the global cognition.", "DesignDetails": null, "Conditions": [], "TaskMetrics": ["MMSE"]}, {"TaskName": "Verbal Memory Test", "TaskDescription": "The Verbal Memory test was used to evaluate the memory and verbal learning ability.", "DesignDetails": null, "Conditions": [], "TaskMetrics": ["Verbal Memory Test"]}, {"TaskName": "Digit Symbol Test", "TaskDescription": "In the Digit Symbol Test, subjects were required to translate numbers to symbols in a given time and correct translations within 90\u2009s were recorded.", "DesignDetails": null, "Conditions": [], "TaskMetrics": ["Digit Symbol Test"]}, {"TaskName": "Rey Auditory Verbal Learning Test", "TaskDescription": "The Rey Auditory Verbal Learning Test was used to evaluate the memory and verbal learning ability.", "DesignDetails": null, "Conditions": [], "TaskMetrics": ["Rey Auditory Verbal Learning Test"]}, {"TaskName": "Digit Span Test", "TaskDescription": "In the Digit Span Test, participants were required to repeat the orally presented lists of numbers, beginning with a two-number sequence, and each correct performance was followed by one additional number.", "DesignDetails": null, "Conditions": [], "TaskMetrics": ["Digit Span Test"]}], "id": 5552726}, {"StudyObjective": "Predictive processing increases intelligibility of acoustically distorted speech: Behavioral and neural correlates", "fMRITasks": [{"TaskName": "fMRI experiment", "TaskDescription": "The fMRI experiment was divided into two 19\u2010min functional runs and one 6\u2010min anatomical run at the end of the scanning session. Each functional run consisted of 9 D\u2010I\u2010D stimulus sets, each of which comprised three blocks of six sentences (see Figure\u00a0 ). The blocks were 22 or 24\u00a0s in duration. To prevent an overlap between the blood oxygenation level dependent (BOLD) responses elicited by each sentence block, the blocks were separated by periods of 16\u00a0s without auditory stimulation. Subjects were instructed to listen attentively to the sentences, to maintain their gaze on a central fixation cross, and to avoid moving during the duration of the experiment. After 1\u00a0s following the end of each D\u2010I\u2010D stimulus set, a question appeared on the screen for 5\u00a0s prompting the subject to indicate by a button press (yes/no) whether the distorted sentences were easier to understand when presented after the intact sentences. Half of the subjects responded with the right and the other half with the left hand. The stimuli were presented using Presentation software (Neurobehavioral Systems,  ,  ), and the fixation cross and the visual prompt were projected to a mirror mounted on the head coil. The sentences were delivered as a monophonic signal to the subject's ears through MR\u2010compatible insertable earphones (Sensimetrics Corporation, Model S14, Malden, Massachusetts, USA,  ). Scan noise was attenuated by dense foam padding around the ears and head coil. Prior to the fMRI scanning, the subject was told that the auditory stimulation would include distorted and intact sentences, and a D\u2010I\u2010D stimulus set was presented to the subject on a computer screen to demonstrate the experiment. During a trial run before the experiment, the subject was presented with an intact and a distorted sentence during scanning, and the sound intensity of the sentences was adjusted to be both comfortable and loud enough to be heard over the scanner noise (the sound intensity averaged over subjects was 75\u00a0dB SPL).", "DesignDetails": "The fMRI experiment was divided into two 19\u2010min functional runs and one 6\u2010min anatomical run at the end of the scanning session. Each functional run consisted of 9 D\u2010I\u2010D stimulus sets, each of which comprised three blocks of six sentences (see Figure\u00a0 ). The blocks were 22 or 24\u00a0s in duration. To prevent an overlap between the blood oxygenation level dependent (BOLD) responses elicited by each sentence block, the blocks were separated by periods of 16\u00a0s without auditory stimulation. Subjects were instructed to listen attentively to the sentences, to maintain their gaze on a central fixation cross, and to avoid moving during the duration of the experiment. After 1\u00a0s following the end of each D\u2010I\u2010D stimulus set, a question appeared on the screen for 5\u00a0s prompting the subject to indicate by a button press (yes/no) whether the distorted sentences were easier to understand when presented after the intact sentences. Half of the subjects responded with the right and the other half with the left hand. The stimuli were presented using Presentation software (Neurobehavioral Systems,  ,  ), and the fixation cross and the visual prompt were projected to a mirror mounted on the head coil. The sentences were delivered as a monophonic signal to the subject's ears through MR\u2010compatible insertable earphones (Sensimetrics Corporation, Model S14, Malden, Massachusetts, USA,  ). Scan noise was attenuated by dense foam padding around the ears and head coil. Prior to the fMRI scanning, the subject was told that the auditory stimulation would include distorted and intact sentences, and a D\u2010I\u2010D stimulus set was presented to the subject on a computer screen to demonstrate the experiment. During a trial run before the experiment, the subject was presented with an intact and a distorted sentence during scanning, and the sound intensity of the sentences was adjusted to be both comfortable and loud enough to be heard over the scanner noise (the sound intensity averaged over subjects was 75\u00a0dB SPL).", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "22 or 24\u00a0s"}, {"TaskName": "Behavioral experiment", "TaskDescription": "In the behavioral measurements, the subject was presented with 15 D\u2010I\u2010D stimulus sets. Each set comprised one block of seven distorted sentences, followed by a block of five intact sentences (a subset of the previous seven), which was followed by the same seven distorted sentences as in the first block. The presentation order of the sentences was the same in each case (notwithstanding sentence omissions in the second block). Two of the sentences were only presented in the distorted form to investigate the effect of repetition on the intelligibility of the distorted sentences. Following the presentation of each sentence, the subject used a keypad to type what he/she had heard. The experiment began with a presentation of an additional stimulus set during which the subject was familiarized with the experiment. The experiment was carried out in a soundproofed listening booth, and the stimuli were delivered as a monophonic signal to the subject's ears through Sennheiser HD650 headphones. Sound intensity of the stimuli was set at 70\u00a0dB sound pressure level (SPL).", "DesignDetails": "In the behavioral measurements, the subject was presented with 15 D\u2010I\u2010D stimulus sets. Each set comprised one block of seven distorted sentences, followed by a block of five intact sentences (a subset of the previous seven), which was followed by the same seven distorted sentences as in the first block. The presentation order of the sentences was the same in each case (notwithstanding sentence omissions in the second block). Two of the sentences were only presented in the distorted form to investigate the effect of repetition on the intelligibility of the distorted sentences. Following the presentation of each sentence, the subject used a keypad to type what he/she had heard. The experiment began with a presentation of an additional stimulus set during which the subject was familiarized with the experiment. The experiment was carried out in a soundproofed listening booth, and the stimuli were delivered as a monophonic signal to the subject's ears through Sennheiser HD650 headphones. Sound intensity of the stimuli was set at 70\u00a0dB sound pressure level (SPL).", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "22 or 24\u00a0s"}], "BehavioralTasks": [{"TaskName": "Behavioral experiment", "TaskDescription": "In the behavioral measurements, the subject was presented with 15 D\u2010I\u2010D stimulus sets. Each set comprised one block of seven distorted sentences, followed by a block of five intact sentences (a subset of the previous seven), which was followed by the same seven distorted sentences as in the first block. The presentation order of the sentences was the same in each case (notwithstanding sentence omissions in the second block). Two of the sentences were only presented in the distorted form to investigate the effect of repetition on the intelligibility of the distorted sentences. Following the presentation of each sentence, the subject used a keypad to type what he/she had heard. The experiment began with a presentation of an additional stimulus set during which the subject was familiarized with the experiment. The experiment was carried out in a soundproofed listening booth, and the stimuli were delivered as a monophonic signal to the subject's ears through Sennheiser HD650 headphones. Sound intensity of the stimuli was set at 70\u00a0dB sound pressure level (SPL).", "DesignDetails": "In the behavioral measurements, the subject was presented with 15 D\u2010I\u2010D stimulus sets. Each set comprised one block of seven distorted sentences, followed by a block of five intact sentences (a subset of the previous seven), which was followed by the same seven distorted sentences as in the first block. The presentation order of the sentences was the same in each case (notwithstanding sentence omissions in the second block). Two of the sentences were only presented in the distorted form to investigate the effect of repetition on the intelligibility of the distorted sentences. Following the presentation of each sentence, the subject used a keypad to type what he/she had heard. The experiment began with a presentation of an additional stimulus set during which the subject was familiarized with the experiment. The experiment was carried out in a soundproofed listening booth, and the stimuli were delivered as a monophonic signal to the subject's ears through Sennheiser HD650 headphones. Sound intensity of the stimuli was set at 70\u00a0dB sound pressure level (SPL).", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "22 or 24\u00a0s"}], "id": 5607552}, {"StudyObjective": "Increased engagement of the cognitive control network associated with music training in children during an fMRI Stroop task", "fMRITasks": [{"TaskName": "Color-Word Stroop task", "TaskDescription": "Playing a musical instrument engages various sensorimotor processes and draws on cognitive capacities collectively termed executive functions. However, while music training is believed to associated with enhancements in certain cognitive and language abilities, studies that have explored the specific relationship between music and executive function have yielded conflicting results.", "DesignDetails": "Playing a musical instrument engages various sensorimotor processes and draws on cognitive capacities collectively termed executive functions. However, while music training is believed to associated with enhancements in certain cognitive and language abilities, studies that have explored the specific relationship between music and executive function have yielded conflicting results.", "Conditions": ["music", "sports", "control"], "TaskMetrics": ["accuracy", "response time"], "RestingState": "false", "TaskDuration": "240s"}, {"TaskName": "Hearts and Flowers task", "TaskDescription": "The task required participants to press a response button that is either on the same side (congruent) or opposite side (incongruent) of an image. When children saw an image of a heart, they were instructed to press the corresponding directional arrow button on a keyboard. When children saw an image of a flower, they were instructed to press the opposite directional arrow button on the keyboard.", "DesignDetails": "The task required participants to press a response button that is either on the same side (congruent) or opposite side (incongruent) of an image. When children saw an image of a heart, they were instructed to press the corresponding directional arrow button on a keyboard. When children saw an image of a flower, they were instructed to press the opposite directional arrow button on the keyboard.", "Conditions": ["congruent", "incongruent"], "TaskMetrics": ["accuracy", "response time"], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Flanker Fish task", "TaskDescription": "Participants were presented with a series of seven fish in a row and were required to press the response button that corresponds to either the direction that the middle fish is facing (standard condition) or the direction that the outside fish are facing (reverse condition).", "DesignDetails": "Participants were presented with a series of seven fish in a row and were required to press the response button that corresponds to either the direction that the middle fish is facing (standard condition) or the direction that the outside fish are facing (reverse condition).", "Conditions": ["standard", "reverse", "mixed"], "TaskMetrics": ["accuracy", "response time"], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Color-Word Stroop task", "TaskDescription": "Playing a musical instrument engages various sensorimotor processes and draws on cognitive capacities collectively termed executive functions. However, while music training is believed to associated with enhancements in certain cognitive and language abilities, studies that have explored the specific relationship between music and executive function have yielded conflicting results.", "DesignDetails": "Playing a musical instrument engages various sensorimotor processes and draws on cognitive capacities collectively termed executive functions. However, while music training is believed to associated with enhancements in certain cognitive and language abilities, studies that have explored the specific relationship between music and executive function have yielded conflicting results.", "Conditions": ["music", "sports", "control"], "TaskMetrics": ["accuracy", "response time"], "RestingState": "false", "TaskDuration": "240s"}, {"TaskName": "Hearts and Flowers task", "TaskDescription": "The task required participants to press a response button that is either on the same side (congruent) or opposite side (incongruent) of an image. When children saw an image of a heart, they were instructed to press the corresponding directional arrow button on a keyboard. When children saw an image of a flower, they were instructed to press the opposite directional arrow button on the keyboard.", "DesignDetails": "The task required participants to press a response button that is either on the same side (congruent) or opposite side (incongruent) of an image. When children saw an image of a heart, they were instructed to press the corresponding directional arrow button on a keyboard. When children saw an image of a flower, they were instructed to press the opposite directional arrow button on the keyboard.", "Conditions": ["congruent", "incongruent"], "TaskMetrics": ["accuracy", "response time"], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Flanker Fish task", "TaskDescription": "Participants were presented with a series of seven fish in a row and were required to press the response button that corresponds to either the direction that the middle fish is facing (standard condition) or the direction that the outside fish are facing (reverse condition).", "DesignDetails": "Participants were presented with a series of seven fish in a row and were required to press the response button that corresponds to either the direction that the middle fish is facing (standard condition) or the direction that the outside fish are facing (reverse condition).", "Conditions": ["standard", "reverse", "mixed"], "TaskMetrics": ["accuracy", "response time"], "RestingState": "false", "TaskDuration": null}], "id": 5662181}, {"StudyObjective": "Reinstatement of memory representations for lifelike events over the course of a week", "fMRITasks": [{"TaskName": "Encoding", "TaskDescription": "Participants watched 24 short videos while in the MRI scanner. The videos lasted on average 38\u2009seconds (range 29\u201348\u2009s) and were taken from short films or videos posted on www.YouTube.com. All videos depicted a short narrative and were presented without sound. The stories centered around one character (5 videos), two main characters (8 videos) or an interaction of multiple characters (11 videos). 13 videos took place outside, 8 videos took place inside of a building and three videos switched between these types of locations. The order of the videos was pseudorandomized across participants. All stimuli were pre-experimentally unfamiliar to the participants.", "DesignDetails": "Participants were scanned twice, with one week between scans. Participants were scanned at a similar time of day on both days. The task was programmed in the Cogent 2000 toolbox (http://www.vislab.ucl.ac.uk/cogent_2000) using MATLAB (Version 2013b, The MathWorks, Inc., Natick, MA, USA). For a visualization of the study design, see Fig. .", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "45\u2009minutes"}, {"TaskName": "Immediate retrieval", "TaskDescription": "Participants were scanned at a similar time of day on both days. The task was programmed in the Cogent 2000 toolbox (http://www.vislab.ucl.ac.uk/cogent_2000) using MATLAB (Version 2013b, The MathWorks, Inc., Natick, MA, USA). For a visualization of the study design, see Fig. .", "DesignDetails": "Participants were scanned at a similar time of day on both days. The task was programmed in the Cogent 2000 toolbox (http://www.vislab.ucl.ac.uk/cogent_2000) using MATLAB (Version 2013b, The MathWorks, Inc., Natick, MA, USA). For a visualization of the study design, see Fig. .", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "45\u2009minutes"}, {"TaskName": "Delayed retrieval", "TaskDescription": "In a single scanning run, participants again silently retrieved all 24 videos (delayed retrieval phase, DelRet). The DelRet phase was structured identically to Day 1, including a cue and a vividness rating for each memory. After the scan, participants were asked to describe each video in as much detail as possible to the experimenter. They were cued with the title of the video. If they could not remember the video by the title alone, they were given up to three standardized hints per video. All video descriptions were audiotaped.", "DesignDetails": "In a single scanning run, participants again silently retrieved all 24 videos (delayed retrieval phase, DelRet). The DelRet phase was structured identically to Day 1, including a cue and a vividness rating for each memory. After the scan, participants were asked to describe each video in as much detail as possible to the experimenter. They were cued with the title of the video. If they could not remember the video by the title alone, they were given up to three standardized hints per video. All video descriptions were audiotaped.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "45\u2009minutes"}], "BehavioralTasks": [{"TaskName": "Free recall", "TaskDescription": "After the scan, participants were asked to describe each video in as much detail as possible to the experimenter. They were cued with the title of the video. If they could not remember the video by the title alone, they were given up to three standardized hints per video. All video descriptions were audiotaped.", "DesignDetails": "After the scan, participants were asked to describe each video in as much detail as possible to the experimenter. They were cued with the title of the video. If they could not remember the video by the title alone, they were given up to three standardized hints per video. All video descriptions were audiotaped.", "Conditions": [], "TaskMetrics": []}], "id": 5662713}, {"StudyObjective": "capture empathy processing in an interpersonal context", "fMRITasks": [{"TaskName": "empathy task", "TaskDescription": "imagine the target person in distressing scenes as either themselves or their family", "DesignDetails": "each completed an empathy task during fMRI", "Conditions": ["self-condition", "family-condition"], "TaskMetrics": ["neural pattern similarity"], "RestingState": "false", "TaskDuration": "8 and 9.2\u2009s"}, {"TaskName": "rating phase", "TaskDescription": "imagine the person in the picture as themselves and to take the perspective of the person in the picture during the self-condition", "DesignDetails": "each trial lasted between 8 and 9.2\u2009s", "Conditions": ["self-condition", "family-condition"], "TaskMetrics": ["rating phase"], "RestingState": "false", "TaskDuration": "2\u2009s"}], "BehavioralTasks": [], "id": 5716095}, {"StudyObjective": "To see whether simultaneous stimulation of the agonist muscle during voluntary movement induces unique brain activation patterns and network properties compared with movement alone or movement combined with concurrent stimulation over areas without agonist muscles.", "fMRITasks": [{"TaskName": "Movement of right ankle alone", "TaskDescription": "The motor task consisted of repetitive alternating dorsiflexion and relaxation of the right foot (with range reaching 15\u00b0). Foot movements were paced following an audio cue that was sounded every 1.5 s. These small range of motion and medium speed were applied to avoid large head motions.", "DesignDetails": "The duration of the fMRI experiment was 570 s for each subject. The fMRI session was composed of nine rest\u2013task cycles with 30 s for each period. Eyes were kept closed during scanning.", "Conditions": ["Movement of right ankle alone", "Movement and simultaneous stimulation of the agonist muscle", "Movement and simultaneous stimulation of a control area"], "TaskMetrics": ["Task+AgonistStim", "Task+ControlStim"], "RestingState": "false", "TaskDuration": "570"}, {"TaskName": "Movement and simultaneous stimulation of the agonist muscle", "TaskDescription": "The motor task consisted of repetitive alternating dorsiflexion and relaxation of the right foot (with range reaching 15\u00b0). Foot movements were paced following an audio cue that was sounded every 1.5 s. These small range of motion and medium speed were applied to avoid large head motions.", "DesignDetails": "The duration of the fMRI experiment was 570 s for each subject. The fMRI session was composed of nine rest\u2013task cycles with 30 s for each period. Eyes were kept closed during scanning.", "Conditions": ["Movement and simultaneous stimulation of the agonist muscle", "Movement and simultaneous stimulation of a control area"], "TaskMetrics": ["Task+AgonistStim", "Task+ControlStim"], "RestingState": "false", "TaskDuration": "570"}, {"TaskName": "Movement and simultaneous stimulation of a control area", "TaskDescription": "The motor task consisted of repetitive alternating dorsiflexion and relaxation of the right foot (with range reaching 15\u00b0). Foot movements were paced following an audio cue that was sounded every 1.5 s. These small range of motion and medium speed were applied to avoid large head motions.", "DesignDetails": "The duration of the fMRI experiment was 570 s for each subject. The fMRI session was composed of nine rest\u2013task cycles with 30 s for each period. Eyes were kept closed during scanning.", "Conditions": ["Movement and simultaneous stimulation of a control area"], "TaskMetrics": ["Task+ControlStim"], "RestingState": "false", "TaskDuration": "570"}], "BehavioralTasks": [], "id": 5776089}, {"StudyObjective": "To investigate the domain generality and domain specificity of representations that support metacognition of perception and memory.", "fMRITasks": [{"TaskName": "Perceptual Task", "TaskDescription": "Subjects were asked to indicate the brighter of two stimuli (words or abstract shapes).", "DesignDetails": "The experiment had a 2 \u00d7 2 \u00d7 2 design: condition (confidence/follow) \u00d7 task domain (perception/memory) \u00d7 stimulus type (shapes/words).", "Conditions": ["confidence", "follow"], "TaskMetrics": ["confidence ratings", "number press"], "RestingState": "false", "TaskDuration": "1.5 h"}, {"TaskName": "Memory Task", "TaskDescription": "Subjects were asked to memorize exemplars of the same stimulus types and then select the previously learned stimulus from two stimuli presented on each trial.", "DesignDetails": "The experiment had a 2 \u00d7 2 \u00d7 2 design: condition (confidence/follow) \u00d7 task domain (perception/memory) \u00d7 stimulus type (shapes/words).", "Conditions": ["confidence", "follow"], "TaskMetrics": ["confidence ratings", "number press"], "RestingState": "false", "TaskDuration": "1.5 h"}], "BehavioralTasks": [{"TaskName": "Confidence Ratings", "TaskDescription": "Subjects rated their confidence in their performance in each trial by selecting a number from a scale of 1 to 4.", "DesignDetails": "In miniblocks from the confidence condition, subjects had to rate their confidence in their performance in each trial by selecting a number from a scale of 1 to 4.", "Conditions": ["confidence", "follow"], "TaskMetrics": ["confidence ratings"]}, {"TaskName": "Follow Instructions", "TaskDescription": "Subjects were asked to respond according to a highlighted number regardless of their confidence.", "DesignDetails": "In miniblocks from the follow condition, subjects had to \u201cfollow the computer\u201d in each trial by pressing the button corresponding to the highlighted number regardless of their confidence.", "Conditions": ["confidence", "follow"], "TaskMetrics": ["number press"]}], "id": 5895040}, {"StudyObjective": "Cognitive regulation alters social and dietary choice by changing attribute representations in domain-general and domain-specific brain circuits", "fMRITasks": [{"TaskName": "Food Task", "TaskDescription": "Subjects chose between on-screen food items that varied in tastiness and healthiness and a neutral default food. Choices were made in 'Natural' [NC], 'Focus on Health' [HC], and 'Focus on Taste' Conditions [TC].", "DesignDetails": "Choices involved foods varying in healthiness and tastiness (food task) or monetary proposals varying in payoffs for subjects and an anonymous partner (altruism task).", "Conditions": ["Natural", "Focus on Health", "Focus on Taste"], "TaskMetrics": ["Healthy choices", "Altruistic choices"], "RestingState": "false", "TaskDuration": "2.5 s"}, {"TaskName": "Altruism Task", "TaskDescription": "Subjects chose between on-screen proposals that affected the payoff of themselves ($Self) and an anonymous partner ($Other) and a default option ($20 for both). Choices were made in 'Natural' [NC], 'Focus on Ethics' [EC], and 'Focus on Partner' Conditions [PC].", "DesignDetails": "Choices involved foods varying in healthiness and tastiness (food task) or monetary proposals varying in payoffs for subjects and an anonymous partner (altruism task).", "Conditions": ["Natural", "Focus on Ethics", "Focus on Partner"], "TaskMetrics": ["Healthy choices", "Altruistic choices"], "RestingState": "false", "TaskDuration": "2.5 s"}], "BehavioralTasks": [{"TaskName": "Food Task", "TaskDescription": "Subjects chose between on-screen food items that varied in tastiness and healthiness and a neutral default food. Choices were made in 'Natural' [NC], 'Focus on Health' [HC], and 'Focus on Taste' Conditions [TC].", "DesignDetails": "Choices involved foods varying in healthiness and tastiness (food task) or monetary proposals varying in payoffs for subjects and an anonymous partner (altruism task).", "Conditions": ["Natural", "Focus on Health", "Focus on Taste"], "TaskMetrics": ["Healthy choices", "Altruistic choices"], "RestingState": "false", "TaskDuration": "2.5 s"}, {"TaskName": "Altruism Task", "TaskDescription": "Subjects chose between on-screen proposals that affected the payoff of themselves ($Self) and an anonymous partner ($Other) and a default option ($20 for both). Choices were made in 'Natural' [NC], 'Focus on Ethics' [EC], and 'Focus on Partner' Conditions [PC].", "DesignDetails": "Choices involved foods varying in healthiness and tastiness (food task) or monetary proposals varying in payoffs for subjects and an anonymous partner (altruism task).", "Conditions": ["Natural", "Focus on Ethics", "Focus on Partner"], "TaskMetrics": ["Healthy choices", "Altruistic choices"], "RestingState": "false", "TaskDuration": "2.5 s"}], "id": 5973829}, {"StudyObjective": "Neural responses to emotional involuntary memories in posttraumatic stress disorder: Differences in timing and activity", "fMRITasks": [{"TaskName": "Involuntary memory task", "TaskDescription": "Twenty-one individuals with PTSD and 21 non-PTSD, trauma-exposed controls performed an involuntary memory task, while undergoing a functional magnetic resonance imaging scan. Environmental sounds served as cues for well-associated pictures of negative and neutral scenes. We used a finite impulse response model to analyze temporal differences between groups in neural responses.", "DesignDetails": "Twenty-one individuals with PTSD and 21 non-PTSD, trauma-exposed controls performed an involuntary memory task, while undergoing a functional magnetic resonance imaging scan. Environmental sounds served as cues for well-associated pictures of negative and neutral scenes. We used a finite impulse response model to analyze temporal differences between groups in neural responses.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Post-scan recall", "TaskDescription": "We quantified the number of pictures that were accurately recalled voluntarily after the scan. Technical error resulted in missing data for one PTSD participant. There was an effect of Group (F(1, 82)\u202f=\u202f5.80,   p  \u202f<\u202f0.05), with the PTSD group accurately recalling a greater percentage of the pictures (PTSD mean: 0.92, control mean: 0.85), an effect of Emotion (F(1, 82)\u202f=\u202f4.03,   p  \u202f<\u202f0.05), with a greater percentage of low emotion pictures being accurately recalled (low emotion mean: 0.92, high emotion mean: 0.86), but no Group x Emotion interaction (F(1, 82)\u202f=\u202f0.06,   p\u202f>  \u202f0.05).", "DesignDetails": null, "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Post-scan recall", "TaskDescription": "We quantified the number of pictures that were accurately recalled voluntarily after the scan. Technical error resulted in missing data for one PTSD participant. There was an effect of Group (F(1, 82)\u202f=\u202f5.80,   p  \u202f<\u202f0.05), with the PTSD group accurately recalling a greater percentage of the pictures (PTSD mean: 0.92, control mean: 0.85), an effect of Emotion (F(1, 82)\u202f=\u202f4.03,   p  \u202f<\u202f0.05), with a greater percentage of low emotion pictures being accurately recalled (low emotion mean: 0.92, high emotion mean: 0.86), but no Group x Emotion interaction (F(1, 82)\u202f=\u202f0.06,   p\u202f>  \u202f0.05).", "DesignDetails": null, "Conditions": [], "TaskMetrics": []}], "id": 6024199}, {"StudyObjective": "To investigate how behavioral differences between the tasks are instantiated as neural differences.", "fMRITasks": [{"TaskName": "Synchrony Judgment (SJ)", "TaskDescription": "Participants decide whether cues are in synch or out of synch.", "DesignDetails": "Participants first completed a pre-fMRI behavioral experiment in which they made SJs and TOJs to synchronous and asynchronous audiovisual stimuli.", "Conditions": ["Synchronous", "Asynchronous"], "TaskMetrics": ["PSS", "TIW"], "RestingState": "false", "TaskDuration": "20 min"}, {"TaskName": "Temporal Order Judgment (TOJ)", "TaskDescription": "Participants decide which cue came first (or last).", "DesignDetails": "Participants made SJs and TOJs, but to a reduced stimulus set of synchrony conditions: individually defined task-specific PSSs, largest audio-leading (333 ms), largest video-leading (333 ms), and physically synchronous stimuli.", "Conditions": ["Synchronous", "Asynchronous"], "TaskMetrics": ["PSS", "TIW"], "RestingState": "false", "TaskDuration": "20 min"}], "BehavioralTasks": [{"TaskName": "Synchrony Judgment (SJ)", "TaskDescription": "Participants decide whether cues are in synch or out of synch.", "DesignDetails": "Participants first completed a pre-fMRI behavioral experiment in which they made SJs and TOJs to synchronous and asynchronous audiovisual stimuli.", "Conditions": ["Synchronous", "Asynchronous"], "TaskMetrics": ["PSS", "TIW"], "RestingState": "false", "TaskDuration": "20 min"}, {"TaskName": "Temporal Order Judgment (TOJ)", "TaskDescription": "Participants decide which cue came first (or last).", "DesignDetails": "Participants made SJs and TOJs, but to a reduced stimulus set of synchrony conditions: individually defined task-specific PSSs, largest audio-leading (333 ms), largest video-leading (333 ms), and physically synchronous stimuli.", "Conditions": ["Synchronous", "Asynchronous"], "TaskMetrics": ["PSS", "TIW"], "RestingState": "false", "TaskDuration": "20 min"}], "id": 6037859}, {"StudyObjective": "Interpretation of Social Interactions: Functional Imaging of Cognitive-Semiotic Categories During Naturalistic Viewing", "fMRITasks": [{"TaskName": "Unresolved", "TaskDescription": "Unresolved interactions are ambiguous in the respective situation and their outcomes are not yet determined.", "DesignDetails": "Unresolved interactions are ambiguous in the respective situation and their outcomes are not yet determined.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "20-min"}, {"TaskName": "Non-habitual", "TaskDescription": "Non-habitual interactions counteract learned behavioral patterns and are disambiguated by the local context.", "DesignDetails": "Non-habitual interactions counteract learned behavioral patterns and are disambiguated by the local context.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "20-min"}, {"TaskName": "Habitual", "TaskDescription": "Habitual interactions include implicitly or explicitly learned behavioral patterns, which conform to social conventions.", "DesignDetails": "Habitual interactions include implicitly or explicitly learned behavioral patterns, which conform to social conventions.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "20-min"}, {"TaskName": "Verbal", "TaskDescription": "Verbal interactions largely rely on the conventional codes of a given language and culture and are subsumed in a forth category.", "DesignDetails": "Verbal interactions largely rely on the conventional codes of a given language and culture and are subsumed in a forth category.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "20-min"}], "BehavioralTasks": [], "id": 6102316}, {"StudyObjective": "Differential effects of parent and peer presence on neural correlates of risk taking in adolescence", "fMRITasks": [{"TaskName": "Yellow Light Game (YLG)", "TaskDescription": "A computerized driving task where participants could make safe or risky decisions, in the presence of a peer and their parent.", "DesignDetails": "Participants completed the YLG, a computerized driving task, during which they could make safe or risky decisions, in the presence of a peer and their parent.", "Conditions": ["Peer presence", "Parent presence"], "TaskMetrics": ["Percentage of go decisions", "Percentage of stop decisions"], "RestingState": "false", "TaskDuration": "20 intersections, totaling 40 trials for each social context condition"}, {"TaskName": "Stoplight Task", "TaskDescription": "A widely used task examining risk-taking at the behavioral and neural level.", "DesignDetails": "Participants were asked to drive a virtual car from the driver\u2019s point of view along a straight track, during which they encountered several intersections with yellow lights.", "Conditions": ["Peer presence", "Parent presence"], "TaskMetrics": ["Percentage of go decisions", "Percentage of stop decisions"], "RestingState": "false", "TaskDuration": "20 intersections, totaling 40 trials for each social context condition"}], "BehavioralTasks": [{"TaskName": "Yellow Light Game (YLG)", "TaskDescription": "A computerized driving task where participants could make safe or risky decisions, in the presence of a peer and their parent.", "DesignDetails": "Participants completed the YLG, a computerized driving task, during which they could make safe or risky decisions, in the presence of a peer and their parent.", "Conditions": ["Peer presence", "Parent presence"], "TaskMetrics": ["Percentage of go decisions", "Percentage of stop decisions"]}, {"TaskName": "Stoplight Task", "TaskDescription": "A widely used task examining risk-taking at the behavioral and neural level.", "DesignDetails": "Participants were asked to drive a virtual car from the driver\u2019s point of view along a straight track, during which they encountered several intersections with yellow lights.", "Conditions": ["Peer presence", "Parent presence"], "TaskMetrics": ["Percentage of go decisions", "Percentage of stop decisions"]}], "id": 6137311}, {"StudyObjective": "The experience of vivid autobiographical reminiscence is supported by subjective content representations in the precuneus", "fMRITasks": [{"TaskName": "fMRI Experiment", "TaskDescription": "Participants were instructed that they would be viewing images from the experience sampling experiment they recently completed and told that each image would be displayed for 8 s. Participants were asked to \u201c\u2026 try to remember the event depicted in the picture, and try to relive your experience mentally\u201d. After the remembrance period for each event, participants were asked if they remembered the event (\u201cyes\u201d or \u201cno\u201d) and how vividly they recalled the event (\u201clots of detail\u201d or \u201cvery little detail\u201d).", "DesignDetails": "In the scanner, participants were instructed that they would be viewing images from the experience sampling experiment they recently completed and told that each image would be displayed for 8 s. Participants were asked to \u201c\u2026 try to remember the event depicted in the picture, and try to relive your experience mentally\u201d. After the remembrance period for each event, participants were asked if they remembered the event (\u201cyes\u201d or \u201cno\u201d) and how vividly they recalled the event (\u201clots of detail\u201d or \u201cvery little detail\u201d).", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "8 s"}, {"TaskName": "Representational Similarity Analysis", "TaskDescription": "Representational Similarity Analysis (RSA ) is a data-analytic framework that allows us to quantify the relationship between the multivoxel patterns of neural activity and the behavior of interest. We used RSA to predict dissimilarities between the neural representations of events based on the dissimilarities between the events in terms of their subjective contents as captured by the tags provided by participants during the lifelogging phase as well as the vividness ratings provided during the reminiscence task in the scanner.", "DesignDetails": "Representational Similarity Analysis (RSA ) is a data-analytic framework that allows us to quantify the relationship between the multivoxel patterns of neural activity and the behavior of interest. We used RSA to predict dissimilarities between the neural representations of events based on the dissimilarities between the events in terms of their subjective contents as captured by the tags provided by participants during the lifelogging phase as well as the vividness ratings provided during the reminiscence task in the scanner.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Behavioral tasks", "TaskDescription": "There were two main behavioral tasks that were performed before the MRI session. The first behavioral task was performed each evening during the lifelogging period. After the smartphone was connected to a power outlet to be charged overnight and had uploaded the data to our server, participants reviewed the images from that day through a web interface, a link to which was uniquely generated for each participant and provided to the participant before data collection, segmenting their stream of images into distinct episodes and tagging each episode with a set of tags chosen from a drop-down menu (Table\u00a0 ). This master list of tags was constructed based on pilot studies we ran prior to the current study both on ourselves as well as with students in a large undergraduate class which is a good representation of the population from which participants in the current study were recruited. Participants were instructed to choose tags that best captured the contents of that episode and those that were likely to be good memory cues. The tags belonged to one of three categories: places, activities, and people but participants were free to choose any number of tags from any number of categories. If no tag fit the episode, participants could choose \u201cother\u201d. For each episode, they also provided a brief title and description. Insofar as only the participant knew the right tag to pick for a given episode, the set of tags captures the subjective contents of that episode. For instance, looking at someone else\u2019s data with images of a person in it, it may be difficult to pick the appropriate tag from amongst \u201cSpouse/Partner\u201d, \u201cBoyfriend/Girlfriend\u201d, \u201cFamily\u201d, \u201cWork colleagues\u201d, \u201cStranger\u201d, and \u201cFriends/Classmates\u201d. While other tags are more objective, such as \u201cSalesperson/Clerk/Cashier\u201d or \u201cGas station\u201d, the chosen tags are nevertheless the aspects chosen by the participant as the most salient of that episode from potentially many other descriptors. Therefore, the current analyses which are based on participant-generated content tags capture more self-relevant and subjective aspects of experience than did our previous work  which based on objective GPS locations and timestamps. A word cloud of the tags belonging to the episodes used in the fMRI experiment across all nine participants is shown in Fig.\u00a0 . The second behavioral task was conducted midway through the lifelogging period and at the end of the lifelogging period. After they collected data for two (and/or four) weeks, participants came into the laboratory on the Thursday of the third (and/or fifth) week and were tested over their ability to identify when events depicted in images drawn from his/her own lifelogs occurred. Specifically, they were shown a series of images from the weekdays of the preceding 2 weeks on the computer screen one at a time and asked to determine whether the image was from the first week or the second week. The results of this week discrimination task will be reported in a separate paper.", "DesignDetails": "There were two main behavioral tasks that were performed before the MRI session. The first behavioral task was performed each evening during the lifelogging period. After the smartphone was connected to a power outlet to be charged overnight and had uploaded the data to our server, participants reviewed the images from that day through a web interface, a link to which was uniquely generated for each participant and provided to the participant before data collection, segmenting their stream of images into distinct episodes and tagging each episode with a set of tags chosen from a drop-down menu (Table\u00a0 ). This master list of tags was constructed based on pilot studies we ran prior to the current study both on ourselves as well as with students in a large undergraduate class which is a good representation of the population from which participants in the current study were recruited. Participants were instructed to choose tags that best captured the contents of that episode and those that were likely to be good memory cues. The tags belonged to one of three categories: places, activities, and people but participants were free to choose any number of tags from any number of categories. If no tag fit the episode, participants could choose \u201cother\u201d. For each episode, they also provided a brief title and description. Insofar as only the participant knew the right tag to pick for a given episode, the set of tags captures the subjective contents of that episode. For instance, looking at someone else\u2019s data with images of a person in it, it may be difficult to pick the appropriate tag from amongst \u201cSpouse/Partner\u201d, \u201cBoyfriend/Girlfriend\u201d, \u201cFamily\u201d, \u201cWork colleagues\u201d, \u201cStranger\u201d, and \u201cFriends/Classmates\u201d. While other tags are more objective, such as \u201cSalesperson/Clerk/Cashier\u201d or \u201cGas station\u201d, the chosen tags are nevertheless the aspects chosen by the participant as the most salient of that episode from potentially many other descriptors. Therefore, the current analyses which are based on participant-generated content tags capture more self-relevant and subjective aspects of experience than did our previous work  which based on objective GPS locations and timestamps. A word cloud of the tags belonging to the episodes used in the fMRI experiment across all nine participants is shown in Fig.\u00a0 . The second behavioral task was conducted midway through the lifelogging period and at the end of the lifelogging period. After they collected data for two (and/or four) weeks, participants came into the laboratory on the Thursday of the third (and/or fifth) week and were tested over their ability to identify when events depicted in images drawn from his/her own lifelogs occurred. Specifically, they were shown a series of images from the weekdays of the preceding 2 weeks on the computer screen one at a time and asked to determine whether the image was from the first week or the second week. The results of this week discrimination task will be reported in a separate paper.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "id": 6175904}, {"StudyObjective": "investigating the interaction of emotion processing and response inhibition in CD youths during an affective Stroop task", "fMRITasks": [{"TaskName": "Affective Stroop Task", "TaskDescription": "The affective Stroop task is a variation of a response inhibition task and comprises a number Stroop task with trials which vary in cognitive load. Additionally, negative and neutral images are presented prior to the Stroop trials.", "DesignDetails": "We applied an affective number Stroop task as previously described in  . Each trial started with an emotional stimulus, i.e., a negative (Neg) or neutral (Neu) stimulus (150 ms), followed by a task trial (congruent/incongruent/blank trials) and finally a relaxation period, i.e., blank screen (350 ms). All pictures were selected from a child-appropriate image system [Developmental Affective Photo System (DAPS); ]. During task trials, participants were presented with an array of 1 to 4 digits or a blank screen and were asked to press a button corresponding to the number of items displayed. The number of items was either congruent (C; e.g., number 3 in an array of 3) or incongruent (IC; e.g., number 1 in an array of 2) with the digits presented. Star shaped stimuli (S; as a neutral baseline counting condition) and blank trials (B; no response expected from participants) were used as control conditions (for further details see ). Trial order and interstimulus intervals (which were 350\u20131850 ms) were randomized using Optseq  and kept constant across participants. A total of 300 task and 100 blank trials were administered (100 for C/IC/S trials, 50 with preceding negative images, 50 with neutral images, in 2 runs), with a total scan time of about 16 min (7.59 min each run).", "Conditions": ["negative", "neutral"], "TaskMetrics": ["RTs", "accuracy"], "RestingState": "false", "TaskDuration": "16 min"}, {"TaskName": "Blank trial", "TaskDescription": "Blank trial", "DesignDetails": "Blank trial", "Conditions": ["blank"], "TaskMetrics": ["RTs", "accuracy"], "RestingState": "false", "TaskDuration": "350 ms"}, {"TaskName": "Congruent trial", "TaskDescription": "Congruent trial", "DesignDetails": "Congruent trial", "Conditions": ["congruent"], "TaskMetrics": ["RTs", "accuracy"], "RestingState": "false", "TaskDuration": "350 ms"}, {"TaskName": "Incongruent trial", "TaskDescription": "Incongruent trial", "DesignDetails": "Incongruent trial", "Conditions": ["incongruent"], "TaskMetrics": ["RTs", "accuracy"], "RestingState": "false", "TaskDuration": "350 ms"}], "BehavioralTasks": [{"TaskName": "In-Scanner Performance", "TaskDescription": "Analysis of RTs and task accuracy (raw scores) were analyzed using 2x2x2 full-factorial ANOVAs with the between-subject factor   group   (CD and TD) and within-subject factors   emotion   (negative and neutral) and   task   (congruent and incongruent) for RTs and accuracy separately using SPSS, version 24.", "DesignDetails": "Analysis of RTs and task accuracy (raw scores) were analyzed using 2x2x2 full-factorial ANOVAs with the between-subject factor   group   (CD and TD) and within-subject factors   emotion   (negative and neutral) and   task   (congruent and incongruent) for RTs and accuracy separately using SPSS, version 24.", "Conditions": ["negative", "neutral", "congruent", "incongruent"], "TaskMetrics": ["RTs", "accuracy"], "RestingState": "false", "TaskDuration": null}], "id": 6200838}, {"StudyObjective": "The impact of self-distancing on emotion explosiveness and accumulation: An fMRI study", "fMRITasks": [{"TaskName": "Emotion intensity profile tracking", "TaskDescription": "Participants were asked to adopt a self-immersed or self-distanced perspective while reading and thinking about negative social feedback, and to report on felt changes in negative affect during that period using an emotion intensity profile tracking approach.", "DesignDetails": "Participants were asked to adopt a self-immersed or self-distanced perspective while reading and thinking about negative social feedback, and to report on felt changes in negative affect during that period using an emotion intensity profile tracking approach.", "Conditions": ["self-immersed", "self-distanced"], "TaskMetrics": ["emotion intensity profile tracking"], "RestingState": "false", "TaskDuration": "50 min"}, {"TaskName": "Emotion intensity profile tracking", "TaskDescription": "Participants were asked to adopt a self-immersed or self-distanced perspective while reading and thinking about negative social feedback, and to report on felt changes in negative affect during that period using an emotion intensity profile tracking approach.", "DesignDetails": "Participants were asked to adopt a self-immersed or self-distanced perspective while reading and thinking about negative social feedback, and to report on felt changes in negative affect during that period using an emotion intensity profile tracking approach.", "Conditions": ["self-immersed", "self-distanced"], "TaskMetrics": ["emotion intensity profile tracking"], "RestingState": "false", "TaskDuration": "50 min"}], "BehavioralTasks": [{"TaskName": "Emotion intensity profile tracking", "TaskDescription": "Participants were asked to adopt a self-immersed or self-distanced perspective while reading and thinking about negative social feedback, and to report on felt changes in negative affect during that period using an emotion intensity profile tracking approach.", "DesignDetails": "Participants were asked to adopt a self-immersed or self-distanced perspective while reading and thinking about negative social feedback, and to report on felt changes in negative affect during that period using an emotion intensity profile tracking approach.", "Conditions": ["self-immersed", "self-distanced"], "TaskMetrics": ["emotion intensity profile tracking"]}], "id": 6219793}, {"StudyObjective": "Contributions of default mode network stability and deactivation to adolescent task engagement", "fMRITasks": [{"TaskName": "Balloon Analogue Risk Task (BART)", "TaskDescription": "Participants completed a version of the Balloon Analogue Risk Task (BART), a well-validated experimental paradigm that has been adapted for fMRI in developmental populations. The BART measures participants\u2019 willingness to engage in risky behavior in order to earn rewards, and is associated with real-life risk taking in adolescents and adults. During the scan session, participants were presented with a sequence of 24 balloons that they could pump up to earn points. Each pump decision was associated with earning one point but also increased the risk that a balloon would explode. If participants pumped a balloon too many times, the balloon would explode and participants would lose all the points they had earned for that balloon. However, if participants chose to cash out before the balloon exploded, the points they earned would be added to the running total of points, which was presented on the screen as a points meter. Participants were instructed that their goal was to earn as many points as possible during the task. Each event (e.g., larger balloon following a pump, new balloon following cashed or explosion outcomes) was separated with a random jitter (500\u20134000\u2009ms). Balloons exploded after 4 to 10 pumps, and the order of balloons was presented in a fixed order (after being pseudo-randomly ordered prior to data collection), although none of this information was made available to participants. The BART was self-paced and would not advance unless the participant made the choice to either pump or cash out. Participants were told that they could win a $10 gift card at the end of the neuroimaging session if they earned enough points during the task. The point threshold for winning this prize was intentionally left ambiguous so that participants were motivated to continue earning points throughout the task. In reality, all participants were given a $10 gift card after completing the scan session.", "DesignDetails": "Participants completed a version of the Balloon Analogue Risk Task (BART), a well-validated experimental paradigm that has been adapted for fMRI in developmental populations. The BART measures participants\u2019 willingness to engage in risky behavior in order to earn rewards, and is associated with real-life risk taking in adolescents and adults. During the scan session, participants were presented with a sequence of 24 balloons that they could pump up to earn points. Each pump decision was associated with earning one point but also increased the risk that a balloon would explode. If participants pumped a balloon too many times, the balloon would explode and participants would lose all the points they had earned for that balloon. However, if participants chose to cash out before the balloon exploded, the points they earned would be added to the running total of points, which was presented on the screen as a points meter. Participants were instructed that their goal was to earn as many points as possible during the task. Each event (e.g., larger balloon following a pump, new balloon following cashed or explosion outcomes) was separated with a random jitter (500\u20134000\u2009ms). Balloons exploded after 4 to 10 pumps, and the order of balloons was presented in a fixed order (after being pseudo-randomly ordered prior to data collection), although none of this information was made available to participants. The BART was self-paced and would not advance unless the participant made the choice to either pump or cash out. Participants were told that they could win a $10 gift card at the end of the neuroimaging session if they earned enough points during the task. The point threshold for winning this prize was intentionally left ambiguous so that participants were motivated to continue earning points throughout the task. In reality, all participants were given a $10 gift card after completing the scan session.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Balloon Analogue Risk Task (BART)", "TaskDescription": "Participants completed a version of the Balloon Analogue Risk Task (BART), a well-validated experimental paradigm that has been adapted for fMRI in developmental populations. The BART measures participants\u2019 willingness to engage in risky behavior in order to earn rewards, and is associated with real-life risk taking in adolescents and adults. During the scan session, participants were presented with a sequence of 24 balloons that they could pump up to earn points. Each pump decision was associated with earning one point but also increased the risk that a balloon would explode. If participants pumped a balloon too many times, the balloon would explode and participants would lose all the points they had earned for that balloon. However, if participants chose to cash out before the balloon exploded, the points they earned would be added to the running total of points, which was presented on the screen as a points meter. Participants were instructed that their goal was to earn as many points as possible during the task. Each event (e.g., larger balloon following a pump, new balloon following cashed or explosion outcomes) was separated with a random jitter (500\u20134000\u2009ms). Balloons exploded after 4 to 10 pumps, and the order of balloons was presented in a fixed order (after being pseudo-randomly ordered prior to data collection), although none of this information was made available to participants. The BART was self-paced and would not advance unless the participant made the choice to either pump or cash out. Participants were told that they could win a $10 gift card at the end of the neuroimaging session if they earned enough points during the task. The point threshold for winning this prize was intentionally left ambiguous so that participants were motivated to continue earning points throughout the task. In reality, all participants were given a $10 gift card after completing the scan session.", "DesignDetails": "Participants completed a version of the Balloon Analogue Risk Task (BART), a well-validated experimental paradigm that has been adapted for fMRI in developmental populations. The BART measures participants\u2019 willingness to engage in risky behavior in order to earn rewards, and is associated with real-life risk taking in adolescents and adults. During the scan session, participants were presented with a sequence of 24 balloons that they could pump up to earn points. Each pump decision was associated with earning one point but also increased the risk that a balloon would explode. If participants pumped a balloon too many times, the balloon would explode and participants would lose all the points they had earned for that balloon. However, if participants chose to cash out before the balloon exploded, the points they earned would be added to the running total of points, which was presented on the screen as a points meter. Participants were instructed that their goal was to earn as many points as possible during the task. Each event (e.g., larger balloon following a pump, new balloon following cashed or explosion outcomes) was separated with a random jitter (500\u20134000\u2009ms). Balloons exploded after 4 to 10 pumps, and the order of balloons was presented in a fixed order (after being pseudo-randomly ordered prior to data collection), although none of this information was made available to participants. The BART was self-paced and would not advance unless the participant made the choice to either pump or cash out. Participants were told that they could win a $10 gift card at the end of the neuroimaging session if they earned enough points during the task. The point threshold for winning this prize was intentionally left ambiguous so that participants were motivated to continue earning points throughout the task. In reality, all participants were given a $10 gift card after completing the scan session.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Balloon Analogue Risk Task (BART)", "TaskDescription": "Participants completed a version of the Balloon Analogue Risk Task (BART), a well-validated experimental paradigm that has been adapted for fMRI in developmental populations. The BART measures participants\u2019 willingness to engage in risky behavior in order to earn rewards, and is associated with real-life risk taking in adolescents and adults. During the scan session, participants were presented with a sequence of 24 balloons that they could pump up to earn points. Each pump decision was associated with earning one point but also increased the risk that a balloon would explode. If participants pumped a balloon too many times, the balloon would explode and participants would lose all the points they had earned for that balloon. However, if participants chose to cash out before the balloon exploded, the points they earned would be added to the running total of points, which was presented on the screen as a points meter. Participants were instructed that their goal was to earn as many points as possible during the task. Each event (e.g., larger balloon following a pump, new balloon following cashed or explosion outcomes) was separated with a random jitter (500\u20134000\u2009ms). Balloons exploded after 4 to 10 pumps, and the order of balloons was presented in a fixed order (after being pseudo-randomly ordered prior to data collection), although none of this information was made available to participants. The BART was self-paced and would not advance unless the participant made the choice to either pump or cash out. Participants were told that they could win a $10 gift card at the end of the neuroimaging session if they earned enough points during the task. The point threshold for winning this prize was intentionally left ambiguous so that participants were motivated to continue earning points throughout the task. In reality, all participants were given a $10 gift card after completing the scan session.", "DesignDetails": "Participants completed a version of the Balloon Analogue Risk Task (BART), a well-validated experimental paradigm that has been adapted for fMRI in developmental populations. The BART measures participants\u2019 willingness to engage in risky behavior in order to earn rewards, and is associated with real-life risk taking in adolescents and adults. During the scan session, participants were presented with a sequence of 24 balloons that they could pump up to earn points. Each pump decision was associated with earning one point but also increased the risk that a balloon would explode. If participants pumped a balloon too many times, the balloon would explode and participants would lose all the points they had earned for that balloon. However, if participants chose to cash out before the balloon exploded, the points they earned would be added to the running total of points, which was presented on the screen as a points meter. Participants were instructed that their goal was to earn as many points as possible during the task. Each event (e.g., larger balloon following a pump, new balloon following cashed or explosion outcomes) was separated with a random jitter (500\u20134000\u2009ms). Balloons exploded after 4 to 10 pumps, and the order of balloons was presented in a fixed order (after being pseudo-randomly ordered prior to data collection), although none of this information was made available to participants. The BART was self-paced and would not advance unless the participant made the choice to either pump or cash out. Participants were told that they could win a $10 gift card at the end of the neuroimaging session if they earned enough points during the task. The point threshold for winning this prize was intentionally left ambiguous so that participants were motivated to continue earning points throughout the task. In reality, all participants were given a $10 gift card after completing the scan session.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "id": 6303343}, {"StudyObjective": "To identify patterns of gray matter volume (GMV) alteration specific to and common among patients with RLS, migraine, and comorbid migraine and RLS.", "fMRITasks": [{"TaskName": "Resting\u2010state functional magnetic resonance imaging (rs\u2010fMRI) study", "TaskDescription": "To localize the distinct and shared neural signatures of migraine and RLS.", "DesignDetails": "Direct group comparisons and conjunction analysis were used to localize the distinct and shared neural signatures of migraine and RLS.", "Conditions": [], "TaskMetrics": [], "RestingState": "true", "TaskDuration": null}, {"TaskName": "Replication analysis of shared neural signatures", "TaskDescription": "To further validate the results of the conjunction analysis described in the previous section, we overlapped these two voxel\u2010wise statistical results in the standard MNI\u2010space to check the spatial relationship between the two analyses.", "DesignDetails": "We used a two\u2010sample t\u2010test to investigate whole brain voxel\u2010wise GMV changes between patients with comorbid migraine and RLS and healthy controls.", "Conditions": [], "TaskMetrics": [], "RestingState": "true", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Sleep quality assessment", "TaskDescription": "To investigate the clinical associations in the group of patients with comorbid migraine and RLS, the anatomical regions identified by the conjunction analysis were extracted, averaged, and correlated with clinical characteristics, including migraine duration, migraine frequency, RLS duration, IRLSSG severity score, total PSQI score, Hospital Anxiety and Depression Scale (HADS) score, and Beck depression inventory (BDI) score, using Pearson's correlation.", "DesignDetails": "To investigate the clinical associations in the group of patients with comorbid migraine and RLS, the anatomical regions identified by the conjunction analysis were extracted, averaged, and correlated with clinical characteristics, including migraine duration, migraine frequency, RLS duration, IRLSSG severity score, total PSQI score, Hospital Anxiety and Depression Scale (HADS) score, and Beck depression inventory (BDI) score, using Pearson's correlation.", "Conditions": [], "TaskMetrics": ["PSQI score", "HADS score", "BDI score"]}], "id": 6331309}, {"StudyObjective": "To identify consistent changes of brain activity in psychopaths and to investigate whether these could explain known psychopathology.", "fMRITasks": [{"TaskName": "Action execution", "TaskDescription": "Associated with the right lateral prefrontal cortex.", "DesignDetails": "Associated with the right lateral prefrontal cortex.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Pain processing", "TaskDescription": "Associated with the left fronto-insular cortex.", "DesignDetails": "Associated with the left fronto-insular cortex.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Semantic language processing", "TaskDescription": "Associated with the left lateral prefrontal cortex.", "DesignDetails": "Associated with the left lateral prefrontal cortex.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Social cognition", "TaskDescription": "Associated with the dorsomedial prefrontal cortex.", "DesignDetails": "Associated with the dorsomedial prefrontal cortex.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Emotional reward processing", "TaskDescription": "Associated with the right amygdala.", "DesignDetails": "Associated with the right amygdala.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Cognitive reward processing", "TaskDescription": "Associated with the right fronto-insular cortex.", "DesignDetails": "Associated with the right fronto-insular cortex.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [], "id": 6344321}, {"StudyObjective": "investigating brain activation in PD patients during disorder-related script-driven imagery", "fMRITasks": [{"TaskName": "disorder-related script-driven imagery", "TaskDescription": "Participants were exposed to disorder-related and neutral narrative scripts while brain activation was measured with fMRI.", "DesignDetails": "Seventeen PD patients and seventeen healthy controls (HC) were exposed to newly developed disorder-related and neutral narrative scripts while brain activation was measured with fMRI.", "Conditions": ["disorder-related", "neutral"], "TaskMetrics": ["anxiety", "arousal", "valence", "ability to imagine the scripts"], "RestingState": "false", "TaskDuration": "9\u2009minutes"}], "BehavioralTasks": [{"TaskName": "rating of script-induced emotional states", "TaskDescription": "Participants rated their script-induced emotional states after the scanning session.", "DesignDetails": "Participants were encouraged to imagine the narrative scripts as vividly as possible and they rated their script-induced emotional states after the scanning session.", "Conditions": ["disorder-related", "neutral"], "TaskMetrics": ["anxiety", "arousal", "valence", "ability to imagine the scripts"]}], "id": 6382839}, {"StudyObjective": "Impaired voice processing in reward and salience circuits predicts social communication in children with autism", "fMRITasks": [{"TaskName": "Unfamiliar Voices minus Environmental Sounds", "TaskDescription": "Children were presented with unfamiliar voices and environmental sounds during fMRI scanning. The task was to identify their mother's voice with high accuracy.", "DesignDetails": "A randomized, rapid event-related design was used.", "Conditions": ["Unfamiliar Voices", "Environmental Sounds"], "TaskMetrics": ["Mother's Voice Identification Accuracy"], "RestingState": "false", "TaskDuration": "4 min"}, {"TaskName": "Mother\u2019s Voice minus Unfamiliar Voices", "TaskDescription": "Children were presented with mother's voice and unfamiliar voices during fMRI scanning. The task was to identify their mother's voice with high accuracy.", "DesignDetails": "A randomized, rapid event-related design was used.", "Conditions": ["Mother\u2019s Voice", "Unfamiliar Voices"], "TaskMetrics": ["Mother's Voice Identification Accuracy"], "RestingState": "false", "TaskDuration": "4 min"}], "BehavioralTasks": [{"TaskName": "Mother\u2019s Voice Identification Task", "TaskDescription": "Participants were seated in a quiet room and presented with a recording of a multisyllabic nonsense word spoken by either the participant\u2019s mother or a control mother. The task was to indicate whether or not their mother spoke the word.", "DesignDetails": "Participants were presented with 54 randomly ordered nonsense words: 18 produced by the subject\u2019s mother and the remaining 36 produced by unfamiliar female voices.", "Conditions": ["Mother\u2019s Voice", "Unfamiliar Voices"], "TaskMetrics": ["Mother's Voice Identification Accuracy"]}], "id": 6391069}, {"StudyObjective": "Investigate whether individual differences in recruitment of cognitive control regions during a difficult response inhibition task are associated with a failure to regulate neural responses to rewarding food cues in a subsequent task in a cohort of 27 female dieters.", "fMRITasks": [{"TaskName": "Effortful self-control task", "TaskDescription": "Participants were required to actively inhibit reading a series of words that appeared on the screen over the course of seven minutes.", "DesignDetails": "The task was modified to be amenable to neuroimaging analysis.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "7 minutes"}, {"TaskName": "Food cue reactivity task", "TaskDescription": "Participants engaged in a food-cue reactivity task involving food commercials that has previously been shown to reliably recruit the brain\u2019s reward system.", "DesignDetails": "The task involved watching a complete episode of the popular television sitcom The Big Bang Theory with commercials.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Ad libitum eating of ice-cream", "TaskDescription": "Participants were instructed to sample three flavors of ice cream under the guise of a taste test. After drinking an entire 15-ounce milkshake, participants were instructed to sample three flavors of ice cream.", "DesignDetails": "The task was designed to temporarily break participants diets and measure subsequent disinhibited eating.", "Conditions": [], "TaskMetrics": ["grams of ice cream consumed"]}], "id": 6397754}, {"StudyObjective": "Neurocognitive decision-making processes of casual methamphetamine users", "fMRITasks": [{"TaskName": "CUPS task", "TaskDescription": "Participants had to decide whether to accept or refuse a series of mixed gambles. In each trial participants were presented with a set of cups (3 to 11). They were informed that one of the cups contained a gain (amount ranging between $3 and $8) and the rest of the cups contained a loss of $1, and they were asked to accept or reject the gamble.", "DesignDetails": "The CUPS task was similarly used to examine neurocognitive characteristics specific to individuals with internet gambling disorder (IGD) during the decision process.", "Conditions": ["risky", "non-risky"], "TaskMetrics": ["risk taken", "response time", "number of misses", "amount or number of wins or losses"], "RestingState": "false", "TaskDuration": "12\u202fmin"}], "BehavioralTasks": [{"TaskName": "CUPS task", "TaskDescription": "Participants had to decide whether to accept or refuse a series of mixed gambles. In each trial participants were presented with a set of cups (3 to 11). They were informed that one of the cups contained a gain (amount ranging between $3 and $8) and the rest of the cups contained a loss of $1, and they were asked to accept or reject the gamble.", "DesignDetails": "The CUPS task was similarly used to examine neurocognitive characteristics specific to individuals with internet gambling disorder (IGD) during the decision process.", "Conditions": ["risky", "non-risky"], "TaskMetrics": ["risk taken", "response time", "number of misses", "amount or number of wins or losses"], "RestingState": "false", "TaskDuration": "12\u202fmin"}], "id": 6411911}, {"StudyObjective": "The efficacy of weight loss intervention can be predicted based on early alterations of fMRI food cue reactivity in the striatum.", "fMRITasks": [{"TaskName": "fMRI food cue reactivity", "TaskDescription": "The study aimed to investigate the relationship between food cue reactivity in the striatum measured one month after the onset of the weight loss program and weight changes obtained at the end of the six-month intervention.", "DesignDetails": "Participants were scheduled for two separate fMRI imaging sessions, one before starting the six-month weight loss intervention (baseline, Session 1) and another at the end of the first month of the six-month weight loss intervention (Session 2). Both imaging sessions included four ~6\u202fmin long experimental and two 10\u202fmin long resting-state runs as first and last runs. During the experimental runs images of neutral objects, high-calorie foods, and low-calorie foods were presented in a block design format. Each run consisted of four randomly presented 21\u202fs long blocks for each image category in which 7 individual images were presented for 2\u202fs followed by a 1\u202fs gap. Each block was separated by 9\u202fs and each run began with 15\u202fs of blank screen with only a fixation cross present. A total of 112 pictures for each image category were collected from the International Affective Picture System (IAPS) database ( ) and Internet search engines. In the two sessions, the same 112 images were randomly presented in four runs of 28 images for each image category. High-calorie food images contained an equal number of sweet and savory food images. All images were equated for luminance and contrast and presented centrally, subtending 8\u202f\u00d7\u202f6\u00b0, on a uniform gray background. Stimuli were projected onto a translucent screen located at the back of the scanner bore using a Panasonic PT-D3500E DLP projector (Matsushita Electric Industrial Co., Ltd., Kadoma, Osaka, Japan) at a refresh rate of 60\u202fHz, and they were viewed through a mirror attached to the head coil at a viewing distance of 57\u202fcm. Head motion was minimized using foam padding. Stimulus presentation was controlled by MATLAB R2010a (The MathWorks Inc., Natick, MA, USA) using PTB-3 ( ;  ;   http://psychtoolbox.org/  ). Participants were instructed to pay attention to the images presented on the screen.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "6\u202fmin"}, {"TaskName": "fMRI food cue reactivity", "TaskDescription": "The study aimed to investigate the relationship between food cue reactivity in the striatum measured one month after the onset of the weight loss program and weight changes obtained at the end of the six-month intervention.", "DesignDetails": "Participants were scheduled for two separate fMRI imaging sessions, one before starting the six-month weight loss intervention (baseline, Session 1) and another at the end of the first month of the six-month weight loss intervention (Session 2). Both imaging sessions included four ~6\u202fmin long experimental and two 10\u202fmin long resting-state runs as first and last runs. During the experimental runs images of neutral objects, high-calorie foods, and low-calorie foods were presented in a block design format. Each run consisted of four randomly presented 21\u202fs long blocks for each image category in which 7 individual images were presented for 2\u202fs followed by a 1\u202fs gap. Each block was separated by 9\u202fs and each run began with 15\u202fs of blank screen with only a fixation cross present. A total of 112 pictures for each image category were collected from the International Affective Picture System (IAPS) database ( ) and Internet search engines. In the two sessions, the same 112 images were randomly presented in four runs of 28 images for each image category. High-calorie food images contained an equal number of sweet and savory food images. All images were equated for luminance and contrast and presented centrally, subtending 8\u202f\u00d7\u202f6\u00b0, on a uniform gray background. Stimuli were projected onto a translucent screen located at the back of the scanner bore using a Panasonic PT-D3500E DLP projector (Matsushita Electric Industrial Co., Ltd., Kadoma, Osaka, Japan) at a refresh rate of 60\u202fHz, and they were viewed through a mirror attached to the head coil at a viewing distance of 57\u202fcm. Head motion was minimized using foam padding. Stimulus presentation was controlled by MATLAB R2010a (The MathWorks Inc., Natick, MA, USA) using PTB-3 ( ;  ;   http://psychtoolbox.org/  ). Participants were instructed to pay attention to the images presented on the screen.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "6\u202fmin"}], "BehavioralTasks": [{"TaskName": "old/new recognition memory task", "TaskDescription": "Participants performed an old/new recognition memory task outside the scanner following each session. Data of four participants were missing due to technical difficulties. Participants did in fact attend to the food images, as evidenced by high average accuracy rates of 75.60\u202f\u00b1\u202f2% (mean percent correct \u00b1 SEM) in this task. There were no differences in memory performance scores (d-prime) across food images (main effect of food cue: t(24)\u202f=\u202f\u22120.58,   p  \u202f=\u202f.567) and sessions (main effect of session: t(24)\u202f=\u202f0.25,   p  \u202f=\u202f.804). The non-significant interaction of food cue and session (t(24)\u202f=\u202f\u22120.88,   p  \u202f=\u202f.388) suggests that memory performance was similar for the high- and low-calorie food images in the two sessions.", "DesignDetails": "Participants performed an old/new recognition memory task outside the scanner following each session. Data of four participants were missing due to technical difficulties. Participants did in fact attend to the food images, as evidenced by high average accuracy rates of 75.60\u202f\u00b1\u202f2% (mean percent correct \u00b1 SEM) in this task. There were no differences in memory performance scores (d-prime) across food images (main effect of food cue: t(24)\u202f=\u202f\u22120.58,   p  \u202f=\u202f.567) and sessions (main effect of session: t(24)\u202f=\u202f0.25,   p  \u202f=\u202f.804). The non-significant interaction of food cue and session (t(24)\u202f=\u202f\u22120.88,   p  \u202f=\u202f.388) suggests that memory performance was similar for the high- and low-calorie food images in the two sessions.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "2\u20135\u202fh"}], "id": 6463125}, {"StudyObjective": "To understand the neural basis of N400 and how it is affected by SZ", "fMRITasks": [{"TaskName": "picture-word matching task", "TaskDescription": "Participants indicated whether a word was a semantic match or non-match (unmatched) relative to the preceding picture.", "DesignDetails": "The task involved a simple line drawing of an object presented for 250 ms, followed by a word presented for 75 ms. Participants responded by indicating whether the word was a semantic match or non-match to the preceding picture.", "Conditions": ["matched", "unrelated"], "TaskMetrics": ["reaction latency", "N400 amplitude"], "RestingState": "false", "TaskDuration": "16.1\u202fdays"}, {"TaskName": "fMRI recording", "TaskDescription": "Structural and functional MRI data were collected using a 3T Siemens Trio scanner.", "DesignDetails": "The fMRI protocol was an AC-PC aligned echo planar imaging (EPI) sequence.", "Conditions": ["matched", "unrelated"], "TaskMetrics": ["beta coefficients"], "RestingState": "false", "TaskDuration": "8:34\u202fmin per run"}], "BehavioralTasks": [{"TaskName": "picture-word matching task", "TaskDescription": "Participants indicated whether a word was a semantic match or non-match (unmatched) relative to the preceding picture.", "DesignDetails": "The task involved a simple line drawing of an object presented for 250 ms, followed by a word presented for 75 ms. Participants responded by indicating whether the word was a semantic match or non-match to the preceding picture.", "Conditions": ["matched", "unrelated"], "TaskMetrics": ["reaction latency", "N400 amplitude"], "RestingState": "false", "TaskDuration": "16.1\u202fdays"}], "id": 6699247}, {"StudyObjective": "The cerebellum is involved in processing of predictions and prediction errors in a fear conditioning paradigm", "fMRITasks": [{"TaskName": "fMRI acquisition", "TaskDescription": "All MR images were acquired with the participants lying supine inside a whole-body MRI system operating at 7 Tesla magnetic field strength (MAGNETOM 7T, Siemens Healthcare GmbH, Erlangen, Germany) equipped with a one-channel transmit/32 channel receive RF head coil (Nova Medical, Wilmington, MA).", "DesignDetails": "Prior to fMRI acquisition a sagittal MP2RAGE sequence ( ;  ) was run to acquire whole-brain anatomical reference images with an isotropic voxel size of 0.75 mm. Further imaging parameters were set as follows: TR/TE, 6000/3.45 ms, TI1/TI2, 800/2700 ms, flip angles 1/2, 4\u00b0/5\u00b0, parallel acceleration factor, 3, phase and slice partial Fourier factor, 6/8, acquisition matrix, 320\u00a0\u00d7\u00a0300, number of slices, 192, TA, 9:40 min.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "fMRI analysis", "TaskDescription": "We focused our fMRI analysis on the cerebellum. In addition, exploratory analysis of the whole brain was performed. The first\u00a0level analysis was modelled as an event related-design. All US, no-US and CS event regressors were modelled for the respective stimulus onset and all the respective durations were set to 0 s. The first five volumes of each fMRI run were disregarded. Events were blocked into 19 regressors of interest as displayed in  . If number of trials allowed (n\u00a0\u2265\u00a04), events of each kind were grouped in two equal-sized blocks representing the first (early) and the second (late) half of each phase. Regressors were chosen for CS+ and CS- during habituation (two regressors, four events each), CS+ and CS- presentations during acquisition and extinction (eight regressors, eight events each), US presentations during acquisition (two regressors, five events each), and the omission of US presentations (no-US) at the expected time of US presentations after CS onset (no-US post CS+: one regressor, six events during acquisition, two regressors, eight events each during extinction; no-US post CS-: four regressors, eight events each during acquisition and extinction).", "DesignDetails": "To correct for motion, volume realignment parameters were prepared as six nuisance regressors (three translations and three rotations). Pulse oximetry and respiration data from PMU were processed using essential features of the PhLEM toolbox for SPM ( ). To correct for physiological motion effects the RETROICOR (retrospective image-based correction) method was applied and eight regressors were generated ( ), resulting in a total of 14 nuisance regressors for each fMRI run. To ensure that no significant information was lost as a result of physiological denoising, an additional analysis with motion regressors but without RETROICOR was performed. Similarly, to ensure that no fine details were lost as a result of smoothing, a further analysis was performed using the normalized, un-smoothed functional data.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "fMRI acquisition", "TaskDescription": "All MR images were acquired with the participants lying supine inside a whole-body MRI system operating at 7 Tesla magnetic field strength (MAGNETOM 7T, Siemens Healthcare GmbH, Erlangen, Germany) equipped with a one-channel transmit/32 channel receive RF head coil (Nova Medical, Wilmington, MA).", "DesignDetails": "Prior to fMRI acquisition a sagittal MP2RAGE sequence ( ;  ) was run to acquire whole-brain anatomical reference images with an isotropic voxel size of 0.75 mm. Further imaging parameters were set as follows: TR/TE, 6000/3.45 ms, TI1/TI2, 800/2700 ms, flip angles 1/2, 4\u00b0/5\u00b0, parallel acceleration factor, 3, phase and slice partial Fourier factor, 6/8, acquisition matrix, 320\u00a0\u00d7\u00a0300, number of slices, 192, TA, 9:40 min.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "fMRI analysis", "TaskDescription": "We focused our fMRI analysis on the cerebellum. In addition, exploratory analysis of the whole brain was performed. The first\u00a0level analysis was modelled as an event related-design. All US, no-US and CS event regressors were modelled for the respective stimulus onset and all the respective durations were set to 0 s. The first five volumes of each fMRI run were disregarded. Events were blocked into 19 regressors of interest as displayed in  . If number of trials allowed (n\u00a0\u2265\u00a04), events of each kind were grouped in two equal-sized blocks representing the first (early) and the second (late) half of each phase. Regressors were chosen for CS+ and CS- during habituation (two regressors, four events each), CS+ and CS- presentations during acquisition and extinction (eight regressors, eight events each), US presentations during acquisition (two regressors, five events each), and the omission of US presentations (no-US) at the expected time of US presentations after CS onset (no-US post CS+: one regressor, six events during acquisition, two regressors, eight events each during extinction; no-US post CS-: four regressors, eight events each during acquisition and extinction).", "DesignDetails": "To correct for motion, volume realignment parameters were prepared as six nuisance regressors (three translations and three rotations). Pulse oximetry and respiration data from PMU were processed using essential features of the PhLEM toolbox for SPM ( ). To correct for physiological motion effects the RETROICOR (retrospective image-based correction) method was applied and eight regressors were generated ( ), resulting in a total of 14 nuisance regressors for each fMRI run. To ensure that no significant information was lost as a result of physiological denoising, an additional analysis with motion regressors but without RETROICOR was performed. Similarly, to ensure that no fine details were lost as a result of smoothing, a further analysis was performed using the normalized, un-smoothed functional data.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "id": 6715348}, {"StudyObjective": "To understand the relationship between affect and task-irrelevant value judgments in the brain.", "fMRITasks": [{"TaskName": "Purchasing decisions", "TaskDescription": "Participants indicated their willingness to pay a specific price for that book.", "DesignDetails": "Participants performed either purchasing or perceptual decisions in alternating blocks.", "Conditions": ["Purchasing decisions", "Perceptual decisions"], "TaskMetrics": ["Willingness-to-pay: WTP"], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Perceptual decisions", "TaskDescription": "Participants viewed the cover of the book, and answered questions relating to perceptual levels.", "DesignDetails": "Participants performed either purchasing or perceptual decisions in alternating blocks.", "Conditions": ["Purchasing decisions", "Perceptual decisions"], "TaskMetrics": ["Perceptual levels"], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Buying reasons for hedonic and utilitarian goods", "TaskDescription": "Participants purchased hedonic goods based on hedonic reasons (emotional wants) for almost all trials.", "DesignDetails": "Participants purchased hedonic goods based on hedonic reasons (emotional wants) for almost all trials.", "Conditions": ["Hedonic goods"], "TaskMetrics": ["Buying reasons for hedonic goods"]}, {"TaskName": "Buying reasons for utilitarian goods", "TaskDescription": "Participants purchased utilitarian goods based on utilitarian reasons (functional needs) for almost all trials.", "DesignDetails": "Participants purchased utilitarian goods based on utilitarian reasons (functional needs) for almost all trials.", "Conditions": ["Utilitarian goods"], "TaskMetrics": ["Buying reasons for utilitarian goods"]}], "id": 6821801}, {"StudyObjective": "To examine neural responses to monetary incentives in individuals diagnosed with Bipolar Disorder.", "fMRITasks": [{"TaskName": "Monetary Incentive Delay (MID) Task", "TaskDescription": "Participants completed a version of the Monetary Incentive Delay (MID) Task designed to elicit neural and behavioral responses to monetary incentives and their outcomes during FMRI scan acquisition.", "DesignDetails": "Each trial (8000 ms total) began with presentation of a visual cue (cue period; 2000 ms). Cue shapes indicated the valence (gain: circle, or loss: square) and horizontal lines across the cues indicated magnitude ($0.00: no lines, $0.20: one line, $1.00: two lines, or $5.00: three lines) of incentives that participants could try to gain or avoid losing by responding to an upcoming target. In addition to gain and loss trials, triangle cues indicated nonresponse trials, in which participants were instructed to not respond to upcoming targets. This version of the MID task therefore included 9 total conditions (4 gain, 4 loss, and 1 nonresponse). After viewing the cue, participants were shown a fixation cross for a variable interval (anticipation period; 2000 \u2013 2500 ms), followed by a target that briefly appeared (150 \u2013 470 ms). Participants were instructed to try to press a button before the disappearance of each target to either gain or avoid losing the previously cued amount of money. After a second variable delay (1030 \u2013 2350 ms), participants received feedback informing them of the amount they had gained or lost on each trial (outcome period; 2000 ms). Participants completed two blocks including 90 trials each (20 trials per condition; 180 trials total). Trials were presented in a pseudo-random sequence within each block. An adaptive timing algorithm applied to the targets maintained an approximately constant hit rate within each condition (i.e., if an individual's hit rate for a condition did not approximate an average of 66%, the duration of the next target was shortened or lengthened).", "Conditions": ["Gain anticipation", "Loss anticipation", "Gain outcome", "Nonloss outcome"], "TaskMetrics": ["Hit rate", "Hit reaction time", "Cue-induced affect ratings"], "RestingState": "false", "TaskDuration": "8000 ms"}], "BehavioralTasks": [{"TaskName": "Monetary Incentive Delay (MID) Task", "TaskDescription": "Participants completed a version of the Monetary Incentive Delay (MID) Task designed to elicit neural and behavioral responses to monetary incentives and their outcomes during FMRI scan acquisition.", "DesignDetails": "Each trial (8000 ms total) began with presentation of a visual cue (cue period; 2000 ms). Cue shapes indicated the valence (gain: circle, or loss: square) and horizontal lines across the cues indicated magnitude ($0.00: no lines, $0.20: one line, $1.00: two lines, or $5.00: three lines) of incentives that participants could try to gain or avoid losing by responding to an upcoming target. In addition to gain and loss trials, triangle cues indicated nonresponse trials, in which participants were instructed to not respond to upcoming targets. This version of the MID task therefore included 9 total conditions (4 gain, 4 loss, and 1 nonresponse). After viewing the cue, participants were shown a fixation cross for a variable interval (anticipation period; 2000 \u2013 2500 ms), followed by a target that briefly appeared (150 \u2013 470 ms). Participants were instructed to try to press a button before the disappearance of each target to either gain or avoid losing the previously cued amount of money. After a second variable delay (1030 \u2013 2350 ms), participants received feedback informing them of the amount they had gained or lost on each trial (outcome period; 2000 ms). Participants completed two blocks including 90 trials each (20 trials per condition; 180 trials total). Trials were presented in a pseudo-random sequence within each block. An adaptive timing algorithm applied to the targets maintained an approximately constant hit rate within each condition (i.e., if an individual's hit rate for a condition did not approximate an average of 66%, the duration of the next target was shortened or lengthened).", "Conditions": ["Gain anticipation", "Loss anticipation", "Gain outcome", "Nonloss outcome"], "TaskMetrics": ["Hit rate", "Hit reaction time", "Cue-induced affect ratings"], "RestingState": "false", "TaskDuration": "8000 ms"}], "id": 6831914}, {"StudyObjective": "Apples to apples? Neural correlates of emotion regulation differences between high- and low-risk adolescents", "fMRITasks": [{"TaskName": "Go/No-Go task", "TaskDescription": "Participants were instructed to inhibit a prepotent behavioral response while distracted by socioaffective cues, which were either appetitive or aversive social stimuli.", "DesignDetails": "The control go/no-go task consisted of four blocks, each containing 25 trials. The control task was completed prior to the social go/no-go, which included four aversive and four appetitive blocks, which were presented in a randomized order.", "Conditions": ["Control", "Appetitive", "Aversive"], "TaskMetrics": ["d\u2019"], "RestingState": "false", "TaskDuration": "100 trials per condition across eight randomized blocks"}, {"TaskName": "Social Go/No-Go task", "TaskDescription": "Participants were presented with blocks of socially appetitive or aversive scenes for 300 ms, after which a letter was superimposed on the image for 500 ms. During this 500 ms window, participants were instructed to respond as quickly as possible by pushing a button for every letter shown ('go') except the letter 'X' ('no-go').", "DesignDetails": "The control go/no-go task was identical in design structure, but did not include superimposed images (rather, a white square was presented on a black screen for 300 ms, after which a black letter was superimposed on the white background for 500 ms).", "Conditions": ["Appetitive", "Aversive"], "TaskMetrics": ["d\u2019"], "RestingState": "false", "TaskDuration": "100 trials per condition across eight randomized blocks"}], "BehavioralTasks": [{"TaskName": "Go/No-Go task", "TaskDescription": "Participants were instructed to inhibit a prepotent behavioral response while distracted by socioaffective cues, which were either appetitive or aversive social stimuli.", "DesignDetails": "The control go/no-go task consisted of four blocks, each containing 25 trials. The control task was completed prior to the social go/no-go, which included four aversive and four appetitive blocks, which were presented in a randomized order.", "Conditions": ["Control", "Appetitive", "Aversive"], "TaskMetrics": ["d\u2019"], "RestingState": "false", "TaskDuration": "100 trials per condition across eight randomized blocks"}, {"TaskName": "Social Go/No-Go task", "TaskDescription": "Participants were presented with blocks of socially appetitive or aversive scenes for 300 ms, after which a letter was superimposed on the image for 500 ms. During this 500 ms window, participants were instructed to respond as quickly as possible by pushing a button for every letter shown ('go') except the letter 'X' ('no-go').", "DesignDetails": "The control go/no-go task was identical in design structure, but did not include superimposed images (rather, a white square was presented on a black screen for 300 ms, after which a black letter was superimposed on the white background for 500 ms).", "Conditions": ["Appetitive", "Aversive"], "TaskMetrics": ["d\u2019"], "RestingState": "false", "TaskDuration": "100 trials per condition across eight randomized blocks"}], "id": 6847532}, {"StudyObjective": "Neural substrates of the influence of emotional cues on cognitive control in risk-taking adolescents", "fMRITasks": [{"TaskName": "Emotional go/no-go task", "TaskDescription": "A modified emotional go/no-go task was created with stimuli selected based on data from the pilot phase ( ). Within a go/no-go paradigm participants are instructed to press a button as quickly as possible when shown a 'go' (i.e., target) stimulus and to inhibit their response by not pressing the button when shown a 'no-go' (i.e., non-target) stimulus.", "DesignDetails": "The task was presented in Presentation using a projection screen and mirror within the head coil. Responses were recorded using a response box attached to the participant\u2019s respiratory belt. Participants responded with their right index finger.", "Conditions": ["calm", "happy", "angry"], "TaskMetrics": ["proportion of hits", "misses", "correct rejections", "false alarms", "reaction times"], "RestingState": "false", "TaskDuration": "2\u202fs"}, {"TaskName": "Emotional go/no-go task", "TaskDescription": "A modified emotional go/no-go task was created with stimuli selected based on data from the pilot phase ( ). Within a go/no-go paradigm participants are instructed to press a button as quickly as possible when shown a 'go' (i.e., target) stimulus and to inhibit their response by not pressing the button when shown a 'no-go' (i.e., non-target) stimulus.", "DesignDetails": "The task was presented in Presentation using a projection screen and mirror within the head coil. Responses were recorded using a response box attached to the participant\u2019s respiratory belt. Participants responded with their right index finger.", "Conditions": ["calm", "happy", "angry"], "TaskMetrics": ["proportion of hits", "misses", "correct rejections", "false alarms", "reaction times"], "RestingState": "false", "TaskDuration": "2\u202fs"}], "BehavioralTasks": [{"TaskName": "Columbia Card Task", "TaskDescription": "The CCT measures risk-taking under conditions of low and high emotional arousal. During this task, participants draw from a deck of cards, with each card earning or losing them points. The amount of gain and loss and the number of loss cards in the deck varies across trials. Consequently, the CCT is considered a dynamic risk-taking task: the risk parameters change each time a card is turned over. Such tasks are thought to be more reflective of real world behaviour than static tasks, as well as being more engaging for the participant ( ).", "DesignDetails": "All participants were typically developing, had normal vision, reported no neurological or psychiatric disorders and had no contraindications for MRI. Demographic characteristics are reported in  . Age and sex did not differ between the two risk-taking groups (age:   t  (30.98)\u202f=\u202f1.17,   p\u202f=\u202f.249; sex:   \u03a7  (1)\u202f=\u202f0.08,   p\u202f=\u202f.773).", "Conditions": ["hot", "cold"], "TaskMetrics": ["performance", "earnings"], "RestingState": "false", "TaskDuration": null}], "id": 6969196}, {"StudyObjective": "To investigate the development of the body-selective areas in the visual cortex and their modulation by emotion by comparing brain activity in adults, adolescents and children passively viewing angry, happy and neutral body movements, as well as objects\u2019 movements.", "fMRITasks": [{"TaskName": "Passive viewing fMRI task", "TaskDescription": "Passive viewing of short videos of angry, happy or neutral body movements.", "DesignDetails": "Forty-five short video-clips were taken from a larger set created and validated by . Each clip depicted one actor, dressed in black against a green background, moving in an angry, happy or neutral manner. Six actors were males and nine females, with each actor recorded three times for each of the three emotions. The videos were recorded using a digital video camera and were edited to two-second long clips (50 frames at 25 frames per second). The faces in the videos were masked with Gaussian filters so that only information from the body was perceived (for full details and validation of stimuli (see  and ). In addition, to use as control stimuli, we selected videos depicting non-human moving objects (e.g. windscreen wipers, windmills, metronomes, etc.) from the internet. We edited these clips using Adobe Premiere so that they matched the body stimuli in terms of size, resolution, and luminance. A green border matching the colour of the human video background was added.", "Conditions": ["Angry", "Happy", "Neutral"], "TaskMetrics": ["Body\u202f>\u202fNon-Human", "Angry\u202f>\u202fNeutral", "Happy\u202f>\u202fNeutral"], "RestingState": "false", "TaskDuration": "10\u202fs"}], "BehavioralTasks": [{"TaskName": "Emotion recognition task", "TaskDescription": "A short forced-choice emotion recognition task using the same stimuli to gauge their understanding of the emotional content of the stimuli.", "Conditions": ["Angry", "Happy", "Neutral"], "TaskMetrics": ["Emotion recognition accuracy"], "RestingState": "false", "TaskDuration": "8\u202fmin"}], "id": 6969350}, {"StudyObjective": "Investigated the behavioral and neural bases for strategic decision making when the participant must consider an opponent\u2019s inferences about the participant\u2019s own beliefs in a bilateral manner.", "fMRITasks": [{"TaskName": "asymmetric matching pennies game", "TaskDescription": "Participants played an economic game with three types of opponents: a human opponent outside the scanner, an artificial agent that followed a fixed probabilistic strategy according to a game-theoretic solution (FIX) and an artificial agent that adjusted its choices through a machine-learning algorithm (LRN).", "DesignDetails": "Participants\u2019 choice behaviors against the human opponent and LRN were similar but remarkably different from those against FIX.", "Conditions": ["HUM", "FIX", "LRN"], "TaskMetrics": ["choice behavior", "activation of RTPJ and LTPJ"], "RestingState": "false", "TaskDuration": "2\u00a0s"}, {"TaskName": "asymmetric matching pennies game", "TaskDescription": "Participants played an economic game with three types of opponents: a human opponent outside the scanner, an artificial agent that followed a fixed probabilistic strategy according to a game-theoretic solution (FIX) and an artificial agent that adjusted its choices through a machine-learning algorithm (LRN).", "DesignDetails": "Participants\u2019 choice behaviors against the human opponent and LRN were similar but remarkably different from those against FIX.", "Conditions": ["HUM", "FIX", "LRN"], "TaskMetrics": ["choice behavior", "activation of RTPJ and LTPJ"], "RestingState": "false", "TaskDuration": "2\u00a0s"}], "BehavioralTasks": [{"TaskName": "asymmetric matching pennies game", "TaskDescription": "Participants played an economic game with three types of opponents: a human opponent outside the scanner, an artificial agent that followed a fixed probabilistic strategy according to a game-theoretic solution (FIX) and an artificial agent that adjusted its choices through a machine-learning algorithm (LRN).", "DesignDetails": "Participants\u2019 choice behaviors against the human opponent and LRN were similar but remarkably different from those against FIX.", "Conditions": ["HUM", "FIX", "LRN"], "TaskMetrics": ["choice behavior", "activation of RTPJ and LTPJ"]}], "id": 6970153}, {"StudyObjective": "Individual differences in pain sensitivity are associated with cognitive network functional connectivity following one night of experimental sleep disruption", "fMRITasks": [{"TaskName": "Simple motor task", "TaskDescription": "Participants were given the opportunity for 8 hours of sleep at the CRU without experimental disruption.", "DesignDetails": "The neuroimaging protocol was further nested within a larger study (R01DA032922) that included additional nights for each sleep conditions and separate daytime procedures conducted on the day following the MRI scan; these data are not examined for the present study.", "Conditions": ["Uninterrupted sleep", "Forced awakenings"], "TaskMetrics": ["Pain ratings", "Stimulus temperatures"], "RestingState": "false", "TaskDuration": "10 min"}, {"TaskName": "Noxious thermal stimulation task", "TaskDescription": "Participants completed a quantitative sensory testing session before scanning at both study visits to derive participant\u2010tailored temperatures for the fMRI noxious stimulation task.", "DesignDetails": "The neuroimaging protocol was further nested within a larger study (R01DA032922) that included additional nights for each sleep conditions and separate daytime procedures conducted on the day following the MRI scan; these data are not examined for the present study.", "Conditions": ["Uninterrupted sleep", "Forced awakenings"], "TaskMetrics": ["Pain ratings", "Stimulus temperatures"], "RestingState": "false", "TaskDuration": "10 min"}], "BehavioralTasks": [{"TaskName": "Simple motor task", "TaskDescription": "Participants were given the opportunity for 8 hours of sleep at the CRU without experimental disruption.", "DesignDetails": "The neuroimaging protocol was further nested within a larger study (R01DA032922) that included additional nights for each sleep conditions and separate daytime procedures conducted on the day following the MRI scan; these data are not examined for the present study.", "Conditions": ["Uninterrupted sleep", "Forced awakenings"], "TaskMetrics": ["Pain ratings", "Stimulus temperatures"], "RestingState": "false"}], "id": 6981017}, {"StudyObjective": "The parent-child relationship and family context influence the development of emotion regulation (ER) brain circuitry and related skills in children and adolescents.", "fMRITasks": [{"TaskName": "TEAM task", "TaskDescription": "Participants completed the task while simultaneously undergoing fMRI scanning. The TEAM task is an event-related design and consists of 17 trials during which participants first see a pattern of colored arrows presented sequentially on the screen for 3 s, twice in a row (totaling 6 s). They are then given 4 s to reconstruct the sequence by pressing colored buttons on a response box.", "DesignDetails": "Participants were scanned simultaneously while each performing the TEAM task", "Conditions": ["both correct", "costly error", "both incorrect", "both correct"], "TaskMetrics": ["vmPFC activation", "dlPFC activation", "anterior insula activation", "fusiform gyrus activation", "thalamus activation", "caudate activation", "precuneus activation", "superior parietal lobule activation"], "RestingState": "false", "TaskDuration": "7 min and 50 s"}], "BehavioralTasks": [{"TaskName": "Alabama Parenting Questionnaire", "TaskDescription": "Participants completed the 42-item Alabama Parenting Questionnaire (APQ-Pos) which includes subscales assessing a parent\u2019s involvement, positive parenting practices, monitoring/supervision, inconsistent discipline, and corporal punishment.", "DesignDetails": "Participants were asked to report on their parents\u2019 positive parenting practices, thus allowing us to determine how a parent\u2019s brain response to their child\u2019s costly error may be correlated with parenting behavior in daily life.", "Conditions": [], "TaskMetrics": []}], "id": 7018765}, {"StudyObjective": "Pattern similarity and connectivity of hippocampal-neocortical regions support empathy for pain", "fMRITasks": [{"TaskName": "Pain empathy task", "TaskDescription": "Participants received a cue if the electrical shock was directed at themselves or at a confederate. After a brief delay, participants saw a photo of the shock recipient and a brief electrical shock was delivered. Participants were asked to rate pain and unpleasantness during one-third of the trials.", "DesignDetails": "Participants were presented with a cue indicating the upcoming pain intensity rather than with pictures of the confederate in painful or non-painful situations. First, we hypothesized that if mental simulation contributes to pain empathy, participants should base the evaluation of another individual\u2019s pain on representations of their previous, first-hand pain experiences. This should involve similar neural representations between first-hand pain and pain empathy within the hippocampus and regions important for mental simulation and pain empathy, including the MPFC, PCC, TPJ, dACC/aMCC, and the anterior insula.", "Conditions": ["self pain", "self no pain", "other pain", "other no pain"], "TaskMetrics": ["pattern similarity", "connectivity"], "RestingState": "false", "TaskDuration": "16\u00a0min"}], "BehavioralTasks": [], "id": 7235961}, {"StudyObjective": "Investigated how the human brain supports private-public mappings, using an interactive task which required subjects to adapt how they communicated their confidence about a perceptual decision to the social context.", "fMRITasks": [{"TaskName": "Social perceptual decision task", "TaskDescription": "Subjects performed a social perceptual decision task in separate prescan and scan sessions. They had to adapt the mapping from private to public confidence according to the social context in order to maximise reward.", "DesignDetails": "The task involved a social perceptual decision task with four partners. Subjects had to adapt the mapping from private to public confidence according to the social context in order to maximise reward.", "Conditions": ["Coherence", "Context", "Hidden context"], "TaskMetrics": ["Confidence reports", "Group accuracy", "Reward"], "RestingState": "false", "TaskDuration": "160"}, {"TaskName": "Confidence model", "TaskDescription": "A model of private confidence was constructed for fMRI analysis. The model included (contrast-coded) coherence and context as predictors of interest and (log-transformed) choice reaction time, choice, motion direction and marker starting position as predictors of no interest.", "DesignDetails": "The model was fitted to a subject\u2019s confidence reports in the final phase of the behavioural session using six predictors: (1) z-scored, contrast-coded coherence, (2) z-scored, log-transformed choice reaction time and (3-6) a dummy variable for each explicitly signalled context.", "Conditions": [], "TaskMetrics": ["Confidence reports"], "RestingState": "false", "TaskDuration": "160"}, {"TaskName": "fMRI analysis", "TaskDescription": "Univariate and multivariate analyses of fMRI data were performed using SPM12. Our main analysis was based on an event-related GLM (GLM1) of the neural response to the context screen. This model included three condition regressors.", "DesignDetails": "The analysis was based on an event-related GLM (GLM1) of the neural response to the context screen. This model included three condition regressors. First, the context screen when the partner was signalled (signalled, 1 s boxcar). Second, the context screen when the partner was hidden (hidden, 1 s boxcar). Third, the update screen informing subjects how often their individual decision had been selected as the group decision for each partner (update, 15 s boxcar).", "Conditions": ["Signalled", "Hidden", "Update"], "TaskMetrics": ["Confidence reports", "Group accuracy", "Reward"], "RestingState": "false", "TaskDuration": "160"}], "BehavioralTasks": [{"TaskName": "Confidence model", "TaskDescription": "A model of private confidence was constructed for fMRI analysis. The model included (contrast-coded) coherence and context as predictors of interest and (log-transformed) choice reaction time, choice, motion direction and marker starting position as predictors of no interest.", "DesignDetails": "The model was fitted to a subject\u2019s confidence reports in the final phase of the behavioural session using six predictors: (1) z-scored, contrast-coded coherence, (2) z-scored, log-transformed choice reaction time and (3-6) a dummy variable for each explicitly signalled context.", "Conditions": [], "TaskMetrics": ["Confidence reports"], "RestingState": "false", "TaskDuration": "160"}], "id": 7377905}, {"StudyObjective": "Examining whether individuals' chronological age could be predicted from T1 MRI scan and identifying the underlying brain regions that allow such prediction.", "fMRITasks": [{"TaskName": "Brain age prediction", "TaskDescription": "Estimating the chronological age from T1 MRI scan using a Deep Learning framework.", "DesignDetails": "An ensemble of 3D CNN models trained to predict age from raw T1 MRI scans.", "Conditions": [], "TaskMetrics": ["Mean absolute error (MAE)", "Pearson correlation coefficient"], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [], "id": 7426775}, {"StudyObjective": "Brain structure correlates of expected social threat and reward", "fMRITasks": [{"TaskName": "LODESTARS", "TaskDescription": "Participants are asked to vividly imagine that they have joined a new group, club or society, then make predictions about the probable emotional consequences of these novel interactions and report their anticipatory and anticipated cognitions and emotions.", "DesignDetails": "A 10-item inventory examining the extent to which respondents expect to experience social reward and threat during an imminent vividly imagined social encounter with a group of unfamiliar peers.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [], "id": 7582181}, {"StudyObjective": "To extend previous findings of WM activation in the internal capsule, showing lateralized activation based on the hand used during the task.", "fMRITasks": [{"TaskName": "Fine motor learning task", "TaskDescription": "Participants used an MRI compatible mouse to guide a cursor through a marked trail displayed on the monitor. Participants were instructed to minimize errors and maximize distance traveled. Performance metrics were recorded based on speed and accuracy.", "DesignDetails": "A 2-week motor training experiment was developed, similar in design as   and  . The motor training block task paradigm was developed in PsychToolbox3 ( ;  ), a package of MATLAB (R2018b, The MathWorks, Inc.). Participants used an MRI compatible mouse (Nata Technologies, Coquitlam B.C.) to guide a cursor through a marked trail displayed on the monitor. Participants were instructed to minimize errors and maximize distance traveled. Performance metrics were recorded based on speed and accuracy. The task difficulty was designed to emphasize the difference in dominant and non-dominant hand proficiency.", "Conditions": ["Baseline scan", "Midpoint scan", "Endpoint scan"], "TaskMetrics": ["Speed", "Accuracy"], "RestingState": "false", "TaskDuration": "6 min"}, {"TaskName": "Gross motor training task", "TaskDescription": "Participants used an MRI compatible mouse to guide a cursor through a marked trail displayed on the monitor. Participants were instructed to minimize errors and maximize distance traveled. Performance metrics were recorded based on speed and accuracy. The task difficulty was designed to emphasize the difference in dominant and non-dominant hand proficiency.", "DesignDetails": "A 2-week motor training experiment was developed, similar in design as   and  . The motor training block task paradigm was developed in PsychToolbox3 ( ;  ), a package of MATLAB (R2018b, The MathWorks, Inc.). Participants used an MRI compatible mouse (Nata Technologies, Coquitlam B.C.) to guide a cursor through a marked trail displayed on the monitor. Participants were instructed to minimize errors and maximize distance traveled. Performance metrics were recorded based on speed and accuracy. The task difficulty was designed to emphasize the difference in dominant and non-dominant hand proficiency.", "Conditions": ["Baseline scan", "Midpoint scan", "Endpoint scan"], "TaskMetrics": ["Speed", "Accuracy"], "RestingState": "false", "TaskDuration": "6 min"}], "BehavioralTasks": [{"TaskName": "Fine motor learning task", "TaskDescription": "Participants used an MRI compatible mouse to guide a cursor through a marked trail displayed on the monitor. Participants were instructed to minimize errors and maximize distance traveled. Performance metrics were recorded based on speed and accuracy. The task difficulty was designed to emphasize the difference in dominant and non-dominant hand proficiency.", "DesignDetails": "A 2-week motor training experiment was developed, similar in design as   and  . The motor training block task paradigm was developed in PsychToolbox3 ( ;  ), a package of MATLAB (R2018b, The MathWorks, Inc.). Participants used an MRI compatible mouse (Nata Technologies, Coquitlam B.C.) to guide a cursor through a marked trail displayed on the monitor. Participants were instructed to minimize errors and maximize distance traveled. Performance metrics were recorded based on speed and accuracy. The task difficulty was designed to emphasize the difference in dominant and non-dominant hand proficiency.", "Conditions": ["Baseline scan", "Midpoint scan", "Endpoint scan"], "TaskMetrics": ["Speed", "Accuracy"], "RestingState": "false", "TaskDuration": "6 min"}, {"TaskName": "Gross motor training task", "TaskDescription": "Participants used an MRI compatible mouse to guide a cursor through a marked trail displayed on the monitor. Participants were instructed to minimize errors and maximize distance traveled. Performance metrics were recorded based on speed and accuracy. The task difficulty was designed to emphasize the difference in dominant and non-dominant hand proficiency.", "DesignDetails": "A 2-week motor training experiment was developed, similar in design as   and  . The motor training block task paradigm was developed in PsychToolbox3 ( ;  ), a package of MATLAB (R2018b, The MathWorks, Inc.). Participants used an MRI compatible mouse (Nata Technologies, Coquitlam B.C.) to guide a cursor through a marked trail displayed on the monitor. Participants were instructed to minimize errors and maximize distance traveled. Performance metrics were recorded based on speed and accuracy. The task difficulty was designed to emphasize the difference in dominant and non-dominant hand proficiency.", "Conditions": ["Baseline scan", "Midpoint scan", "Endpoint scan"], "TaskMetrics": ["Speed", "Accuracy"], "RestingState": "false", "TaskDuration": "6 min"}], "id": 7649291}, {"StudyObjective": "Brain activity associated with regulating food cravings predicts changes in self-reported food craving and consumption over time", "fMRITasks": [{"TaskName": "Regulation of Craving (ROC) Task", "TaskDescription": "Participants were trained to decrease their desire to consume personally-desired foods using cognitive reappraisal.", "DesignDetails": "Participants viewed unhealthy craved foods, unhealthy not-craved foods, or healthy vegetables. For unhealthy craved foods, participants either actively viewed the foods or reappraised their craving for them.", "Conditions": ["Look Craved", "Look Not Craved", "Regulate Craved"], "TaskMetrics": ["craving for unhealthy foods", "craving for healthy foods", "consumption of unhealthy foods", "consumption of healthy foods"], "RestingState": "false", "TaskDuration": "11s"}, {"TaskName": "Food Craving Inventory (FCI)", "TaskDescription": "A 67-item self-report measure of cravings for and liking of specific foods.", "DesignDetails": "Participants rated the frequency of cravings for the past 30 days and how much they liked each food on a 5-point Likert scale.", "Conditions": [], "TaskMetrics": ["craving for unhealthy foods", "craving for healthy foods", "liking of unhealthy foods", "liking of healthy foods"], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Automated Self-Administered 24 h (ASA24) Dietary Assessment Tool", "TaskDescription": "Eating behavior was assessed via the ASA24, which calculates the Healthy Eating Index (HEI).", "DesignDetails": "Participants completed the ASA twice at each time point to obtain a more representative estimate of daily eating behavior.", "Conditions": [], "TaskMetrics": ["HEI", "total kilocalories consumed", "empty calories consumed"], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Food Craving Inventory (FCI)", "TaskDescription": "A 67-item self-report measure of cravings for and liking of specific foods.", "DesignDetails": "Participants rated the frequency of cravings for the past 30 days and how much they liked each food on a 5-point Likert scale.", "Conditions": [], "TaskMetrics": ["craving for unhealthy foods", "craving for healthy foods", "liking of unhealthy foods", "liking of healthy foods"], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Automated Self-Administered 24 h (ASA24) Dietary Assessment Tool", "TaskDescription": "Eating behavior was assessed via the ASA24, which calculates the Healthy Eating Index (HEI).", "DesignDetails": "Participants completed the ASA twice at each time point to obtain a more representative estimate of daily eating behavior.", "Conditions": [], "TaskMetrics": ["HEI", "total kilocalories consumed", "empty calories consumed"], "RestingState": "false", "TaskDuration": null}], "id": 7689031}, {"StudyObjective": "Probing the relevance of the hippocampus for conflict-induced memory improvement", "fMRITasks": [{"TaskName": "face-word Stroop task", "TaskDescription": "Participants performed a face-word Stroop task during functional magnetic resonance imaging (fMRI) followed by a recognition task for the faces.", "DesignDetails": "The task comprised face-word stimuli consisting of male and female faces [Glasgow Face Database,  ], overlaid by the words \u201cman\u201d or \u201cwoman\u201d (in German language). These words could be either congruent or incongruent with the sex of the face.", "Conditions": ["congruent", "incongruent"], "TaskMetrics": ["response time", "accuracy"], "RestingState": "false", "TaskDuration": null}, {"TaskName": "incidental delayed memory task", "TaskDescription": "About 30\u201345\u00a0min after the face-word Stroop task, an incidental memory task of to the previously seen faces was conducted outside of the MRI scanner.", "DesignDetails": "All 120 faces that had been shown in the face-word Stroop task and 40 novel faces were presented in a random order on a standard laptop computer. The faces were displayed in the center of a white screen for 2000\u00a0ms, followed by an inter-trial interval of 2000\u00a0ms (SOA\u00a0=\u00a04000\u00a0ms). Subjects were asked to indicate whether they had seen the face before (during the fMRI task or the familiarization) or not by pressing one of four buttons (4: \u201cdefinitely old\u201d, 3: \u201cprobably old\u201d, 2: \u201cprobably new\u201d, 1: \u201cdefinitely new\u201d).", "Conditions": ["definitely old", "probably old", "definitely new", "probably new"], "TaskMetrics": ["response time", "accuracy"], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "face-word Stroop task", "TaskDescription": "The task comprised face-word stimuli consisting of male and female faces [Glasgow Face Database,  ], overlaid by the words \u201cman\u201d or \u201cwoman\u201d (in German language). These words could be either congruent or incongruent with the sex of the face.", "DesignDetails": "With respect to RT, a mixed ANOVA revealed significant main effects of \u201ccongruency\u201d (incongruent vs. congruent; F(1,36)\u00a0=\u00a044.3;   p   < 0.001) and \u201cgroup\u201d (MTLE patients vs controls; F(1,36)\u00a0=\u00a04.7;   p  \u00a0=\u00a00.037) as well as a significant interaction (group x congruency; F(1,36)\u00a0=\u00a04.6;   p  \u00a0=\u00a00.039). RT slowing in incongruent compared to congruent trials was found in both healthy subjects (t(18)\u00a0=\u00a0\u22125.4;   p   < 0.001) and MTLE patients (t(18)\u00a0=\u00a0\u22123.9;   p  \u00a0=\u00a00.001), confirming robust interference effects in our paradigm.", "Conditions": ["congruent", "incongruent"], "TaskMetrics": ["response time", "accuracy"], "RestingState": "false", "TaskDuration": null}, {"TaskName": "incidental delayed memory task", "TaskDescription": "Retrieval rates are presented in  . Before analysis, we excluded all error trials and misses in the face-word Stroop task. The number of analyzed items did not differ between controls (97%) and MTLE patients (93%; t(36)\u00a0=\u00a01.79;   p  \u00a0=\u00a00.082). Notably, false alarm rates (new faces rated as \u201cdefinitely old\u201d or \u201cprobably old\u201d) did not differ between MTLE patients (33%) and controls (34%; t(36)\u00a0=\u00a00.1;   p  \u00a0=\u00a00.9).", "Conditions": ["definitely old", "probably old", "definitely new", "probably new"], "TaskMetrics": ["response time", "accuracy"], "RestingState": "false", "TaskDuration": null}], "id": 7836234}, {"StudyObjective": "A Functional MRI Paradigm for Efficient Mapping of Memory Encoding Across Sensory Conditions", "fMRITasks": [{"TaskName": "Memory Encoding", "TaskDescription": "We introduce a new and time-efficient memory-encoding paradigm for functional magnetic resonance imaging (fMRI). This paradigm is optimized for mapping multiple contrasts using a mixed design, using auditory (environmental/vocal) and visual (scene/face) stimuli. We demonstrate that the paradigm evokes robust neuronal activity in typical sensory and memory networks. We were able to detect auditory and visual sensory-specific encoding activities in auditory and visual cortices. Also, we detected stimulus-selective activation in environmental-, voice-, scene-, and face-selective brain regions (parahippocampal place and fusiform face area). A subsequent recognition task allowed the detection of sensory-specific encoding success activity (ESA) in both auditory and visual cortices, as well as sensory-unspecific positive ESA in the hippocampus. Further, sensory-unspecific negative ESA was observed in the precuneus. Among others, the parallel mixed design enabled sustained and transient activity comparison in contrast to rest blocks. Sustained and transient activations showed great overlap in most sensory brain regions, whereas several regions, typically associated with the default-mode network, showed transient rather than sustained deactivation. We also show that the use of a parallel mixed model had relatively little influence on positive or negative ESA. Together, these results demonstrate a feasible, versatile, and brief memory-encoding task, which includes multiple sensory stimuli to guarantee a comprehensive measurement. This task is especially suitable for large-scale clinical or population studies, which aim to test task-evoked sensory-specific and sensory-unspecific memory-encoding performance as well as broad sensory activity across the life span within a very limited time frame.", "DesignDetails": "We designed a novel task paradigm that we consider especially suited for large-scale studies. It measures predominantly memory encoding, but also perception and attention in both the auditory and visual domains within 10 min of fMRI acquisition time using simple instructions. To our knowledge, memory-encoding paradigms so far presented stimuli of one sensory condition or did face\u2013name associative memory tasks (Sperling,  ; Barch et al.,  ; Nenert et al.,  ; Sidhu et al.,  ; Hayes et al.,  ) within a similar time frame. We optimized our task to allow mapping of a versatile number of contrasts that are relatively straightforward to interpret. To enable the separation of sensory-specific and sensory-unspecific activities (Wheeler et al.,  ; Daselaar et al.,  ; Langner et al.,  ), we used two sensory modalities, auditory and visual. Twenty-five percent of the total time consisted of passive rest blocks as baseline/rest condition (Gusnard and Raichle,  ). Each sensory condition contained two distinct sub-conditions to cover a wide range of information on visual and auditory system activations as well as joined activation for sensory-unspecific functions like overall memory. Within the visual condition, we chose to present faces and spatial scenes, motivated by work on face-selective and scene-selective brain regions (Kanwisher et al.,  ; Epstein and Kanwisher,  ; Gazzaley et al.,  ; Collins and Dickerson,  ). Further, those stimuli seemed to show differences in age-related reductions in neural dedifferentiation, which makes them interesting for longitudinal studies (Srokova et al.,  ). To select auditory stimuli on a similar level of specificity, we chose voice and environmental stimuli motivated by previous work on voice-selective brain regions (Belin et al.,  ,  ; Pernet et al.,  ; Agus et al.,  ; Z\u00e4ske et al.,  ; Aglieri et al.,  ). This decision was further supported by studies showing that similarities as well as differences exist between the regional activation of voice and face perception (Young et al.,  ). Due to the simplicity of the design and to keep the paradigm language free, we did not include language stimuli. A post-fMRI recognition test, with previously seen/heard and novel items, enables the computation of contrasts between subsequently remembered (hit) and forgotten (miss) items (Wagner et al.,  ; Otten and Rugg,  ; Prince et al.,  ; Collins and Dickerson,  ). In the following, we will refer to these contrasts as encoding success activity (ESA). We used a parallel mixed block/event design to include a large number of stimuli within a limited time and to enable the already versatile number of contrasts also for the separation of sustained (block) and transient (event) activities (Velanova et al.,  ; Visscher et al.,  ; Petersen and Dubis,  ). Differentiating both can help to get a more complex understanding of the functional processes underlying a task. Sustained effects give more information about the maintenance of activity throughout a set of stimuli, for example, representing also overall attentional performance or arousal, whereas transient effects are specific for each trial of a task (Visscher et al.,  ).", "Conditions": ["Rest", "Auditory", "Visual", "Parallel"], "TaskMetrics": ["Hit-rate", "False alarm (FA)-rate", "d-prime (d\u2032)", "Response bias (c)"], "RestingState": "true", "TaskDuration": "10 min"}, {"TaskName": "Recognition Test", "TaskDescription": "The task was designed as a mixed model (Visscher et al.,  ) and included 180 events (trials), grouped into 32 blocks ( ). Out of these 32 blocks, eight were rest blocks (fixation), eight isolated auditory blocks, eight isolated visual blocks, and eight parallel auditory/visual blocks. Sixteen blocks contained auditory stimuli, half isolated auditory and half parallel with visual images. Of these 16 blocks, eight blocks contained environmental sounds (four isolated and four parallel), and eight blocks contained vocal sounds (four isolated and four parallel). Similarly, for the visual blocks, half were presented in isolation and half in parallel with sounds (scene and face images equally distributed). In each block, five items\u2014sounds, images, or both\u2014were presented for a total of 16 s per block ( ). Within the auditory blocks, the inter-trial interval between items was 200\u20132,700 ms. Within the visual stimulus blocks, the inter-trial interval between items was 200\u20132,200 ms. The difference in the inter-trial intervals between auditory and visual blocks is due to the variable duration of sounds. Each image was presented for exactly 2,000 ms. Inter-trial intervals as well as the order of blocks and the order of stimuli within the blocks were once randomly assigned and remained the same for all participants. A white fixation cross on black background was shown during the rest blocks, the inter-trial intervals, the isolated auditory blocks, and the initial and final 8 s of each run. By design, we tried to ensure that the different blocks and items would result in separate, uncorrelated regressors (see section Parallel Mixed Model Analysis). As we cannot predetermine which items will be remembered or forgotten, we also evaluated the collinearity of the regressors after data collection (see section Parallel Mixed Model Analysis).", "DesignDetails": "The task was designed as a mixed model (Visscher et al.,  ) and included 180 events (trials), grouped into 32 blocks ( ). Out of these 32 blocks, eight were rest blocks (fixation), eight isolated auditory blocks, eight isolated visual blocks, and eight parallel auditory/visual blocks. Sixteen blocks contained auditory stimuli, half isolated auditory and half parallel with visual images. Of these 16 blocks, eight blocks contained environmental sounds (four isolated and four parallel), and eight blocks contained vocal sounds (four isolated and four parallel). Similarly, for the visual blocks, half were presented in isolation and half in parallel with sounds (scene and face images equally distributed). In each block, five items\u2014sounds, images, or both\u2014were presented for a total of 16 s per block ( ). Within the auditory blocks, the inter-trial interval between items was 200\u20132,700 ms. Within the visual stimulus blocks, the inter-trial interval between items was 200\u20132,200 ms. The difference in the inter-trial intervals between auditory and visual blocks is due to the variable duration of sounds. Each image was presented for exactly 2,000 ms. Inter-trial intervals as well as the order of blocks and the order of stimuli within the blocks were once randomly assigned and remained the same for all participants. A white fixation cross on black background was shown during the rest blocks, the inter-trial intervals, the isolated auditory blocks, and the initial and final 8 s of each run. By design, we tried to ensure that the different blocks and items would result in separate, uncorrelated regressors (see section Parallel Mixed Model Analysis). As we cannot predetermine which items will be remembered or forgotten, we also evaluated the collinearity of the regressors after data collection (see section Parallel Mixed Model Analysis).", "Conditions": ["Rest", "Auditory", "Visual", "Parallel"], "TaskMetrics": ["Hit-rate", "False alarm (FA)-rate", "d-prime (d\u2032)", "Response bias (c)"], "RestingState": "true", "TaskDuration": "10 min"}], "BehavioralTasks": [{"TaskName": "Recognition Test", "TaskDescription": "The task was designed as a mixed model (Visscher et al.,  ) and included 180 events (trials), grouped into 32 blocks ( ). Out of these 32 blocks, eight were rest blocks (fixation), eight isolated auditory blocks, eight isolated visual blocks, and eight parallel auditory/visual blocks. Sixteen blocks contained auditory stimuli, half isolated auditory and half parallel with visual images. Of these 16 blocks, eight blocks contained environmental sounds (four isolated and four parallel), and eight blocks contained vocal sounds (four isolated and four parallel). Similarly, for the visual blocks, half were presented in isolation and half in parallel with sounds (scene and face images equally distributed). In each block, five items\u2014sounds, images, or both\u2014were presented for a total of 16 s per block ( ). Within the auditory blocks, the inter-trial interval between items was 200\u20132,700 ms. Within the visual stimulus blocks, the inter-trial interval between items was 200\u20132,200 ms. The difference in the inter-trial intervals between auditory and visual blocks is due to the variable duration of sounds. Each image was presented for exactly 2,000 ms. Inter-trial intervals as well as the order of blocks and the order of stimuli within the blocks were once randomly assigned and remained the same for all participants. A white fixation cross on black background was shown during the rest blocks, the inter-trial intervals, the isolated auditory blocks, and the initial and final 8 s of each run. By design, we tried to ensure that the different blocks and items would result in separate, uncorrelated regressors (see section Parallel Mixed Model Analysis). As we cannot predetermine which items will be remembered or forgotten, we also evaluated the collinearity of the regressors after data collection (see section Parallel Mixed Model Analysis).", "DesignDetails": "The task was designed as a mixed model (Visscher et al.,  ) and included 180 events (trials), grouped into 32 blocks ( ). Out of these 32 blocks, eight were rest blocks (fixation), eight isolated auditory blocks, eight isolated visual blocks, and eight parallel auditory/visual blocks. Sixteen blocks contained auditory stimuli, half isolated auditory and half parallel with visual images. Of these 16 blocks, eight blocks contained environmental sounds (four isolated and four parallel), and eight blocks contained vocal sounds (four isolated and four parallel). Similarly, for the visual blocks, half were presented in isolation and half in parallel with sounds (scene and face images equally distributed). In each block, five items\u2014sounds, images, or both\u2014were presented for a total of 16 s per block ( ). Within the auditory blocks, the inter-trial interval between items was 200\u20132,700 ms. Within the visual stimulus blocks, the inter-trial interval between items was 200\u20132,200 ms. The difference in the inter-trial intervals between auditory and visual blocks is due to the variable duration of sounds. Each image was presented for exactly 2,000 ms. Inter-trial intervals as well as the order of blocks and the order of stimuli within the blocks were once randomly assigned and remained the same for all participants. A white fixation cross on black background was shown during the rest blocks, the inter-trial intervals, the isolated auditory blocks, and the initial and final 8 s of each run. By design, we tried to ensure that the different blocks and items would result in separate, uncorrelated regressors (see section Parallel Mixed Model Analysis). As we cannot predetermine which items will be remembered or forgotten, we also evaluated the collinearity of the regressors after data collection (see section Parallel Mixed Model Analysis).", "Conditions": ["Rest", "Auditory", "Visual", "Parallel"], "TaskMetrics": ["Hit-rate", "False alarm (FA)-rate", "d-prime (d\u2032)", "Response bias (c)"], "RestingState": "true", "TaskDuration": "10 min"}], "id": 7859438}, {"StudyObjective": "To characterize sex differences in cerebral responses to reward anticipation and feedback and whether women and men differ in the influences of individual reward and punishment sensitivity on these neural processes.", "fMRITasks": [{"TaskName": "Monetary Incentive Delay Task (MIDT)", "TaskDescription": "Participants pressed a button to collect reward ($1, 1\u00a2, or nil), with the reaction time window titrated across trials so participants achieved a success rate of approximately 67%. We assessed sensitivity to punishment (SP) and sensitivity to reward (SR) with the Sensitivity to Punishment and Sensitivity to Reward Questionnaire (SPSRQ).", "DesignDetails": "The present study aims to characterize sex differences in cerebral responses to reward anticipation and feedback and whether women and men differ in the influences of individual reward and punishment sensitivity on these neural processes.", "Conditions": ["dollar", "cent", "nil"], "TaskMetrics": ["accuracy rate", "reaction time"], "RestingState": "false", "TaskDuration": "10 min"}, {"TaskName": "Sensitivity to Punishment and Sensitivity to Reward Questionnaire (SPSRQ)", "TaskDescription": "We assessed sensitivity to punishment (SP) and sensitivity to reward (SR) with the Sensitivity to Punishment and Sensitivity to Reward Questionnaire (SPSRQ).", "DesignDetails": "The present study aims to characterize sex differences in cerebral responses to reward anticipation and feedback and whether women and men differ in the influences of individual reward and punishment sensitivity on these neural processes.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Monetary Incentive Delay Task (MIDT)", "TaskDescription": "Participants pressed a button to collect reward ($1, 1\u00a2, or nil), with the reaction time window titrated across trials so participants achieved a success rate of approximately 67%. We assessed sensitivity to punishment (SP) and sensitivity to reward (SR) with the Sensitivity to Punishment and Sensitivity to Reward Questionnaire (SPSRQ).", "DesignDetails": "The present study aims to characterize sex differences in cerebral responses to reward anticipation and feedback and whether women and men differ in the influences of individual reward and punishment sensitivity on these neural processes.", "Conditions": ["dollar", "cent", "nil"], "TaskMetrics": ["accuracy rate", "reaction time"], "RestingState": "false", "TaskDuration": "10 min"}], "id": 7913329}, {"StudyObjective": "Medical education and distrust modulate the response of insular-cingulate network and ventral striatum in pain diagnosis", "fMRITasks": [{"TaskName": "Pain expression ratings", "TaskDescription": "Participants rated the pain of facial expressions and were confronted with two feedbacks (self-report of the person in pain and average opinion of 20 medical practitioners).", "DesignDetails": "Participants rated the pain of facial expressions and were confronted with two feedbacks (self-report of the person in pain and average opinion of 20 medical practitioners).", "Conditions": ["Target feedback", "MPs feedback"], "TaskMetrics": ["pain ratings", "reappraisal"], "RestingState": "false", "TaskDuration": "30 min"}, {"TaskName": "Feedback processing", "TaskDescription": "Participants were asked to rate again all 44 videoclips without being exposed to any feedback.", "DesignDetails": "Participants were asked to rate again all 44 videoclips without being exposed to any feedback.", "Conditions": ["Target feedback", "MPs feedback"], "TaskMetrics": ["pain ratings", "reappraisal"], "RestingState": "false", "TaskDuration": "30 min"}], "BehavioralTasks": [{"TaskName": "Implicit Association Task", "TaskDescription": "Participants were asked to rate again all 44 videoclips without being exposed to any feedback.", "DesignDetails": "Participants were asked to rate again all 44 videoclips without being exposed to any feedback.", "Conditions": ["Target feedback", "MPs feedback"], "TaskMetrics": ["pain ratings", "reappraisal"], "RestingState": "false", "TaskDuration": "30 min"}], "id": 8104963}, {"StudyObjective": "Beyond Sharing Unpleasant Affect\u2014Evidence for Pain-Specific Opioidergic Modulation of Empathy for Pain", "fMRITasks": [{"TaskName": "Empathy for Pain Paradigm", "TaskDescription": "In this task, short-lasting (500\u00a0ms) and individually calibrated painful or nonpainful electrical stimulation was delivered to participants, or to another person (a confederate of the experimenters). Trials were structured as follows: First, an arrow (2000\u00a0ms) indicated the   target   (self vs. other) of the upcoming stimulus. The intensity of the upcoming stimulus was indicated by the color of this arrow (red: painful vs. green: nonpainful). After a jittered blank screen (3500\u2009\u00b1\u20091500\u00a0ms), the electrical stimulus (500\u00a0ms) was delivered during simultaneous presentation of another visual delivery stimulus (1000\u00a0ms). The latter consisted of a picture of the confederate\u2019s face, shown with either a painful or a neutral expression, or, in case of self-directed stimulation, scrambled versions of these pictures were shown to control for visual stimulation. Depending on the stimulus category, these pictures were accompanied by either a red (painful) or green (nonpainful) flash in the lower right corner of the picture. The delivery cue was followed by a fixation cross (5000\u2009\u00b1\u20092500\u00a0ms), and an optional rating (self-directed: one rating question; other-directed: two rating questions; 6000-ms answering time per each question). After self-directed stimulation, participants rated their own pain (self-directed pain ratings), using the question \u201cHow painful was this stimulus for you?\u201d on a seven-point rating scale ranging from \u201cnot at all\u201d to \u201cextremely painful.\u201d After other-directed stimulation, participants rated the other person\u2019s pain (other-directed pain ratings; \u201cHow painful was this stimulus for the other person?\u201d answered using the same seven-point rating scale as for the self-directed pain ratings), as well as their own unpleasantness during other-directed stimulation (unpleasantness ratings; \u201cHow unpleasant did it feel when the other person was stimulated?\u201d; seven-point scale, from \u201cnot at all\u201d to \u201cextremely unpleasant\u201d). Ratings were collected in about one third of the trials in a pseudorandomized fashion. Between trials, a fixation cross (2000\u00a0ms) was presented. In sum, 15 trials per condition (i.e., self-directed pain/no pain; other-directed pain/no pain) were presented. Participants were instructed to empathize with the other person.", "DesignDetails": "The following task descriptions apply to both the fMRI and the psychopharmacological experiment. To maximize comparability, all parameters (including timing and number of ratings) of the tasks were kept the same across both experiments.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "15\u00a0min"}, {"TaskName": "Touch Paradigm", "TaskDescription": "Following the empathy for pain paradigm, we applied a touch paradigm ( ;  ) including 15 pleasant, 15 unpleasant and 15 neutral stimuli in pseudo-randomized order (see also  ). This paradigm consisted of two separate runs: In the first run (self-directed affective touch), the participant was stimulated to measure behavioral responses and brain activation related to the first-hand experience of affective touch. In the second run (empathy for affective touch) a confederate acting as a second participant was supposedly undergoing affective touch, and participants were instructed to empathize with her feelings. In every single self-directed trial, visual presentation of an object was accompanied by simultaneous stroking of the left palm at 1\u00a0Hz for 2\u00a0s in proximal-to-distal direction with a material whose touch resembled the touch of the object depicted on the screen. For example, touching the participant\u2019s hand with down feathers was accompanied by the picture of a chick to elicit a pleasant affective touch experience. The stimuli had been selected in extensive pretesting based on maximum agreement among participants in terms of congruency between visual and somatosensory stimulus and emotional responses (see   for paradigm validation test). In one third of the trials (5 per condition), participants were asked to rate the stimulation in that trial on a 9-point scale ranging from very unpleasant (left extreme of the scale) to very pleasant (right extreme) for either themselves or, supposedly, for the other participant (i.e., the confederate). Each single trial consisted of a jittered fixation cross (5000\u2009+\u2009\u22122000\u00a0ms), followed by visuo-tactile stimulation (2000\u00a0ms) and a jittered blank screen (1500\u2009+\u2009\u22121000\u00a0ms). In trials with ratings, the rating was presented after the jittered blank screen for 5000\u00a0ms and was followed by another jittered blank screen (1500\u2009+\u2009\u22121000\u00a0ms). Other-directed trials were identical apart from the absence of tactile stimulation of the participant, and the instruction that participants should empathize with their feelings.", "DesignDetails": "The following task descriptions apply to both the fMRI and the psychopharmacological experiment. To maximize comparability, all parameters (including timing and number of ratings) of the tasks were kept the same across both experiments.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "10\u00a0min"}], "BehavioralTasks": [{"TaskName": "Psychopharmacological Experiment", "TaskDescription": "This experiment was largely identical to the fMRI experiment, but it involved additional administration of a pharmacological compound to half of the participants, in a double-blinded (between-subjects) fashion. The placebo analgesia induction procedure differed from the one in the fMRI experiment in one respect, which was that after the initial administration of a placebo pill and the conditioning procedure, participants received another pill (supposedly to strengthen the analgesic effects). This pill was the one that included either the opioid antagonist naltrexone, or starch (placebo). The rationale of this procedure was directly motivated by previous placebo analgesia research (see, e.g.,  ), and served to investigate opioidergically mediated placebo analgesia effects once induced by the administration of the inert pill and the conditioning procedure. Following the peak level at about 50\u00a0min after administration, naltrexone plasma levels have been shown to be stable for at least 2\u00a0h ( ). In the present study, the touch paradigm immediately followed the empathy for pain paradigm, with a maximum starting point of 70\u00a0min after naltrexone administration. Thus, naltrexone medication effects were expected to persist over the whole course of the experimental tasks (which lasted 35\u00a0min in total), including the part when the affective touch task was performed.", "DesignDetails": "This experiment was largely identical to the fMRI experiment, but it involved additional administration of a pharmacological compound to half of the participants, in a double-blinded (between-subjects) fashion. The placebo analgesia induction procedure differed from the one in the fMRI experiment in one respect, which was that after the initial administration of a placebo pill and the conditioning procedure, participants received another pill (supposedly to strengthen the analgesic effects). This pill was the one that included either the opioid antagonist naltrexone, or starch (placebo). The rationale of this procedure was directly motivated by previous placebo analgesia research (see, e.g.,  ), and served to investigate opioidergically mediated placebo analgesia effects once induced by the administration of the inert pill and the conditioning procedure. Following the peak level at about 50\u00a0min after administration, naltrexone plasma levels have been shown to be stable for at least 2\u00a0h ( ). In the present study, the touch paradigm immediately followed the empathy for pain paradigm, with a maximum starting point of 70\u00a0min after naltrexone administration. Thus, naltrexone medication effects were expected to persist over the whole course of the experimental tasks (which lasted 35\u00a0min in total), including the part when the affective touch task was performed.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": "35\u00a0min"}], "id": 8107785}, {"StudyObjective": "Age-Related Differences in Auditory Cortex Activity During Spoken Word Recognition", "fMRITasks": [{"TaskName": "attentive listening", "TaskDescription": "Participants were asked to stay alert, still, and keep their eyes focused on a fixation cross while listening to a sequence of auditory sounds, including words, silence, and noise (single-channel noise vocoded words).", "DesignDetails": "During attentive listening, participants were asked to stay alert, still, and keep their eyes focused on a fixation cross while listening to a sequence of auditory sounds, including words, silence, and noise (single-channel noise vocoded words).", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "word repetition", "TaskDescription": "Participants were asked to do the same as in attentive listening, with the addition of repeating the word they just heard aloud.", "DesignDetails": "During word repetition, participants were asked to do the same as in attentive listening, with the addition of repeating the word they just heard aloud.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "word repetition", "TaskDescription": "Participants were asked to do the same as in attentive listening, with the addition of repeating the word they just heard aloud.", "DesignDetails": "During word repetition, participants were asked to do the same as in attentive listening, with the addition of repeating the word they just heard aloud.", "Conditions": [], "TaskMetrics": []}], "id": 8318202}, {"StudyObjective": "Punishment on Pause: Preliminary Evidence That Mindfulness Training Modifies Neural Responses in a Reactive Aggression Task", "fMRITasks": [{"TaskName": "Taylor Aggression Paradigm", "TaskDescription": "A version of the TAP adapted for the fMRI scanner, participants compete in multiple trials of a reaction time competition, in which the loser of each trial received an aversive noise blast through headphones, at one of four noise levels chosen by the other player.", "DesignDetails": "The TAP consists of 16 trials, each beginning with a fixation phase, followed by a decision phase, in which participants selected the volume of noise blast that their partner would receive if their partner lost the reaction time trial. Participants then viewed a fixation cross with a jittered duration (0.5/1.0/1.5 s) before the competition phase, during which participants were required to quickly press a button when a red square target was shown on-screen (5 s). Participants then viewed their opponent\u2019s (pre-programmed) volume setting. This time point of notification, when the participant perceived the opponent\u2019s intended noise blast setting, was modeled as the provocation phase. Finally, in the outcome phase, participants learned whether they won or lost the trial. The \u201closing\u201d outcome phase, modeled as the punishment phase, subjected participants to a 5 s noise blast delivered by their opponent.", "Conditions": ["retaliatory", "non-retaliatory"], "TaskMetrics": ["noise volume selection", "noise level chosen"], "RestingState": "false", "TaskDuration": "16"}, {"TaskName": "Aggressive Motives Scale", "TaskDescription": "A 6-item scale measuring desire to harm their opponent during completion of the TAP.", "DesignDetails": null, "Conditions": [], "TaskMetrics": ["aggressive motives"], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Aggressive Pleasure Scale", "TaskDescription": "An adapted version of the APS, a 38-item self-report index of positive emotions (e.g., excited, proud) and negative emotions (e.g., distressed, ashamed) felt by the participant when their opponent received the noise blast.", "DesignDetails": null, "Conditions": [], "TaskMetrics": ["aggressive pleasure"], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Aggressive Motives Scale", "TaskDescription": "A 6-item scale measuring desire to harm their opponent during completion of the TAP.", "DesignDetails": null, "Conditions": [], "TaskMetrics": ["aggressive motives"], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Aggressive Pleasure Scale", "TaskDescription": "An adapted version of the APS, a 38-item self-report index of positive emotions (e.g., excited, proud) and negative emotions (e.g., distressed, ashamed) felt by the participant when their opponent received the noise blast.", "DesignDetails": null, "Conditions": [], "TaskMetrics": ["aggressive pleasure"], "RestingState": "false", "TaskDuration": null}], "id": 8342928}, {"StudyObjective": "The neural underpinnings of intergroup social cognition: an fMRI meta-analysis", "fMRITasks": [{"TaskName": "Empathy", "TaskDescription": "Empathy directed at in-group members was associated with more consistent activation in the dmPFC, even when focused specifically on racial in-group (  vs   out-group) empathy.", "DesignDetails": "We found empathy directed at in-group members was associated with more consistent activation in the dmPFC, even when focused specifically on racial in-group (  vs   out-group) empathy.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Emotion perception", "TaskDescription": "Perceiving emotions of racial in-group members was associated with activation in the amygdala and fusiform, regions that have been well-established in visual emotion perception ( ;  ;  ), while emotion perception directed at racial out-group members was related to consistent anterior insula activation.", "DesignDetails": "We also observed differences in neural activation in response to racial in-group   vs   out-group members (although not to in-group   vs   out-group members in general) during emotion perception tasks.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [], "id": 8421705}, {"StudyObjective": "Neural dynamics between anterior insular cortex and right supramarginal gyrus dissociate genuine affect sharing from perceptual saliency of pretended pain", "fMRITasks": [{"TaskName": "Genuine: pain - no pain", "TaskDescription": "Participants watched video clips of persons who supposedly either genuinely experienced pain or merely pretended to be in strong pain.", "DesignDetails": "The participants were shown video clips of other persons who supposedly either genuinely experienced pain or merely pretended to be in strong pain.", "Conditions": ["genuine", "no pain"], "TaskMetrics": ["painful expressions in others", "painful feelings in others", "unpleasantness in self"], "RestingState": "false", "TaskDuration": "2 s"}, {"TaskName": "Pretended: pain - no pain", "TaskDescription": "Participants watched video clips of persons who supposedly either genuinely experienced pain or merely pretended to be in strong pain.", "DesignDetails": "The participants were shown video clips of other persons who supposedly either genuinely experienced pain or merely pretended to be in strong pain.", "Conditions": ["pretended", "no pain"], "TaskMetrics": ["painful expressions in others", "painful feelings in others", "unpleasantness in self"], "RestingState": "false", "TaskDuration": "2 s"}], "BehavioralTasks": [{"TaskName": "Genuine: pain - no pain", "TaskDescription": "Participants watched video clips of persons who supposedly either genuinely experienced pain or merely pretended to be in strong pain.", "DesignDetails": "The participants were shown video clips of other persons who supposedly either genuinely experienced pain or merely pretended to be in strong pain.", "Conditions": ["genuine", "no pain"], "TaskMetrics": ["painful expressions in others", "painful feelings in others", "unpleasantness in self"], "RestingState": "false", "TaskDuration": "2 s"}, {"TaskName": "Pretended: pain - no pain", "TaskDescription": "Participants watched video clips of persons who supposedly either genuinely experienced pain or merely pretended to be in strong pain.", "DesignDetails": "The participants were shown video clips of other persons who supposedly either genuinely experienced pain or merely pretended to be in strong pain.", "Conditions": ["pretended", "no pain"], "TaskMetrics": ["painful expressions in others", "painful feelings in others", "unpleasantness in self"], "RestingState": "false", "TaskDuration": "2 s"}], "id": 8443248}, {"StudyObjective": "Altered Brain Structure in Chronic Visceral Pain: Specific Differences in Gray Matter Volume and Associations With Visceral Symptoms and Chronic Stress", "fMRITasks": [], "BehavioralTasks": [], "id": 8564184}, {"StudyObjective": "To characterize developmental changes in brain activity related to the influence of a social stimulus on cognitive control and more specifically on inhibitory control.", "fMRITasks": [{"TaskName": "Antisaccade task", "TaskDescription": "Participants are asked to inhibit their reflexive eye movement to an abruptly appearing peripheral visual target and to reprogram a saccade in the opposite direction.", "DesignDetails": "We implemented an event-related design, mixing pro and antisaccades to faces and cars.", "Conditions": ["faces", "cars"], "TaskMetrics": ["reaction time", "error rate"], "RestingState": "false", "TaskDuration": "4 min"}, {"TaskName": "Go/Nogo task", "TaskDescription": "Participants are asked to inhibit their reflexive eye movement to an abruptly appearing peripheral visual target and to reprogram a saccade in the opposite direction.", "DesignDetails": "We implemented an event-related design, mixing pro and antisaccades to faces and cars.", "Conditions": ["faces", "cars"], "TaskMetrics": ["reaction time", "error rate"], "RestingState": "false", "TaskDuration": "4 min"}], "BehavioralTasks": [{"TaskName": "Go/Nogo task", "TaskDescription": "Participants are asked to inhibit their reflexive eye movement to an abruptly appearing peripheral visual target and to reprogram a saccade in the opposite direction.", "DesignDetails": "We implemented an event-related design, mixing pro and antisaccades to faces and cars.", "Conditions": ["faces", "cars"], "TaskMetrics": ["reaction time", "error rate"]}], "id": 8597975}, {"StudyObjective": "The present fMRI study aimed at highlighting patterns of brain activations and autonomic activity when confronted with high mental workload and the threat of auditory stressors.", "fMRITasks": [{"TaskName": "Toulouse n\u2010back Task (TNT)", "TaskDescription": "The task is described in detail in a previous publication (Mandrick et al.,\u00a0). The task was developed to combine a classical n\u2010back task with mental arithmetic. Instead of memorizing and comparing unique items, as in the classical n\u2010back task, the participants had to memorize and to compare the results of arithmetic operations, computed beforehand. Arithmetic operations were either additions or subtractions. All numbers were multiples of five (e.g., 15\u2009+\u200940, 90\u201335). The arithmetic operations (trials) were presented for 2.5\u00a0s, followed by an interstimulus\u2010interval of 0.5\u00a0s. Volunteers were required to compute the result of the arithmetic operations and compare it with either a fixed number (0\u2010back) or the result obtained two trials before (2\u2010back).", "DesignDetails": "Experimental design. (a) Toulouse n\u2010back task (TNT). The active blocks consisted of 12 trials and lasted 36\u00a0s. They were interleaved with 24\u2010s rest blocks (R). Participants responded to targets and nontargets by pressing one of two different buttons. The side of the buttons was counterbalanced across participants. (b) experimental timeline. The experiment included five functional runs (two safe runs without any sounds and three threat runs with the possible occurrence of aversive sounds), presented in a counterbalanced order. TNT difficulty levels (0\u2010back and 2\u2010back) were counterbalanced and alternated with rest periods.", "Conditions": ["0\u2010back safe", "0\u2010back threat", "2\u2010back safe", "2\u2010back threat"], "TaskMetrics": ["percentage of correct responses", "mean reaction times", "d\u2010prime"], "RestingState": "false", "TaskDuration": "36\u00a0s"}, {"TaskName": "Heart rate", "TaskDescription": "ECG signal was first visually controlled for outliers and artifacts. Signal was processed with the \u201cfindpeaks\u201d function of MATLAB 2019. The series of R\u2013R interval times were then derived from the ECG and the mean heart rate was calculated for each active 36\u00a0s block.", "DesignDetails": "ECG signal was first visually controlled for outliers and artifacts. Signal was processed with the \u201cfindpeaks\u201d function of MATLAB 2019. The series of R\u2013R interval times were then derived from the ECG and the mean heart rate was calculated for each active 36\u00a0s block.", "Conditions": ["0\u2010back safe", "0\u2010back threat", "2\u2010back safe", "2\u2010back threat"], "TaskMetrics": ["mean heart rate"], "RestingState": "false", "TaskDuration": "36\u00a0s"}, {"TaskName": "Pupil diameter", "TaskDescription": "Pupil diameter signal was processed using home\u2010made MATLAB scripts. Periods of signal loss and blinking as well as six samples before and after each signal loss period (100\u2009ms at 60\u2009Hz) were linearly interpolated. Trials where the number of interpolated samples exceeded 50%, were excluded from analyses. The signal was low\u2010passed using a 9\u2010point moving average filter. The pupil diameter was then averaged over all trials of each active 36\u2010s block, and then averaged for each of the four experimental conditions.", "DesignDetails": "Pupil diameter signal was processed using home\u2010made MATLAB scripts. Periods of signal loss and blinking as well as six samples before and after each signal loss period (100\u2009ms at 60\u2009Hz) were linearly interpolated. Trials where the number of interpolated samples exceeded 50%, were excluded from analyses. The signal was low\u2010passed using a 9\u2010point moving average filter. The pupil diameter was then averaged over all trials of each active 36\u2010s block, and then averaged for each of the four experimental conditions.", "Conditions": ["0\u2010back safe", "0\u2010back threat", "2\u2010back safe", "2\u2010back threat"], "TaskMetrics": ["mean pupil diameter"], "RestingState": "false", "TaskDuration": "36\u00a0s"}], "BehavioralTasks": [{"TaskName": "n\u2010back performance", "TaskDescription": "The percentage of correct responses induced by the four experimental conditions were 94.44% (  SD  \u00a0=\u00a04.05) for \u201c0\u2010back safe,\u201d 94.71% (  SD  \u00a0=\u00a03.80) for \u201c0\u2010back threat,\u201d 78.70% (  SD  \u00a0=\u00a020.31) for \u201c2\u2010back safe,\u201d and 78.14% (  SD  \u00a0=\u00a020.25) for \u201c2\u2010back threat\u201d (Figure\u00a0 , middle left panel). Participants showed lower percentage of correct response with increased difficulty [  F  (1,19)\u00a0=\u00a018.33,   p  \u2009<\u2009.001,   \u03b7  \u00a0=\u00a0.49]. The threat of unpredictable auditory stressors did not impact accuracy (  p  \u00a0=\u00a0.853). The interaction term was not significant (  p  \u00a0=\u00a0.502).", "DesignDetails": "The percentage of correct responses induced by the four experimental conditions were 94.44% (  SD  \u00a0=\u00a04.05) for \u201c0\u2010back safe,\u201d 94.71% (  SD  \u00a0=\u00a03.80) for \u201c0\u2010back threat,\u201d 78.70% (  SD  \u00a0=\u00a020.31) for \u201c2\u2010back safe,\u201d and 78.14% (  SD  \u00a0=\u00a020.25) for \u201c2\u2010back threat\u201d (Figure\u00a0 , middle left panel). Participants showed lower percentage of correct response with increased difficulty [  F  (1,19)\u00a0=\u00a018.33,   p  \u2009<\u2009.001,   \u03b7  \u00a0=\u00a0.49]. The threat of unpredictable auditory stressors did not impact accuracy (  p  \u00a0=\u00a0.853). The interaction term was not significant (  p  \u00a0=\u00a0.502).", "Conditions": ["0\u2010back safe", "0\u2010back threat", "2\u2010back safe", "2\u2010back threat"], "TaskMetrics": ["percentage of correct responses"], "RestingState": "false", "TaskDuration": "36\u00a0s"}], "id": 8764488}, {"StudyObjective": "Growing in generosity? The effects of giving magnitude, target, and audience on the neural signature of giving in adolescence", "fMRITasks": [{"TaskName": "Giving magnitude", "TaskDescription": "Participants divided 7 coins between themselves and either a friend or unfamiliar peer in an audience or anonymous condition.", "DesignDetails": "Participants could give away 1, 2, or 3 out of 7 coins in the small giving condition, and 4, 5, or 6 out of 7 coins in the large giving condition.", "Conditions": ["small giving condition", "large giving condition"], "TaskMetrics": ["activation in the mPFC and AI"], "RestingState": "false", "TaskDuration": "15\u2009min"}, {"TaskName": "Familiarity of the target", "TaskDescription": "Participants could give away 1, 2, or 3 out of 7 coins in the small giving condition, and 4, 5, or 6 out of 7 coins in the large giving condition.", "DesignDetails": "Participants could give away 1, 2, or 3 out of 7 coins in the small giving condition, and 4, 5, or 6 out of 7 coins in the large giving condition.", "Conditions": ["small giving condition", "large giving condition"], "TaskMetrics": ["activation in the mPFC and AI"], "RestingState": "false", "TaskDuration": "15\u2009min"}, {"TaskName": "Peer presence", "TaskDescription": "Participants could give away 1, 2, or 3 out of 7 coins in the small giving condition, and 4, 5, or 6 out of 7 coins in the large giving condition.", "DesignDetails": "Participants could give away 1, 2, or 3 out of 7 coins in the small giving condition, and 4, 5, or 6 out of 7 coins in the large giving condition.", "Conditions": ["small giving condition", "large giving condition"], "TaskMetrics": ["activation in the mPFC and AI"], "RestingState": "false", "TaskDuration": "15\u2009min"}], "BehavioralTasks": [{"TaskName": "Giving behavior", "TaskDescription": "Participants gave more to a friend than to an unfamiliar peer, especially in the small giving context.", "DesignDetails": "Participants gave more to a friend than to an unfamiliar peer, especially in the small giving context.", "Conditions": ["small giving condition", "large giving condition"], "TaskMetrics": ["activation in the mPFC and AI"], "RestingState": "false", "TaskDuration": "15\u2009min"}], "id": 8857499}, {"StudyObjective": "The role of the right prefrontal cortex in the retrieval of weak representations", "fMRITasks": [{"TaskName": "2-back updating task", "TaskDescription": "Participants were required to determine whether the current target was identical to the stimulus that appeared two trials earlier in the Classification task.", "DesignDetails": "The task began with a Classification trial. Specifically, the participants were asked to classify the target stimuli, printed in red, based on their characteristics (i.e., odd/even or vowel/consonant). Subsequently, when the color of the target was changed to green, participants were required to perform the 2Back trials (2Back switch; 2Back-SW). In the 2Back-SW trials, participants were required to identify whether the given stimulus was identical to the one (i.e., a previous red target or gray distractor) presented two trials earlier in the Classification task.", "Conditions": ["2Back-SWr", "2Back-SWi", "2Back-RP"], "TaskMetrics": ["accuracy", "reaction time"], "RestingState": "false", "TaskDuration": "2000\u20134000\u00a0ms"}, {"TaskName": "Classification task", "TaskDescription": "Participants were asked to classify the stimuli as odd/even or vowel/consonant according to whether the current red target was a number or letter, respectively, by pressing a left or right button.", "DesignDetails": "The task began with a Classification trial. Specifically, the participants were asked to classify the target stimuli, printed in red, based on their characteristics (i.e., odd/even or vowel/consonant). Subsequently, when the color of the target was changed to green, participants were required to perform the 2Back trials (2Back switch; 2Back-SW). In the 2Back-SW trials, participants were required to identify whether the given stimulus was identical to the one (i.e., a previous red target or gray distractor) presented two trials earlier in the Classification task.", "Conditions": ["Classification-SWr", "Classification-SWi", "Classification-RP"], "TaskMetrics": ["accuracy", "reaction time"], "RestingState": "false", "TaskDuration": "2000\u20134000\u00a0ms"}], "BehavioralTasks": [{"TaskName": "Alternate Uses Test (AUT)", "TaskDescription": "Participants were instructed to generate appropriate alternative uses for three common objects (\u201cBrick,\u201d \u201cKey,\u201d and \u201cNewspaper\u201d); they recorded as many uses as possible for each item within 2\u00a0min using a paper and pen.", "DesignDetails": "The task consisted of 480 trials divided into four runs. Each of the 2Back-SWi, 2Back-SWr, Classification-SWi, and Classification-SWr conditions included 30 trials, while the 2Back-RP and Classification-RP conditions included 120 and 180 trials, respectively.", "Conditions": ["Classification-SWr", "Classification-SWi", "Classification-RP"], "TaskMetrics": ["fluency", "flexibility", "originality"]}, {"TaskName": "Arrow flanker task", "TaskDescription": "A horizontal array of five white arrows in the center of the screen was presented on a black background. The middle arrow was the target while the others were non-target distractors. The task required participants to respond to the direction of the target with a left or right button press as quickly and accurately as possible while ignoring distractors.", "DesignDetails": "The task consisted of 128 trials (64 congruent and 64 incongruent trials). The stimuli were presented for 500\u00a0ms with a fixation cross presented as an ITI in the middle of the screen for 2000\u00a0ms.", "Conditions": ["congruent", "incongruent"], "TaskMetrics": ["interference effect"]}, {"TaskName": "Response switching task", "TaskDescription": "Stimuli for the response switching task consisted of four even numbers (2, 4, 6, and 8) and four odd (3, 5, 7, and 9), which were colored either green or red. Participants were asked to classify the targets as odd or even by pressing their left or right buttons, respectively, when the target color was green; their responses were then reversed when the target was red.", "DesignDetails": "The task included 40 switch trials and 120 repeat trials. The stimuli were presented for 500\u00a0ms with a fixation cross presented as an ITI in the middle of the screen for 2000\u00a0ms.", "Conditions": ["switch", "repeat"], "TaskMetrics": ["switch cost"]}], "id": 8927597}, {"StudyObjective": "Processing of visual and non-visual naturalistic spatial information in the 'parahippocampal place area'", "fMRITasks": [{"TaskName": "movie stimulus", "TaskDescription": "The movie stimulus offers ecologically more valid visual stimulation than a paradigm using blocks of pictures.", "DesignDetails": "The movie\u2019s primary t-contrast that compared cuts to a setting that was not depicted before to cuts within a recurring setting (vse_new\u2009>\u2009vpe_old) yielded three significant clusters.", "Conditions": ["vse_new", "vse_old", "vlo_ch", "vpe_new", "vpe_old"], "TaskMetrics": ["Z-threshold Z > 3.4", "p < 0.05", "cluster-corrected"], "RestingState": "false", "TaskDuration": null}, {"TaskName": "audio-description stimulus", "TaskDescription": "The audio-description stimulus offers an exclusively auditory stimulation.", "DesignDetails": "The primary t-contrast for the audio-description (geo, groom\u2009>\u2009non-spatial noun categories) yielded six significant clusters.", "Conditions": ["geo", "groom", "se_new", "se_old"], "TaskMetrics": ["Z-threshold Z > 3.4", "p < 0.05", "cluster-corrected"], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "audio-description stimulus", "TaskDescription": "The audio-description stimulus offers an exclusively auditory stimulation.", "DesignDetails": "The primary t-contrast for the audio-description (geo, groom\u2009>\u2009non-spatial noun categories) yielded six significant clusters.", "Conditions": ["geo", "groom", "se_new", "se_old"], "TaskMetrics": ["Z-threshold Z > 3.4", "p < 0.05", "cluster-corrected"], "RestingState": "false", "TaskDuration": null}], "id": 8975992}, {"StudyObjective": "Decreased Efficiency of Between-Network Dynamics During Early Memory Consolidation With Aging", "fMRITasks": [{"TaskName": "encoding", "TaskDescription": "Participants had to memorize the object and its respective position.", "DesignDetails": "The encoding task consisted of 64 trials. During each trial, participants saw a stimulus, showing a colored photograph of a natural or artificial (man-made) object. The stimuli were randomly presented in one of four circles on a white screen, arranged in a horizontal semi-circle bent to the top. Participants had to memorize the object and its respective position. To ensure alertness, participants had to indicate whether the object was natural or artificial by pressing two corresponding keys with their right index and middle finger, respectively. Each stimulus was presented for 3 s with a variable inter-trial interval of 2 to 12 s, followed by a fixation cross presented for 2 s.", "Conditions": ["control", "reminder", "interference"], "TaskMetrics": ["fractional amplitude of low-frequency fluctuations (fALFF)"], "RestingState": "false", "TaskDuration": "14 min"}, {"TaskName": "consolidation", "TaskDescription": "The consolidation phase was interrupted by a modulatory task that differed between conditions in the extent to which consolidation processes were supposed to be affected.", "DesignDetails": "The consolidation phase was interrupted by a modulatory task that differed between conditions in the extent to which consolidation processes were supposed to be affected: Interference task: In the interference condition, the same stimuli as in the encoding task were presented again, but at a different position. Thus, the spatial contextual information was expected to interfere with that of the initial encoding task. Participants were asked to decide whether the object was natural or artificial but to ignore the spatial position. Reminder task: In the reminder condition, the stimuli presented during encoding were presented again, albeit in the middle at the bottom of the screen. Thus, no interference with spatial contextual information was assumed. Instead, repeated presentation of the stimuli at a neutral position was expected to facilitate memory consolidation by causing reactivation of the memory for the respective position during the preceding encoding run. Participants were asked to make natural-artificial judgments. They were not instructed to recall the position of the stimuli from the encoding task. Control task: In the control task, abstract and pixelated images with no meaningful information were presented in the middle at the bottom of the screen. Participants were asked to press a button with their right index finger each time an image appeared. The task was expected to provide neither interference nor any type of reminder, while variables such as motor activity and visual input were kept constant to the interference and reminder task.", "Conditions": ["control", "reminder", "interference"], "TaskMetrics": ["fractional amplitude of low-frequency fluctuations (fALFF)"], "RestingState": "false", "TaskDuration": "14 min"}, {"TaskName": "retrieval", "TaskDescription": "During the retrieval task, the stimuli of the encoding task were presented in the screen\u2019s center. Participants had to indicate the position of the stimuli during encoding by pressing four respective keys with their right-hand fingers. Each stimulus was presented for 2 s, followed by a variable inter-trial interval of 2 to 12 s and a 2-s fixation cross.", "DesignDetails": "During the retrieval task, the stimuli of the encoding task were presented in the screen\u2019s center. Participants had to indicate the position of the stimuli during encoding by pressing four respective keys with their right-hand fingers. Each stimulus was presented for 2 s, followed by a variable inter-trial interval of 2 to 12 s and a 2-s fixation cross.", "Conditions": ["control", "reminder", "interference"], "TaskMetrics": ["fractional amplitude of low-frequency fluctuations (fALFF)"], "RestingState": "false", "TaskDuration": "14 min"}], "BehavioralTasks": [{"TaskName": "spatial contextual memory performance", "TaskDescription": "Memory performance varied with the extent of interference during consolidation across groups.", "DesignDetails": "Mixed ANOVA yielded a significant within-subject effect   condition  . Memory performance varied with the extent of interference during consolidation across groups [  F  (2,54) = 6.901,   p   = 0.002,   \u03b7   = 0.204]. Pairwise comparisons indicated a significantly decreased memory performance in the interference relative to both the control and reminder conditions (both   p-FDR   < 0.018). However, there was no significant difference in memory performance between the control and reminder conditions (  p-FDR   = 0.450).", "Conditions": ["control", "reminder", "interference"], "TaskMetrics": ["spatial contextual memory performance"]}, {"TaskName": "inhibition capacity", "TaskDescription": "Inhibition capacity or interference susceptibility was operationalized as d-prime: Positive d-prime values indicate the ability to successfully ignore the object-location associations from the interference task (inhibition capacity). A negative d-prime, in turn, indicates susceptibility to the object-location associations from the interference task (susceptibility to retroactive interference).", "DesignDetails": "Using   d  -prime, the number of intrusions was related to the number of correctly remembered object-location associations in the interference condition. A two-sample   t  -test showed a significant difference in d-prime between groups, indicating a negative d-prime for HS and a positive d-prime for HY [  t  (27) = 3.209,   p   = 0.007,   95% CI   [0.673, 3.359],   Cohen\u2019s d   = 1.198] ( ).", "Conditions": ["control", "reminder", "interference"], "TaskMetrics": ["d-prime"]}], "id": 9148994}, {"StudyObjective": "Does losing money truly hurt? The shared neural bases of monetary loss and pain", "fMRITasks": [{"TaskName": "Monetary loss", "TaskDescription": "The receipt of monetary loss activates a broad range of brain regions, including the anterior cingulate cortex (ACC), inferior frontal gyrus, medial frontal cortex, insula, cuneus, lingual gyrus, and parahippocampal gyrus.", "DesignDetails": "A meta\u2010analysis to explore the overlapping brain regions between monetary loss and pain, including physical pain and social pain.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Physical pain", "TaskDescription": "The processing of physical pain involves a specific brain network referred to as the \u201cpain matrix,\u201d including the sensory\u2010discriminative system and cognitive\u2010affective system.", "DesignDetails": "The neurocognitive network underlying physical pain and social pain were similar to those underlying monetary loss.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "Social pain", "TaskDescription": "The processing of social pain activates the insula, ACC, and ventrolateral prefrontal cortex.", "DesignDetails": "Previous studies have found that monetary loss directly affects individuals\u2019 sensitivity to pain, since monetary loss might amplify the painful feelings of nociceptive stimuli or social exclusion.", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [], "id": 9189080}, {"StudyObjective": "The aim of the study was to evaluate correlation of sleep quality with visual attention and search, functional, and tracts\u2019 properties of the DAN and VAN.", "fMRITasks": [{"TaskName": "match-to-sample (MTS) task", "TaskDescription": "In this computerized task, subjects were presented with a complex figure in the middle of the screen. Then, a few patterns were shown in the periphery, from which one was matched with the presented pattern. In the first trials, two patterns were presented in the periphery, and it was increased to eight patterns in the final trials. A total of 48 trials were conducted for each subject. Total correct, mean reaction time (RT), and mean RT change from 2 to 8 pattern trials were calculated for each participant.", "DesignDetails": "We used the match-to-sample (MTS) task of the Cambridge Neuropsychological Test Automated Battery (CANTAB) for visual search and attention.", "Conditions": [], "TaskMetrics": ["total correct", "mean RT", "mean RT change"], "RestingState": "false", "TaskDuration": "6:08 mins"}], "BehavioralTasks": [{"TaskName": "match-to-sample (MTS) task", "TaskDescription": "In this computerized task, subjects were presented with a complex figure in the middle of the screen. Then, a few patterns were shown in the periphery, from which one was matched with the presented pattern. In the first trials, two patterns were presented in the periphery, and it was increased to eight patterns in the final trials. A total of 48 trials were conducted for each subject. Total correct, mean reaction time (RT), and mean RT change from 2 to 8 pattern trials were calculated for each participant.", "DesignDetails": "We used the match-to-sample (MTS) task of the Cambridge Neuropsychological Test Automated Battery (CANTAB) for visual search and attention.", "Conditions": [], "TaskMetrics": ["total correct", "mean RT", "mean RT change"]}], "id": 9202476}, {"StudyObjective": "Longitudinal changes in auditory and reward systems following receptive music-based intervention in older adults", "fMRITasks": [{"TaskName": "fMRI task", "TaskDescription": "Participants were presented with a musical stimulus (lasting 20 s), then they were given the task of rating how familiar they found the music to be (familiarity rating lasted 2 s), and how much they liked the music (liking rating also lasted 2 s).", "DesignDetails": "Musical stimuli for the MRI task consisted of 24 different audio excerpts. Each auditory stimulus was from one of the following three categories: participant self-selected music (6/24 stimuli), other-selected (researcher-selected) music including well-known excerpts spanning multiple musical genres (10/24 stimuli) and novel music spanning multiple genres (8/24 stimuli).", "Conditions": ["self-selected", "other-selected well-known", "other-selected novel"], "TaskMetrics": ["liking rating", "familiarity rating"], "RestingState": "false", "TaskDuration": "20 s"}], "BehavioralTasks": [{"TaskName": "Behavioral tasks", "TaskDescription": "Participants rated self-selected and researcher-selected musical excerpts on liking and familiarity.", "DesignDetails": "Participants rated self-selected and researcher-selected musical excerpts on liking and familiarity.", "Conditions": ["self-selected", "other-selected well-known", "other-selected novel"], "TaskMetrics": ["liking rating", "familiarity rating"]}], "id": 9261172}, {"StudyObjective": "To study age-related differences in ventral striatal and default mode network function during reciprocated trust.", "fMRITasks": [{"TaskName": "Trust Game", "TaskDescription": "Participants played an economic trust game as the investor with three partners (friend, stranger, and computer) who played the role of investee.", "DesignDetails": "Participants underwent functional magnetic resonance imaging (fMRI) during the trust game while investees were seated outside of the scanner.", "Conditions": ["friend", "stranger", "computer"], "TaskMetrics": ["striatal responses", "default mode network connectivity"], "RestingState": "false", "TaskDuration": "90"}, {"TaskName": "Additional fMRI tasks", "TaskDescription": "Participants completed two separate, additional fMRI tasks aimed at investigating age-related differences in shared reward processing and bargaining behavior.", "DesignDetails": null, "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [{"TaskName": "Trust Game", "TaskDescription": "Participants played an economic trust game as the investor with three partners (friend, stranger, and computer) who played the role of investee.", "DesignDetails": "Participants underwent functional magnetic resonance imaging (fMRI) during the trust game while investees were seated outside of the scanner.", "Conditions": ["friend", "stranger", "computer"], "TaskMetrics": ["investment rates", "reaction time"], "RestingState": "false", "TaskDuration": "90"}], "id": 9308012}, {"StudyObjective": "Investigate the neuronal relations of mechanical restriction, specifically the impact of acute loss of stomach restriction on neuronal activation during food viewing.", "fMRITasks": [{"TaskName": "Food Cue Reactivity Task", "TaskDescription": "Participants were asked to indicate whether they 'liked,' 'disliked,' or felt 'neutral' about each image by pressing a corresponding button within 2,000 ms of image presentation; ratings and reaction times were logged via a fiber-optic response box.", "DesignDetails": "The task was modified in-house from the Alcohol Cue Reactivity Task.", "Conditions": ["sham-deflation", "deflation"], "TaskMetrics": ["activation in response to food images", "activation in response to degraded images"], "RestingState": "false", "TaskDuration": "5:54 min"}], "BehavioralTasks": [{"TaskName": "Visual Analog Scale (VAS) on food intake motivation", "TaskDescription": "Participants were asked to indicate their motivation for food intake by pressing a corresponding button within 2,000 ms of image presentation; ratings and reaction times were logged via a fiber-optic response box.", "DesignDetails": null, "Conditions": ["sham-deflation", "deflation"], "TaskMetrics": ["VAS motivation for food intake"]}], "id": 9454014}, {"StudyObjective": "Re-examined the VAN and the DAN neuroanatomy by co-registering individual network maps in a common functional space.", "fMRITasks": [{"TaskName": "Resting-state functional imaging (rs-fMRI)", "TaskDescription": "Used 110 7\u2009T resting-state functional MRI datasets from the Human Connectome Project S1200.", "DesignDetails": "Images were preprocessed and registered to the MNI152 space as specified in the Human Connectome Project protocol.", "Conditions": [], "TaskMetrics": [], "RestingState": "true", "TaskDuration": null}], "BehavioralTasks": [], "id": 9729227}, {"StudyObjective": "To examine whether lonely individuals have a reduced ability to synchronize with others.", "fMRITasks": [{"TaskName": "Random condition", "TaskDescription": "Participants control the movement of one circle, and the other circle's movement is controlled by the computer and is randomized.", "DesignDetails": "The movement of the circle assigned to the participant outside the scanner was controlled using the 1\u20134 keys on a keyboard, and the movement of the circle assigned to the participant inside the scanner was controlled using the 4 keys of the response box.", "Conditions": ["Random condition"], "TaskMetrics": ["Following periods", "Zero-lag correlation score"], "RestingState": "false", "TaskDuration": "45"}, {"TaskName": "Free condition", "TaskDescription": "Participants control the movement of the circle that was assigned to them, and the other circle is controlled by the other participant. Participants are instructed to move their circle freely.", "DesignDetails": "The movement of the circle assigned to the participant outside the scanner was controlled using the 1\u20134 keys on a keyboard, and the movement of the circle assigned to the participant inside the scanner was controlled using the 4 keys of the response box.", "Conditions": ["Free condition"], "TaskMetrics": ["Following periods", "Zero-lag correlation score"], "RestingState": "false", "TaskDuration": "45"}, {"TaskName": "Synchronized movement condition", "TaskDescription": "Participants are instructed to coordinate their movement with the other participant.", "DesignDetails": "The movement of the circle assigned to the participant outside the scanner was controlled using the 1\u20134 keys on a keyboard, and the movement of the circle assigned to the participant inside the scanner was controlled using the 4 keys of the response box.", "Conditions": ["Synchronized movement condition"], "TaskMetrics": ["Following periods", "Zero-lag correlation score"], "RestingState": "false", "TaskDuration": "45"}], "BehavioralTasks": [{"TaskName": "Enjoyment ratings", "TaskDescription": "Participants rated how much they enjoyed the game.", "DesignDetails": "Participants\u2019 enjoyment ratings in each of the blocks were used to calculate an average enjoyment score in each condition for each participant.", "Conditions": ["Sync condition", "Free condition", "Random condition"], "TaskMetrics": ["Enjoyment score"]}], "id": 9837608}, {"StudyObjective": "We combined established emotion regulation and dietary choice tasks with fMRI to investigate behavioral and neural associations in self-regulation across the two domains in human participants.", "fMRITasks": [{"TaskName": "emotion reappraisal", "TaskDescription": "Participants were asked to either (1) simply view and react naturally or (2) reappraise photographs with different emotional valence.", "DesignDetails": "Participants were able to both regulate their emotions and use dietary self-control to select healthier foods well within each experimental task, respectively.", "Conditions": ["positive view", "positive reappraisal success", "negative view", "negative reappraisal success", "neutral view", "positive regulate", "positive view"], "TaskMetrics": ["emotion reappraisal success"], "RestingState": "false", "TaskDuration": "7 s"}, {"TaskName": "food choice", "TaskDescription": "Participants knew that one of these trials would be selected at random and their choice on that trial implemented for real, meaning that they would have to eat the food item or go hungry for an additional 30\u00a0min.", "DesignDetails": "Participants were able to both regulate their emotions and use dietary self-control to select healthier foods well within each experimental task, respectively.", "Conditions": ["palatable\u2013unhealthy foods", "unpalatable\u2013healthy foods"], "TaskMetrics": ["food choice success"], "RestingState": "false", "TaskDuration": "3 s"}], "BehavioralTasks": [{"TaskName": "emotion reappraisal", "TaskDescription": "Participants were able to both regulate their emotions and use dietary self-control to select healthier foods well within each experimental task, respectively.", "DesignDetails": "Participants were able to both regulate their emotions and use dietary self-control to select healthier foods well within each experimental task, respectively.", "Conditions": ["positive view", "positive reappraisal success", "negative view", "negative reappraisal success", "neutral view", "positive regulate", "positive view"], "TaskMetrics": ["emotion reappraisal success"], "RestingState": "false", "TaskDuration": "7 s"}, {"TaskName": "food choice", "TaskDescription": "Participants were able to both regulate their emotions and use dietary self-control to select healthier foods well within each experimental task, respectively.", "DesignDetails": "Participants were able to both regulate their emotions and use dietary self-control to select healthier foods well within each experimental task, respectively.", "Conditions": ["palatable\u2013unhealthy foods", "unpalatable\u2013healthy foods"], "TaskMetrics": ["food choice success"], "RestingState": "false", "TaskDuration": "3 s"}], "id": 9910278}, {"StudyObjective": "Neighborhood disadvantage, race/ethnicity and neural sensitivity to social threat and reward among adolescents", "fMRITasks": [{"TaskName": "Social Incentive Delay Task", "TaskDescription": "Participants completed the Social Incentive Delay Task ( ) while undergoing fMRI to measure neural responses to anticipating social rewards and threats.", "DesignDetails": "Each trial began with a cue (i.e.\u00a0a shape) that signaled whether the upcoming image was a potential reward (i.e.\u00a0happy face), threat (i.e.\u00a0angry face) or neutral (i.e.\u00a0blurred face). Participants completed two rounds of the task, totaling 116 trials (48 reward, 48 threat and 20 neutral).", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "fMRI data acquisition and preprocessing", "TaskDescription": "A full description of fMRI data acquisition and preprocessing parameters can be found in the  .", "DesignDetails": "A full description of fMRI data acquisition and preprocessing parameters can be found in the  .", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}, {"TaskName": "fMRI data analysis", "TaskDescription": "Individual-level, fixed-effects analyses were estimated using the general linear model convolved with a canonical hemodynamic response function in SPM12. A full description of task modeling can be found in the  .", "DesignDetails": "Individual-level, fixed-effects analyses were estimated using the general linear model convolved with a canonical hemodynamic response function in SPM12. A full description of task modeling can be found in the  .", "Conditions": [], "TaskMetrics": [], "RestingState": "false", "TaskDuration": null}], "BehavioralTasks": [], "id": 9949505}]